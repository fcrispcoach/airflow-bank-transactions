2025-05-02 16:33:18,770 INFO - Loaded executor: SequentialExecutor
2025-05-02 16:33:19,117 INFO - Starting the scheduler
2025-05-02 16:33:19,120 INFO - Processing each file at most -1 times
2025-05-02 16:33:19,133 INFO - Launched DagFileProcessorManager with pid: 271099
2025-05-02 16:33:19,135 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:33:19,138 INFO - Configured default timezone UTC
2025-05-02 16:33:37,128 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 16:33:37,978 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:33:37,978 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:33:37,979 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:33:37,981 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:33:37,982 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 16:33:37,982 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:33:38,129 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:33:43,437 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 16:33:43,443 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 19:33:40.954991+00:00, run_end_date=2025-05-02 19:33:42.143965+00:00, run_duration=1.188974, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=3, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 19:33:37.980043+00:00, queued_by_job_id=2, pid=271293
2025-05-02 16:36:44,628 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T19:36:41.836623+00:00 [scheduled]>
2025-05-02 16:36:44,629 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:36:44,629 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T19:36:41.836623+00:00 [scheduled]>
2025-05-02 16:36:44,632 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T19:36:41.836623+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:36:44,632 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T19:36:41.836623+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 16:36:44,633 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T19:36:41.836623+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:36:44,791 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T19:36:41.836623+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:36:49,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T19:36:41.836623+00:00', try_number=1, map_index=-1)
2025-05-02 16:36:50,114 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T19:36:41.836623+00:00, map_index=-1, run_start_date=2025-05-02 19:36:47.590787+00:00, run_end_date=2025-05-02 19:36:48.518569+00:00, run_duration=0.927782, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=4, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 19:36:44.630666+00:00, queued_by_job_id=2, pid=272503
2025-05-02 16:38:19,373 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:38:42,799 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:38:42,800 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:38:42,801 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:38:42,804 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:38:42,805 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 16:38:42,806 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:38:42,936 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:38:47,952 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1)
2025-05-02 16:38:47,956 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 19:38:45.704702+00:00, run_end_date=2025-05-02 19:38:46.471076+00:00, run_duration=0.766374, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=5, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 19:38:42.802926+00:00, queued_by_job_id=2, pid=273212
2025-05-02 16:38:48,283 ERROR - Marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 19:33:37.109521+00:00. externally triggered: False> failed
2025-05-02 16:38:48,284 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 19:33:37.456148+00:00, run_end_date=2025-05-02 19:38:48.284720+00:00, run_duration=310.828572, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=954c438b5f491c6d6e97f9745942fd63
2025-05-02 16:38:48,289 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 16:41:40,678 ERROR - Task deadlock (no runnable tasks); marking run <DagRun fraud_detection_pipeline @ 2025-05-02 19:36:41.836623+00:00: manual__2025-05-02T19:36:41.836623+00:00, state:running, queued_at: 2025-05-02 19:36:41.862371+00:00. externally triggered: True> failed
2025-05-02 16:41:40,679 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-02 19:36:41.836623+00:00, run_id=manual__2025-05-02T19:36:41.836623+00:00, run_start_date=2025-05-02 19:36:44.279935+00:00, run_end_date=2025-05-02 19:41:40.679580+00:00, run_duration=296.399645, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=954c438b5f491c6d6e97f9745942fd63
2025-05-02 16:42:36,434 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 16:42:37,444 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:42:37,445 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:42:37,446 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:42:37,449 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:42:37,450 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 16:42:37,451 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:42:37,572 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:42:49,657 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 16:42:49,662 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 19:42:41.602626+00:00, run_end_date=2025-05-02 19:42:46.456257+00:00, run_duration=4.853631, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=6, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 19:42:37.447345+00:00, queued_by_job_id=2, pid=274989
2025-05-02 16:42:50,338 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:42:50,339 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:42:50,340 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:42:50,342 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:42:50,342 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 16:42:50,343 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:42:50,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:42:57,070 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 16:42:57,073 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 19:42:54.159802+00:00, run_end_date=2025-05-02 19:42:55.518100+00:00, run_duration=1.358298, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 19:42:50.341000+00:00, queued_by_job_id=2, pid=275063
2025-05-02 16:42:57,309 INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 19:42:36.424231+00:00. externally triggered: False> successful
2025-05-02 16:42:57,310 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 19:42:36.790696+00:00, run_end_date=2025-05-02 19:42:57.310263+00:00, run_duration=20.519567, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=954c438b5f491c6d6e97f9745942fd63
2025-05-02 16:42:57,313 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 16:43:19,442 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:48:19,475 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:51:35,073 INFO - Exiting gracefully upon receiving signal 15
2025-05-02 16:51:36,288 INFO - Sending 15 to group 271099. PIDs of all processes in the group: [271099]
2025-05-02 16:51:36,289 INFO - Sending the signal 15 to group 271099
2025-05-02 16:51:36,582 INFO - Process psutil.Process(pid=271099, status='terminated', exitcode=0, started='16:33:18') (271099) terminated with exit code 0
2025-05-02 16:51:36,604 INFO - Sending 15 to group 271099. PIDs of all processes in the group: []
2025-05-02 16:51:36,604 INFO - Sending the signal 15 to group 271099
2025-05-02 16:51:36,605 INFO - Sending the signal 15 to process 271099 as process group is missing.
2025-05-02 16:51:36,605 INFO - Exited execute loop
2025-05-02 16:51:50,809 INFO - Loaded executor: SequentialExecutor
2025-05-02 16:51:51,356 INFO - Starting the scheduler
2025-05-02 16:51:51,359 INFO - Processing each file at most -1 times
2025-05-02 16:51:51,372 INFO - Launched DagFileProcessorManager with pid: 278880
2025-05-02 16:51:51,374 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:51:51,378 INFO - Configured default timezone UTC
2025-05-02 16:52:22,682 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 16:52:23,536 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:52:23,538 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:52:23,539 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:52:23,549 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:52:23,551 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 16:52:23,553 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:52:23,698 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:52:31,832 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 16:52:31,843 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 19:52:27.011155+00:00, run_end_date=2025-05-02 19:52:29.902781+00:00, run_duration=2.891626, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=9, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 19:52:23.543430+00:00, queued_by_job_id=8, pid=279105
2025-05-02 16:52:32,760 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:52:32,761 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 16:52:32,761 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 16:52:32,763 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 16:52:32,763 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 16:52:32,764 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:52:33,028 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 16:52:40,917 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 16:52:40,920 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 19:52:35.915126+00:00, run_end_date=2025-05-02 19:52:38.785444+00:00, run_duration=2.870318, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=10, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 19:52:32.762289+00:00, queued_by_job_id=8, pid=279178
2025-05-02 16:52:41,550 INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 19:52:22.666469+00:00. externally triggered: False> successful
2025-05-02 16:52:41,551 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 19:52:22.946322+00:00, run_end_date=2025-05-02 19:52:41.551478+00:00, run_duration=18.605156, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 16:52:41,557 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 16:56:51,423 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:58:38,893 INFO - Exiting gracefully upon receiving signal 15
2025-05-02 16:58:39,248 INFO - Sending 15 to group 278880. PIDs of all processes in the group: []
2025-05-02 16:58:39,249 INFO - Sending the signal 15 to group 278880
2025-05-02 16:58:39,250 INFO - Sending the signal 15 to process 278880 as process group is missing.
2025-05-02 16:58:39,254 INFO - Sending 15 to group 278880. PIDs of all processes in the group: []
2025-05-02 16:58:39,255 INFO - Sending the signal 15 to group 278880
2025-05-02 16:58:39,257 INFO - Sending the signal 15 to process 278880 as process group is missing.
2025-05-02 16:58:39,258 INFO - Exited execute loop
2025-05-02 16:59:23,836 INFO - Loaded executor: SequentialExecutor
2025-05-02 16:59:24,142 INFO - Starting the scheduler
2025-05-02 16:59:24,146 INFO - Processing each file at most -1 times
2025-05-02 16:59:24,158 INFO - Launched DagFileProcessorManager with pid: 282510
2025-05-02 16:59:24,161 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 16:59:24,164 INFO - Configured default timezone UTC
2025-05-02 17:04:24,206 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:09:24,265 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:14:19,678 INFO - Exiting gracefully upon receiving signal 15
2025-05-02 17:14:20,701 INFO - Sending 15 to group 282510. PIDs of all processes in the group: [282510]
2025-05-02 17:14:20,702 INFO - Sending the signal 15 to group 282510
2025-05-02 17:14:21,540 INFO - Process psutil.Process(pid=282510, status='terminated', exitcode=0, started='16:59:23') (282510) terminated with exit code 0
2025-05-02 17:14:21,608 INFO - Sending 15 to group 282510. PIDs of all processes in the group: []
2025-05-02 17:14:21,612 INFO - Sending the signal 15 to group 282510
2025-05-02 17:14:21,613 INFO - Sending the signal 15 to process 282510 as process group is missing.
2025-05-02 17:14:21,615 INFO - Exited execute loop
2025-05-02 17:20:01,146 INFO - Loaded executor: SequentialExecutor
2025-05-02 17:20:01,512 INFO - Starting the scheduler
2025-05-02 17:20:01,514 INFO - Processing each file at most -1 times
2025-05-02 17:20:01,524 INFO - Launched DagFileProcessorManager with pid: 291991
2025-05-02 17:20:01,526 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:20:01,528 INFO - Configured default timezone UTC
2025-05-02 17:22:04,935 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:22:05,482 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:22:05,482 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:22:05,482 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:22:05,484 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:22:05,485 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:22:05,486 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:22:05,613 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:22:11,350 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 17:22:11,356 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:22:08.865988+00:00, run_end_date=2025-05-02 20:22:10.142206+00:00, run_duration=1.276218, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=11, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:22:05.483474+00:00, queued_by_job_id=10, pid=292816
2025-05-02 17:22:49,951 INFO - Exiting gracefully upon receiving signal 15
2025-05-02 17:22:50,808 INFO - Sending 15 to group 291991. PIDs of all processes in the group: []
2025-05-02 17:22:50,809 INFO - Sending the signal 15 to group 291991
2025-05-02 17:22:50,810 INFO - Sending the signal 15 to process 291991 as process group is missing.
2025-05-02 17:22:50,815 INFO - Sending 15 to group 291991. PIDs of all processes in the group: []
2025-05-02 17:22:50,816 INFO - Sending the signal 15 to group 291991
2025-05-02 17:22:50,818 INFO - Sending the signal 15 to process 291991 as process group is missing.
2025-05-02 17:22:50,819 INFO - Exited execute loop
2025-05-02 17:30:03,690 INFO - Loaded executor: SequentialExecutor
2025-05-02 17:30:03,989 INFO - Starting the scheduler
2025-05-02 17:30:03,990 INFO - Processing each file at most -1 times
2025-05-02 17:30:03,998 INFO - Launched DagFileProcessorManager with pid: 295856
2025-05-02 17:30:04,000 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:30:04,002 INFO - Configured default timezone UTC
2025-05-02 17:30:04,741 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:30:04,742 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:30:04,742 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:30:04,746 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:30:04,747 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:30:04,748 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:30:04,935 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:30:12,641 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1)
2025-05-02 17:30:12,705 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:30:08.600031+00:00, run_end_date=2025-05-02 20:30:10.145829+00:00, run_duration=1.545798, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:30:04.744381+00:00, queued_by_job_id=12, pid=295937
2025-05-02 17:30:12,964 ERROR - Marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 20:22:04.915576+00:00. externally triggered: False> failed
2025-05-02 17:30:12,964 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 20:22:05.120769+00:00, run_end_date=2025-05-02 20:30:12.964703+00:00, run_duration=487.843934, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:30:12,972 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:31:37,962 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:31:38,419 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:31:38,420 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:31:38,421 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:31:38,423 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:31:38,424 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:31:38,425 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:31:38,770 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:31:47,816 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 17:31:47,820 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:31:42.921180+00:00, run_end_date=2025-05-02 20:31:45.911229+00:00, run_duration=2.990049, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:31:38.421971+00:00, queued_by_job_id=12, pid=296443
2025-05-02 17:32:29,243 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:32:27.652839+00:00 [scheduled]>
2025-05-02 17:32:29,244 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:32:29,244 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:32:27.652839+00:00 [scheduled]>
2025-05-02 17:32:29,677 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:32:27.652839+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:32:29,680 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:32:27.652839+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:32:29,683 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:32:27.652839+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:32:30,177 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:32:27.652839+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:32:42,219 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:32:27.652839+00:00', try_number=1, map_index=-1)
2025-05-02 17:32:42,269 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T20:32:27.652839+00:00, map_index=-1, run_start_date=2025-05-02 20:32:37.813366+00:00, run_end_date=2025-05-02 20:32:39.305682+00:00, run_duration=1.492316, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:32:29.245641+00:00, queued_by_job_id=12, pid=296755
2025-05-02 17:35:04,232 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:36:47,641 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:36:47,642 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:36:47,643 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:36:47,648 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:36:47,649 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:36:47,650 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:36:47,777 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:36:54,539 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1)
2025-05-02 17:36:54,545 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:36:51.879734+00:00, run_end_date=2025-05-02 20:36:52.806235+00:00, run_duration=0.926501, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=16, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:36:47.646004+00:00, queued_by_job_id=12, pid=298241
2025-05-02 17:36:55,370 ERROR - Marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 20:31:37.950908+00:00. externally triggered: False> failed
2025-05-02 17:36:55,371 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 20:31:38.098414+00:00, run_end_date=2025-05-02 20:36:55.371087+00:00, run_duration=317.272673, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:36:55,375 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:37:40,600 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:32:27.652839+00:00 [scheduled]>
2025-05-02 17:37:40,602 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:37:40,603 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:32:27.652839+00:00 [scheduled]>
2025-05-02 17:37:40,610 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:32:27.652839+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:37:40,612 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:32:27.652839+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:37:40,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:32:27.652839+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:37:40,828 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:32:27.652839+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:37:47,701 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:32:27.652839+00:00', try_number=2, map_index=-1)
2025-05-02 17:37:47,709 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T20:32:27.652839+00:00, map_index=-1, run_start_date=2025-05-02 20:37:44.802717+00:00, run_end_date=2025-05-02 20:37:45.726266+00:00, run_duration=0.923549, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=17, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:37:40.606192+00:00, queued_by_job_id=12, pid=298528
2025-05-02 17:37:48,118 ERROR - Marking run <DagRun fraud_detection_pipeline @ 2025-05-02 20:32:27.652839+00:00: manual__2025-05-02T20:32:27.652839+00:00, state:running, queued_at: 2025-05-02 20:32:27.722404+00:00. externally triggered: True> failed
2025-05-02 17:37:48,119 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-02 20:32:27.652839+00:00, run_id=manual__2025-05-02T20:32:27.652839+00:00, run_start_date=2025-05-02 20:32:28.777158+00:00, run_end_date=2025-05-02 20:37:48.119523+00:00, run_duration=319.342365, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:40:04,273 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:43:37,876 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:43:38,595 INFO - 2 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:43:35.409881+00:00 [scheduled]>
2025-05-02 17:43:38,597 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:43:38,599 INFO - DAG fraud_detection_pipeline has 1/16 running and queued tasks
2025-05-02 17:43:38,600 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:43:35.409881+00:00 [scheduled]>
2025-05-02 17:43:38,608 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>, <TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:43:35.409881+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:43:38,610 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:43:38,612 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:43:38,615 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:43:35.409881+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:43:38,617 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:43:35.409881+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:43:38,769 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:43:46,201 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:43:35.409881+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:43:52,592 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 17:43:52,593 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:43:35.409881+00:00', try_number=1, map_index=-1)
2025-05-02 17:43:52,600 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T20:43:35.409881+00:00, map_index=-1, run_start_date=2025-05-02 20:43:49.641560+00:00, run_end_date=2025-05-02 20:43:50.843044+00:00, run_duration=1.201484, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:43:38.603241+00:00, queued_by_job_id=12, pid=300489
2025-05-02 17:43:52,601 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:43:41.930732+00:00, run_end_date=2025-05-02 20:43:44.156986+00:00, run_duration=2.226254, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:43:38.603241+00:00, queued_by_job_id=12, pid=300439
2025-05-02 17:45:04,444 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:45:12,318 ERROR - Task deadlock (no runnable tasks); marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 20:43:37.857501+00:00. externally triggered: False> failed
2025-05-02 17:45:12,319 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 20:43:38.060665+00:00, run_end_date=2025-05-02 20:45:12.319376+00:00, run_duration=94.258711, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:45:12,323 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:45:12,326 ERROR - Task deadlock (no runnable tasks); marking run <DagRun fraud_detection_pipeline @ 2025-05-02 20:43:35.409881+00:00: manual__2025-05-02T20:43:35.409881+00:00, state:running, queued_at: 2025-05-02 20:43:35.458902+00:00. externally triggered: True> failed
2025-05-02 17:45:12,327 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-02 20:43:35.409881+00:00, run_id=manual__2025-05-02T20:43:35.409881+00:00, run_start_date=2025-05-02 20:43:38.061787+00:00, run_end_date=2025-05-02 20:45:12.327015+00:00, run_duration=94.265228, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:46:09,162 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:46:05.893617+00:00 [scheduled]>
2025-05-02 17:46:09,162 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:46:09,162 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:46:05.893617+00:00 [scheduled]>
2025-05-02 17:46:09,164 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:46:05.893617+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:46:09,164 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:46:05.893617+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:46:09,165 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:46:05.893617+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:46:09,584 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:46:05.893617+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:46:23,430 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:46:05.893617+00:00', try_number=1, map_index=-1)
2025-05-02 17:46:23,435 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T20:46:05.893617+00:00, map_index=-1, run_start_date=2025-05-02 20:46:17.458299+00:00, run_end_date=2025-05-02 20:46:21.579423+00:00, run_duration=4.121124, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:46:09.163538+00:00, queued_by_job_id=12, pid=301279
2025-05-02 17:46:24,458 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:46:25,162 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:46:25,163 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:46:25,164 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:46:25,166 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:46:25,167 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:46:25,167 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:46:25,301 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:46:31,350 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 17:46:31,484 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:46:28.458519+00:00, run_end_date=2025-05-02 20:46:29.485092+00:00, run_duration=1.026573, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:46:25.165017+00:00, queued_by_job_id=12, pid=301350
2025-05-02 17:50:04,793 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:50:33,901 ERROR - Task deadlock (no runnable tasks); marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 20:46:24.454346+00:00. externally triggered: False> failed
2025-05-02 17:50:33,902 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 20:46:24.619358+00:00, run_end_date=2025-05-02 20:50:33.902221+00:00, run_duration=249.282863, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:50:33,907 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:50:33,912 ERROR - Task deadlock (no runnable tasks); marking run <DagRun fraud_detection_pipeline @ 2025-05-02 20:46:05.893617+00:00: manual__2025-05-02T20:46:05.893617+00:00, state:running, queued_at: 2025-05-02 20:46:05.926089+00:00. externally triggered: True> failed
2025-05-02 17:50:33,912 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-02 20:46:05.893617+00:00, run_id=manual__2025-05-02T20:46:05.893617+00:00, run_start_date=2025-05-02 20:46:08.701952+00:00, run_end_date=2025-05-02 20:50:33.912681+00:00, run_duration=265.210729, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:51:25,890 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>
2025-05-02 17:51:25,892 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:51:25,894 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>
2025-05-02 17:51:25,901 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:51:25,903 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:51:24.963450+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:51:25,905 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:51:24.963450+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:26,037 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T20:51:24.963450+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:37,058 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T20:51:24.963450+00:00', try_number=1, map_index=-1)
2025-05-02 17:51:37,062 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T20:51:24.963450+00:00, map_index=-1, run_start_date=2025-05-02 20:51:29.584817+00:00, run_end_date=2025-05-02 20:51:34.367048+00:00, run_duration=4.782231, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:51:25.898337+00:00, queued_by_job_id=12, pid=303034
2025-05-02 17:51:38,264 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:51:39,042 INFO - 2 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>
2025-05-02 17:51:39,043 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:51:39,044 INFO - DAG fraud_detection_pipeline has 1/16 running and queued tasks
2025-05-02 17:51:39,044 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>
2025-05-02 17:51:39,048 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model scheduled__2025-05-01T00:00:00+00:00 [scheduled]>, <TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:51:39,049 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 17:51:39,049 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:39,050 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T20:51:24.963450+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 17:51:39,052 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T20:51:24.963450+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:39,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:49,433 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T20:51:24.963450+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:55,728 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 17:51:55,728 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T20:51:24.963450+00:00', try_number=1, map_index=-1)
2025-05-02 17:51:55,739 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:51:42.890156+00:00, run_end_date=2025-05-02 20:51:47.235414+00:00, run_duration=4.345258, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 20:51:39.045822+00:00, queued_by_job_id=12, pid=303124
2025-05-02 17:51:55,740 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=manual__2025-05-02T20:51:24.963450+00:00, map_index=-1, run_start_date=2025-05-02 20:51:53.410424+00:00, run_end_date=2025-05-02 20:51:54.411640+00:00, run_duration=1.001216, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 20:51:39.045822+00:00, queued_by_job_id=12, pid=303204
2025-05-02 17:51:56,187 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:51:56,188 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:51:56,189 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:51:56,192 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:51:56,193 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 17:51:56,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:51:56,336 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:52:02,592 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-02 17:52:02,734 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:51:59.888389+00:00, run_end_date=2025-05-02 20:52:01.084287+00:00, run_duration=1.195898, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 20:51:56.190914+00:00, queued_by_job_id=12, pid=303252
2025-05-02 17:55:05,207 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:56:54,713 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>
2025-05-02 17:56:54,714 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:56:54,714 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>
2025-05-02 17:56:54,717 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T20:51:24.963450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:56:54,719 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T20:51:24.963450+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 17:56:54,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T20:51:24.963450+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:56:54,847 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T20:51:24.963450+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:57:00,947 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T20:51:24.963450+00:00', try_number=2, map_index=-1)
2025-05-02 17:57:00,953 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=manual__2025-05-02T20:51:24.963450+00:00, map_index=-1, run_start_date=2025-05-02 20:56:58.012602+00:00, run_end_date=2025-05-02 20:56:59.499601+00:00, run_duration=1.486999, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 20:56:54.716108+00:00, queued_by_job_id=12, pid=304784
2025-05-02 17:57:01,626 INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-05-02 20:51:24.963450+00:00: manual__2025-05-02T20:51:24.963450+00:00, state:running, queued_at: 2025-05-02 20:51:25.001042+00:00. externally triggered: True> successful
2025-05-02 17:57:01,627 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-02 20:51:24.963450+00:00, run_id=manual__2025-05-02T20:51:24.963450+00:00, run_start_date=2025-05-02 20:51:25.367836+00:00, run_end_date=2025-05-02 20:57:01.627042+00:00, run_duration=336.259206, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:57:01,844 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:57:01,846 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 17:57:01,847 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>
2025-05-02 17:57:01,851 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.predict_new_transactions scheduled__2025-05-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 17:57:01,852 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 17:57:01,853 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:57:02,061 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'scheduled__2025-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 17:57:08,218 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='scheduled__2025-05-01T00:00:00+00:00', try_number=2, map_index=-1)
2025-05-02 17:57:08,222 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=scheduled__2025-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-02 20:57:05.215481+00:00, run_end_date=2025-05-02 20:57:06.672062+00:00, run_duration=1.456581, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 20:57:01.848922+00:00, queued_by_job_id=12, pid=304834
2025-05-02 17:57:09,243 INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-05-01 00:00:00+00:00: scheduled__2025-05-01T00:00:00+00:00, state:running, queued_at: 2025-05-02 20:51:38.246244+00:00. externally triggered: False> successful
2025-05-02 17:57:09,244 INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-05-01 00:00:00+00:00, run_id=scheduled__2025-05-01T00:00:00+00:00, run_start_date=2025-05-02 20:51:38.420327+00:00, run_end_date=2025-05-02 20:57:09.244087+00:00, run_duration=330.82376, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-01 00:00:00+00:00, data_interval_end=2025-05-02 00:00:00+00:00, dag_hash=ca1f07b6c3902a079d7f47edfa684aa1
2025-05-02 17:57:09,249 INFO - Setting next_dagrun for fraud_detection_pipeline to 2025-05-02 00:00:00+00:00, run_after=2025-05-03 00:00:00+00:00
2025-05-02 17:57:26,413 INFO - Exiting gracefully upon receiving signal 15
2025-05-02 17:57:27,250 INFO - Sending 15 to group 295856. PIDs of all processes in the group: []
2025-05-02 17:57:27,251 INFO - Sending the signal 15 to group 295856
2025-05-02 17:57:27,252 INFO - Sending the signal 15 to process 295856 as process group is missing.
2025-05-02 17:57:27,257 INFO - Sending 15 to group 295856. PIDs of all processes in the group: []
2025-05-02 17:57:27,258 INFO - Sending the signal 15 to group 295856
2025-05-02 17:57:27,259 INFO - Sending the signal 15 to process 295856 as process group is missing.
2025-05-02 17:57:27,260 INFO - Exited execute loop
2025-05-02 17:57:34,128 INFO - Loaded executor: SequentialExecutor
2025-05-02 17:57:34,555 INFO - Starting the scheduler
2025-05-02 17:57:34,556 INFO - Processing each file at most -1 times
2025-05-02 17:57:34,567 INFO - Launched DagFileProcessorManager with pid: 305215
2025-05-02 17:57:34,569 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 17:57:34,571 INFO - Configured default timezone UTC
2025-05-02 18:02:34,658 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 18:07:35,214 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 18:12:35,248 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 18:16:15,489 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>
2025-05-02 18:16:15,490 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 18:16:15,491 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>
2025-05-02 18:16:15,495 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 18:16:15,497 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T21:16:12.473966+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 18:16:15,497 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T21:16:12.473966+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:16:15,952 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T21:16:12.473966+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:16:25,154 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T21:16:12.473966+00:00', try_number=1, map_index=-1)
2025-05-02 18:16:25,162 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T21:16:12.473966+00:00, map_index=-1, run_start_date=2025-05-02 21:16:21.646581+00:00, run_end_date=2025-05-02 21:16:23.010074+00:00, run_duration=1.363493, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 21:16:15.492343+00:00, queued_by_job_id=28, pid=312062
2025-05-02 18:17:35,606 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-02 18:21:16,336 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:21:14.296182+00:00 [scheduled]>
2025-05-02 18:21:16,337 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 18:21:16,337 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:21:14.296182+00:00 [scheduled]>
2025-05-02 18:21:16,341 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:21:14.296182+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 18:21:16,342 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T21:21:14.296182+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 18:21:16,343 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T21:21:14.296182+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:16,553 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T21:21:14.296182+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:26,568 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T21:21:14.296182+00:00', try_number=1, map_index=-1)
2025-05-02 18:21:26,572 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T21:21:14.296182+00:00, map_index=-1, run_start_date=2025-05-02 21:21:20.132175+00:00, run_end_date=2025-05-02 21:21:24.424783+00:00, run_duration=4.292608, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 21:21:16.339071+00:00, queued_by_job_id=28, pid=313716
2025-05-02 18:21:27,685 INFO - 2 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T21:21:14.296182+00:00 [scheduled]>
2025-05-02 18:21:27,686 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 18:21:27,687 INFO - DAG fraud_detection_pipeline has 1/16 running and queued tasks
2025-05-02 18:21:27,687 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T21:21:14.296182+00:00 [scheduled]>
2025-05-02 18:21:27,690 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.train_model manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>, <TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T21:21:14.296182+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 18:21:27,691 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T21:16:12.473966+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-02 18:21:27,691 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T21:16:12.473966+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:27,692 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T21:21:14.296182+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 18:21:27,692 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T21:21:14.296182+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:27,905 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'train_model', 'manual__2025-05-02T21:16:12.473966+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:37,844 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T21:21:14.296182+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:44,685 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='train_model', run_id='manual__2025-05-02T21:16:12.473966+00:00', try_number=2, map_index=-1)
2025-05-02 18:21:44,685 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T21:21:14.296182+00:00', try_number=1, map_index=-1)
2025-05-02 18:21:44,694 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=manual__2025-05-02T21:21:14.296182+00:00, map_index=-1, run_start_date=2025-05-02 21:21:41.568179+00:00, run_end_date=2025-05-02 21:21:42.945301+00:00, run_duration=1.377122, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 21:21:27.688852+00:00, queued_by_job_id=28, pid=313883
2025-05-02 18:21:44,695 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=train_model, run_id=manual__2025-05-02T21:16:12.473966+00:00, map_index=-1, run_start_date=2025-05-02 21:21:31.523257+00:00, run_end_date=2025-05-02 21:21:35.571522+00:00, run_duration=4.048265, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-02 21:21:27.688852+00:00, queued_by_job_id=28, pid=313811
2025-05-02 18:21:45,780 INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>
2025-05-02 18:21:45,781 INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
2025-05-02 18:21:45,782 INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>
2025-05-02 18:21:45,786 INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.predict_new_transactions manual__2025-05-02T21:16:12.473966+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-02 18:21:45,787 INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T21:16:12.473966+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-02 18:21:45,788 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T21:16:12.473966+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:46,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'predict_new_transactions', 'manual__2025-05-02T21:16:12.473966+00:00', '--local', '--subdir', 'DAGS_FOLDER/fraud_detection_dag.py']
2025-05-02 18:21:53,687 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='predict_new_transactions', run_id='manual__2025-05-02T21:16:12.473966+00:00', try_number=1, map_index=-1)
2025-05-02 18:21:53,693 INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=predict_new_transactions, run_id=manual__2025-05-02T21:16:12.473966+00:00, map_index=-1, run_start_date=2025-05-02 21:21:49.770796+00:00, run_end_date=2025-05-02 21:21:51.312870+00:00, run_duration=1.542074, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-02 21:21:45.784125+00:00, queued_by_job_id=28, pid=313945
2025-05-02 18:22:18,510 INFO - Exiting gracefully upon receiving signal 15
2025-05-02 18:22:19,241 INFO - Sending 15 to group 305215. PIDs of all processes in the group: []
2025-05-02 18:22:19,242 INFO - Sending the signal 15 to group 305215
2025-05-02 18:22:19,243 INFO - Sending the signal 15 to process 305215 as process group is missing.
2025-05-02 18:22:19,247 INFO - Sending 15 to group 305215. PIDs of all processes in the group: []
2025-05-02 18:22:19,248 INFO - Sending the signal 15 to group 305215
2025-05-02 18:22:19,249 INFO - Sending the signal 15 to process 305215 as process group is missing.
2025-05-02 18:22:19,250 INFO - Exited execute loop
2025-05-05 07:28:45,427 INFO - Loaded executor: SequentialExecutor
2025-05-05 07:28:46,804 INFO - Starting the scheduler
2025-05-05 07:28:46,807 INFO - Processing each file at most -1 times
2025-05-05 07:28:46,828 INFO - Launched DagFileProcessorManager with pid: 34703
2025-05-05 07:28:46,830 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 07:28:46,834 INFO - Configured default timezone UTC
2025-05-05 07:33:46,973 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 07:38:47,045 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 07:43:47,113 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 07:45:50,762 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 07:45:51,887 INFO - Sending 15 to group 34703. PIDs of all processes in the group: [34703]
2025-05-05 07:45:51,888 INFO - Sending the signal 15 to group 34703
2025-05-05 07:45:53,726 INFO - Process psutil.Process(pid=34703, status='terminated', exitcode=0, started='07:28:46') (34703) terminated with exit code 0
2025-05-05 07:45:53,780 INFO - Sending 15 to group 34703. PIDs of all processes in the group: []
2025-05-05 07:45:53,781 INFO - Sending the signal 15 to group 34703
2025-05-05 07:45:53,782 INFO - Sending the signal 15 to process 34703 as process group is missing.
2025-05-05 07:45:53,783 INFO - Exited execute loop
2025-05-05 07:47:13,931 ERROR - Failed to import plugin /home/pyshell/airflow/plugins/custom_operators.py
Traceback (most recent call last):
  File "/home/pyshell/airflow_env/lib/python3.12/site-packages/airflow/plugins_manager.py", line 298, in load_plugins_from_plugin_directory
    loader.exec_module(mod)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/pyshell/airflow/plugins/custom_operators.py", line 3, in <module>
    from schemas.transaction_schema import get_validator
ModuleNotFoundError: No module named 'schemas'
2025-05-05 07:47:14,334 INFO - Loaded executor: SequentialExecutor
2025-05-05 07:47:14,682 INFO - Starting the scheduler
2025-05-05 07:47:14,684 INFO - Processing each file at most -1 times
2025-05-05 07:47:14,711 INFO - Launched DagFileProcessorManager with pid: 43923
2025-05-05 07:47:14,712 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 07:47:14,715 INFO - Configured default timezone UTC
2025-05-05 07:48:37,877 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 07:48:38,112 INFO - Sending 15 to group 43923. PIDs of all processes in the group: []
2025-05-05 07:48:38,112 INFO - Sending the signal 15 to group 43923
2025-05-05 07:48:38,113 INFO - Sending the signal 15 to process 43923 as process group is missing.
2025-05-05 07:48:38,116 INFO - Sending 15 to group 43923. PIDs of all processes in the group: []
2025-05-05 07:48:38,117 INFO - Sending the signal 15 to group 43923
2025-05-05 07:48:38,119 INFO - Sending the signal 15 to process 43923 as process group is missing.
2025-05-05 07:48:38,120 INFO - Exited execute loop
2025-05-05 08:19:40,906 INFO - Loaded executor: SequentialExecutor
2025-05-05 08:19:41,199 INFO - Starting the scheduler
2025-05-05 08:19:41,200 INFO - Processing each file at most -1 times
2025-05-05 08:19:41,208 INFO - Launched DagFileProcessorManager with pid: 58949
2025-05-05 08:19:41,210 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:19:41,212 INFO - Configured default timezone UTC
2025-05-05 08:22:45,186 INFO - Setting next_dagrun for bank_transactions_ml_append to 2025-05-05 06:00:00+00:00, run_after=2025-05-05 12:00:00+00:00
2025-05-05 08:22:47,053 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.generate_fake_data scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:22:47,055 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:22:47,056 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.generate_fake_data scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:22:47,062 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.generate_fake_data scheduled__2025-05-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:22:47,064 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='generate_fake_data', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-05-05 08:22:47,065 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'generate_fake_data', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:22:47,384 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'generate_fake_data', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:22:59,032 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='generate_fake_data', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:22:59,039 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=generate_fake_data, run_id=scheduled__2025-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:22:54.091033+00:00, run_end_date=2025-05-05 11:22:56.781677+00:00, run_duration=2.690644, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-05-05 11:22:47.059081+00:00, queued_by_job_id=36, pid=60091
2025-05-05 08:23:00,200 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.extract scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:23:00,201 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:23:00,203 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.extract scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:23:00,209 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.extract scheduled__2025-05-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:23:00,212 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='extract', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-05-05 08:23:00,214 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'extract', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:00,703 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'extract', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:09,622 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='extract', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:23:09,628 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=extract, run_id=scheduled__2025-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:23:04.952389+00:00, run_end_date=2025-05-05 11:23:07.480976+00:00, run_duration=2.528587, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-05-05 11:23:00.205330+00:00, queued_by_job_id=36, pid=60157
2025-05-05 08:23:11,418 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.transform scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:23:11,419 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:23:11,419 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.transform scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:23:11,420 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.transform scheduled__2025-05-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:23:11,421 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='transform', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-05-05 08:23:11,421 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'transform', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:11,807 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'transform', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:19,997 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='transform', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:23:20,002 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=transform, run_id=scheduled__2025-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:23:16.023778+00:00, run_end_date=2025-05-05 11:23:18.084586+00:00, run_duration=2.060808, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-05-05 11:23:11.420070+00:00, queued_by_job_id=36, pid=60241
2025-05-05 08:23:20,584 INFO - 3 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.load scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.data_quality scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.detect_anomalies scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:23:20,585 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:23:20,585 INFO - DAG bank_transactions_ml_append has 1/16 running and queued tasks
2025-05-05 08:23:20,586 INFO - DAG bank_transactions_ml_append has 2/16 running and queued tasks
2025-05-05 08:23:20,588 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.load scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.data_quality scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.detect_anomalies scheduled__2025-05-05T00:00:00+00:00 [scheduled]>
2025-05-05 08:23:20,592 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.load scheduled__2025-05-05T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_ml_append.data_quality scheduled__2025-05-05T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_ml_append.detect_anomalies scheduled__2025-05-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:23:20,593 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='load', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:23:20,593 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'load', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:20,594 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='data_quality', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:23:20,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'data_quality', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:20,595 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='detect_anomalies', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:23:20,595 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'detect_anomalies', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:20,795 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'load', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:27,838 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'data_quality', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:34,652 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'detect_anomalies', 'scheduled__2025-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:42,261 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='load', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:23:42,262 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='data_quality', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:23:42,262 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='detect_anomalies', run_id='scheduled__2025-05-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:23:42,268 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=data_quality, run_id=scheduled__2025-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:23:31.392709+00:00, run_end_date=2025-05-05 11:23:32.694142+00:00, run_duration=1.301433, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 11:23:20.589940+00:00, queued_by_job_id=36, pid=60351
2025-05-05 08:23:42,269 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=detect_anomalies, run_id=scheduled__2025-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:23:38.916530+00:00, run_end_date=2025-05-05 11:23:40.486149+00:00, run_duration=1.569619, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 11:23:20.589940+00:00, queued_by_job_id=36, pid=60393
2025-05-05 08:23:42,269 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=load, run_id=scheduled__2025-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:23:24.392015+00:00, run_end_date=2025-05-05 11:23:25.630861+00:00, run_duration=1.238846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 11:23:20.589940+00:00, queued_by_job_id=36, pid=60297
2025-05-05 08:23:45,754 INFO - Marking run <DagRun bank_transactions_ml_append @ 2025-05-05 00:00:00+00:00: scheduled__2025-05-05T00:00:00+00:00, state:running, queued_at: 2025-05-05 11:22:45.158978+00:00. externally triggered: False> successful
2025-05-05 08:23:45,755 INFO - DagRun Finished: dag_id=bank_transactions_ml_append, execution_date=2025-05-05 00:00:00+00:00, run_id=scheduled__2025-05-05T00:00:00+00:00, run_start_date=2025-05-05 11:22:45.462103+00:00, run_end_date=2025-05-05 11:23:45.755148+00:00, run_duration=60.293045, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-05 00:00:00+00:00, data_interval_end=2025-05-05 06:00:00+00:00, dag_hash=633de723d94ca85f7f154cb5a97ec3e6
2025-05-05 08:23:45,758 INFO - Setting next_dagrun for bank_transactions_ml_append to 2025-05-05 06:00:00+00:00, run_after=2025-05-05 12:00:00+00:00
2025-05-05 08:23:46,014 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.generate_fake_data manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:23:46,015 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:23:46,016 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.generate_fake_data manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:23:46,019 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.generate_fake_data manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:23:46,020 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='generate_fake_data', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-05-05 08:23:46,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'generate_fake_data', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:46,362 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'generate_fake_data', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:53,380 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='generate_fake_data', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1)
2025-05-05 08:23:53,384 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=generate_fake_data, run_id=manual__2025-05-05T11:23:26.854663+00:00, map_index=-1, run_start_date=2025-05-05 11:23:49.747219+00:00, run_end_date=2025-05-05 11:23:51.158080+00:00, run_duration=1.410861, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-05-05 11:23:46.017868+00:00, queued_by_job_id=36, pid=60481
2025-05-05 08:23:54,223 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.extract manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:23:54,224 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:23:54,225 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.extract manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:23:54,227 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.extract manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:23:54,228 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='extract', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-05-05 08:23:54,229 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'extract', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:23:54,584 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'extract', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:01,268 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='extract', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1)
2025-05-05 08:24:01,272 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=extract, run_id=manual__2025-05-05T11:23:26.854663+00:00, map_index=-1, run_start_date=2025-05-05 11:23:57.779007+00:00, run_end_date=2025-05-05 11:23:59.328085+00:00, run_duration=1.549078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-05-05 11:23:54.226712+00:00, queued_by_job_id=36, pid=60547
2025-05-05 08:24:01,900 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.transform manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:24:01,901 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:24:01,901 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.transform manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:24:01,903 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.transform manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:24:01,904 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='transform', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-05-05 08:24:01,904 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'transform', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:02,233 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'transform', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:08,987 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='transform', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1)
2025-05-05 08:24:08,990 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=transform, run_id=manual__2025-05-05T11:23:26.854663+00:00, map_index=-1, run_start_date=2025-05-05 11:24:05.581168+00:00, run_end_date=2025-05-05 11:24:07.302298+00:00, run_duration=1.72113, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-05-05 11:24:01.902408+00:00, queued_by_job_id=36, pid=60614
2025-05-05 08:24:09,938 INFO - 3 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.load manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.data_quality manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.detect_anomalies manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:24:09,939 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 08:24:09,941 INFO - DAG bank_transactions_ml_append has 1/16 running and queued tasks
2025-05-05 08:24:09,942 INFO - DAG bank_transactions_ml_append has 2/16 running and queued tasks
2025-05-05 08:24:09,943 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.load manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.data_quality manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.detect_anomalies manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>
2025-05-05 08:24:09,947 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.load manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>, <TaskInstance: bank_transactions_ml_append.data_quality manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>, <TaskInstance: bank_transactions_ml_append.detect_anomalies manual__2025-05-05T11:23:26.854663+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:24:09,948 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='load', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:24:09,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'load', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:09,949 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='data_quality', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:24:09,950 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'data_quality', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:09,950 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='detect_anomalies', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:24:09,951 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'detect_anomalies', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:10,153 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'load', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:17,398 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'data_quality', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:22,778 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'detect_anomalies', 'manual__2025-05-05T11:23:26.854663+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 08:24:28,863 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='load', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1)
2025-05-05 08:24:28,864 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='data_quality', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1)
2025-05-05 08:24:28,864 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='detect_anomalies', run_id='manual__2025-05-05T11:23:26.854663+00:00', try_number=1, map_index=-1)
2025-05-05 08:24:28,869 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=data_quality, run_id=manual__2025-05-05T11:23:26.854663+00:00, map_index=-1, run_start_date=2025-05-05 11:24:20.373582+00:00, run_end_date=2025-05-05 11:24:21.407913+00:00, run_duration=1.034331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 11:24:09.944881+00:00, queued_by_job_id=36, pid=60740
2025-05-05 08:24:28,870 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=detect_anomalies, run_id=manual__2025-05-05T11:23:26.854663+00:00, map_index=-1, run_start_date=2025-05-05 11:24:25.939629+00:00, run_end_date=2025-05-05 11:24:27.194827+00:00, run_duration=1.255198, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 11:24:09.944881+00:00, queued_by_job_id=36, pid=60792
2025-05-05 08:24:28,871 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=load, run_id=manual__2025-05-05T11:23:26.854663+00:00, map_index=-1, run_start_date=2025-05-05 11:24:13.240434+00:00, run_end_date=2025-05-05 11:24:15.204838+00:00, run_duration=1.964404, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 11:24:09.944881+00:00, queued_by_job_id=36, pid=60680
2025-05-05 08:24:32,431 INFO - Marking run <DagRun bank_transactions_ml_append @ 2025-05-05 11:23:26.854663+00:00: manual__2025-05-05T11:23:26.854663+00:00, state:running, queued_at: 2025-05-05 11:23:27.134748+00:00. externally triggered: True> successful
2025-05-05 08:24:32,431 INFO - DagRun Finished: dag_id=bank_transactions_ml_append, execution_date=2025-05-05 11:23:26.854663+00:00, run_id=manual__2025-05-05T11:23:26.854663+00:00, run_start_date=2025-05-05 11:23:43.216775+00:00, run_end_date=2025-05-05 11:24:32.431770+00:00, run_duration=49.214995, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-05-05 05:23:26.854663+00:00, data_interval_end=2025-05-05 11:23:26.854663+00:00, dag_hash=633de723d94ca85f7f154cb5a97ec3e6
2025-05-05 08:24:41,257 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:29:36,038 INFO - Setting next_dagrun for bank_transactions_validation to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 08:29:36,991 INFO - 12 tasks up for execution:
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_05_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_08_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_12_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_11_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_02_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_03_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_07_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_10_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_06_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_01_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_09_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_04_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 08:29:36,992 INFO - DAG bank_transactions_validation has 0/16 running and queued tasks
2025-05-05 08:29:36,992 INFO - DAG bank_transactions_validation has 1/16 running and queued tasks
2025-05-05 08:29:36,992 INFO - DAG bank_transactions_validation has 2/16 running and queued tasks
2025-05-05 08:29:36,993 INFO - DAG bank_transactions_validation has 3/16 running and queued tasks
2025-05-05 08:29:36,993 INFO - DAG bank_transactions_validation has 4/16 running and queued tasks
2025-05-05 08:29:36,994 INFO - DAG bank_transactions_validation has 5/16 running and queued tasks
2025-05-05 08:29:36,994 INFO - DAG bank_transactions_validation has 6/16 running and queued tasks
2025-05-05 08:29:36,995 INFO - DAG bank_transactions_validation has 7/16 running and queued tasks
2025-05-05 08:29:36,995 INFO - DAG bank_transactions_validation has 8/16 running and queued tasks
2025-05-05 08:29:36,996 INFO - DAG bank_transactions_validation has 9/16 running and queued tasks
2025-05-05 08:29:36,997 INFO - DAG bank_transactions_validation has 10/16 running and queued tasks
2025-05-05 08:29:36,997 INFO - DAG bank_transactions_validation has 11/16 running and queued tasks
2025-05-05 08:29:36,998 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_05_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_08_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_12_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_11_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_02_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_03_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_07_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_10_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_06_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_01_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_09_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_04_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 08:29:37,000 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_validation.validate_transacoes_2023_05_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_08_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_12_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_11_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_02_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_03_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_07_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_10_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_06_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_01_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_09_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_04_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:29:37,001 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_05_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,001 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_05_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,002 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_08_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,002 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_08_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,002 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_12_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,003 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_12_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,003 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_11_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,003 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_11_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,004 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_02_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,004 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_02_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,005 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_03_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,006 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_03_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,006 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_07_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,007 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_07_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,007 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_10_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,008 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_10_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,008 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_06_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,009 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_06_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,010 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_01_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,010 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_01_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,011 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_09_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,011 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_09_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,012 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_04_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:29:37,013 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_04_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:37,309 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_05_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:45,682 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_08_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:29:53,755 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_12_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:00,313 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_11_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:10,451 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_02_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:19,679 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_03_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:28,821 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_07_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:37,211 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_10_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:46,947 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_06_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:30:57,032 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_01_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:05,823 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_09_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:13,148 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_04_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:21,364 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_05_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,365 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_08_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,365 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_12_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,366 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_11_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,366 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_02_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,367 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_03_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,367 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_07_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,368 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_10_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,368 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_06_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,369 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_01_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,369 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_09_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,370 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_04_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:31:21,394 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_01_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:31:01.354367+00:00, run_end_date=2025-05-05 11:31:03.406248+00:00, run_duration=2.051881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=58, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63369
2025-05-05 08:31:21,395 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_02_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:30:13.011080+00:00, run_end_date=2025-05-05 11:30:16.197548+00:00, run_duration=3.186468, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=53, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63009
2025-05-05 08:31:21,395 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_03_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:30:23.195713+00:00, run_end_date=2025-05-05 11:30:26.500166+00:00, run_duration=3.304453, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=54, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63106
2025-05-05 08:31:21,396 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_04_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:31:17.666058+00:00, run_end_date=2025-05-05 11:31:19.646025+00:00, run_duration=1.979967, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=60, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63482
2025-05-05 08:31:21,397 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_05_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:29:41.007566+00:00, run_end_date=2025-05-05 11:29:43.190573+00:00, run_duration=2.183007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=49, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=62791
2025-05-05 08:31:21,397 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_06_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:30:50.225436+00:00, run_end_date=2025-05-05 11:30:54.020288+00:00, run_duration=3.794852, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=57, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63296
2025-05-05 08:31:21,398 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_07_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:30:31.331786+00:00, run_end_date=2025-05-05 11:30:33.789914+00:00, run_duration=2.458128, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=55, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63167
2025-05-05 08:31:21,399 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_08_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:29:48.221128+00:00, run_end_date=2025-05-05 11:29:50.212652+00:00, run_duration=1.991524, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=50, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=62832
2025-05-05 08:31:21,399 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_09_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:31:08.350060+00:00, run_end_date=2025-05-05 11:31:10.927955+00:00, run_duration=2.577895, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=59, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63417
2025-05-05 08:31:21,400 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_10_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:30:40.694248+00:00, run_end_date=2025-05-05 11:30:43.621529+00:00, run_duration=2.927281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=56, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=63221
2025-05-05 08:31:21,401 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_11_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:30:02.641356+00:00, run_end_date=2025-05-05 11:30:07.682090+00:00, run_duration=5.040734, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=52, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=62929
2025-05-05 08:31:21,402 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_12_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:29:56.112360+00:00, run_end_date=2025-05-05 11:29:57.552812+00:00, run_duration=1.440452, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=51, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:29:36.999205+00:00, queued_by_job_id=36, pid=62879
2025-05-05 08:31:21,414 ERROR - DagFileProcessorManager (PID=58949) last sent a heartbeat 105.40 seconds ago! Restarting it
2025-05-05 08:31:21,425 INFO - Sending 15 to group 58949. PIDs of all processes in the group: [58949]
2025-05-05 08:31:21,425 INFO - Sending the signal 15 to group 58949
2025-05-05 08:31:22,160 INFO - Process psutil.Process(pid=58949, status='terminated', exitcode=0, started='08:19:41') (58949) terminated with exit code 0
2025-05-05 08:31:22,168 INFO - Launched DagFileProcessorManager with pid: 63501
2025-05-05 08:31:22,177 INFO - Configured default timezone UTC
2025-05-05 08:31:22,571 INFO - Heartbeat recovered after 110.89 seconds
2025-05-05 08:31:22,602 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:31:23,779 INFO - 16 tasks up for execution:
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_05_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_08_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_12_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_11_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_02_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_03_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_07_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_10_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_06_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_01_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_09_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_04_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_05_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_08_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_12_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_11_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 08:31:23,780 INFO - DAG bank_transactions_validation has 0/16 running and queued tasks
2025-05-05 08:31:23,781 INFO - DAG bank_transactions_validation has 1/16 running and queued tasks
2025-05-05 08:31:23,781 INFO - DAG bank_transactions_validation has 2/16 running and queued tasks
2025-05-05 08:31:23,782 INFO - DAG bank_transactions_validation has 3/16 running and queued tasks
2025-05-05 08:31:23,782 INFO - DAG bank_transactions_validation has 4/16 running and queued tasks
2025-05-05 08:31:23,783 INFO - DAG bank_transactions_validation has 5/16 running and queued tasks
2025-05-05 08:31:23,784 INFO - DAG bank_transactions_validation has 6/16 running and queued tasks
2025-05-05 08:31:23,784 INFO - DAG bank_transactions_validation has 7/16 running and queued tasks
2025-05-05 08:31:23,785 INFO - DAG bank_transactions_validation has 8/16 running and queued tasks
2025-05-05 08:31:23,785 INFO - DAG bank_transactions_validation has 9/16 running and queued tasks
2025-05-05 08:31:23,786 INFO - DAG bank_transactions_validation has 10/16 running and queued tasks
2025-05-05 08:31:23,787 INFO - DAG bank_transactions_validation has 11/16 running and queued tasks
2025-05-05 08:31:23,787 INFO - DAG bank_transactions_validation has 12/16 running and queued tasks
2025-05-05 08:31:23,788 INFO - DAG bank_transactions_validation has 13/16 running and queued tasks
2025-05-05 08:31:23,789 INFO - DAG bank_transactions_validation has 14/16 running and queued tasks
2025-05-05 08:31:23,789 INFO - DAG bank_transactions_validation has 15/16 running and queued tasks
2025-05-05 08:31:23,790 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_05_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_08_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_12_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_11_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_02_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_03_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_07_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_10_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_06_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_01_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_09_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.validate_transacoes_2023_04_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_05_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_08_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_12_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_11_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 08:31:23,793 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_validation.validate_transacoes_2023_05_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_08_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_12_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_11_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_02_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_03_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_07_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_10_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_06_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_01_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_09_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.validate_transacoes_2023_04_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_05_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_08_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_12_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_11_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:31:23,794 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_05_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,794 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_05_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,794 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_08_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_08_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,795 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_12_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_12_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,796 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_11_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,796 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_11_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,797 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_02_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,797 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_02_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,797 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_03_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,798 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_03_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,798 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_07_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,798 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_07_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,799 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_10_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,799 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_10_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,799 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_06_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,800 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_06_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,800 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_01_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,800 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_01_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,801 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_09_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,801 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_09_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,801 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_04_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 08:31:23,801 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_04_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,802 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_05_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:31:23,802 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_05_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,803 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_08_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:31:23,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_08_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,804 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_12_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:31:23,804 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_12_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:23,805 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_11_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:31:23,805 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_11_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:24,211 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_05_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:31,742 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_08_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:38,825 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_12_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:46,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_11_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:53,286 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_02_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:31:59,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_03_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:06,293 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_07_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:13,652 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_10_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:20,485 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_06_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:26,965 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_01_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:33,579 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_09_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:40,738 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'validate_transacoes_2023_04_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:47,842 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_05_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:53,376 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_08_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:32:59,072 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_12_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:05,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_11_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:11,144 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_05_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,145 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_08_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,145 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_12_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,145 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_11_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,146 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_02_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,146 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_03_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,147 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_07_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,147 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_10_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,147 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_06_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,148 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_01_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,148 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_09_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,149 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='validate_transacoes_2023_04_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,149 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_05_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,149 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_08_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,150 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_12_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,150 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_11_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:33:11,161 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_01_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:29.546681+00:00, run_end_date=2025-05-05 11:32:31.691326+00:00, run_duration=2.144645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=70, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63956
2025-05-05 08:33:11,162 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_02_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:31:55.801425+00:00, run_end_date=2025-05-05 11:31:58.090960+00:00, run_duration=2.289535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=65, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63741
2025-05-05 08:33:11,163 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_03_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:02.318060+00:00, run_end_date=2025-05-05 11:32:04.402242+00:00, run_duration=2.084182, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=66, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63785
2025-05-05 08:33:11,163 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_04_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:43.161196+00:00, run_end_date=2025-05-05 11:32:45.150209+00:00, run_duration=1.989013, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=72, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=64057
2025-05-05 08:33:11,164 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_05_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:31:26.734738+00:00, run_end_date=2025-05-05 11:31:29.707945+00:00, run_duration=2.973207, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=61, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63535
2025-05-05 08:33:11,165 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_06_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:22.936468+00:00, run_end_date=2025-05-05 11:32:25.115765+00:00, run_duration=2.179297, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=69, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63908
2025-05-05 08:33:11,165 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_07_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:08.890364+00:00, run_end_date=2025-05-05 11:32:11.680078+00:00, run_duration=2.789714, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=67, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63824
2025-05-05 08:33:11,166 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_08_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:31:34.727567+00:00, run_end_date=2025-05-05 11:31:36.873504+00:00, run_duration=2.145937, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=62, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63578
2025-05-05 08:33:11,167 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_09_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:36.015684+00:00, run_end_date=2025-05-05 11:32:38.523292+00:00, run_duration=2.507608, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=71, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=64004
2025-05-05 08:33:11,168 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_10_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:32:16.089838+00:00, run_end_date=2025-05-05 11:32:18.559550+00:00, run_duration=2.469712, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=68, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63873
2025-05-05 08:33:11,169 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_11_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:31:49.152727+00:00, run_end_date=2025-05-05 11:31:51.387294+00:00, run_duration=2.234567, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=64, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63696
2025-05-05 08:33:11,170 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=validate_transacoes_2023_12_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:31:41.786006+00:00, run_end_date=2025-05-05 11:31:44.310144+00:00, run_duration=2.524138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=63, pool=default_pool, queue=default, priority_weight=2, operator=JsonValidatorOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=63632
2025-05-05 08:33:11,170 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_05_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:32:50.315284+00:00, run_end_date=2025-05-05 11:32:51.768527+00:00, run_duration=1.453243, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=73, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=64104
2025-05-05 08:33:11,171 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_08_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:32:55.779012+00:00, run_end_date=2025-05-05 11:32:57.545609+00:00, run_duration=1.766597, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=74, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=64146
2025-05-05 08:33:11,172 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_11_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:07.742844+00:00, run_end_date=2025-05-05 11:33:09.563951+00:00, run_duration=1.821107, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=76, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=64246
2025-05-05 08:33:11,172 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_12_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:01.669096+00:00, run_end_date=2025-05-05 11:33:03.725533+00:00, run_duration=2.056437, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=75, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:31:23.791081+00:00, queued_by_job_id=36, pid=64192
2025-05-05 08:33:11,184 ERROR - DagFileProcessorManager (PID=63501) last sent a heartbeat 108.07 seconds ago! Restarting it
2025-05-05 08:33:11,193 INFO - Sending 15 to group 63501. PIDs of all processes in the group: [63501]
2025-05-05 08:33:11,194 INFO - Sending the signal 15 to group 63501
2025-05-05 08:33:11,326 INFO - Process psutil.Process(pid=63501, status='terminated', exitcode=0, started='08:31:21') (63501) terminated with exit code 0
2025-05-05 08:33:11,332 INFO - Launched DagFileProcessorManager with pid: 64272
2025-05-05 08:33:11,338 INFO - Configured default timezone UTC
2025-05-05 08:33:11,618 INFO - Heartbeat recovered after 109.43 seconds
2025-05-05 08:33:12,401 INFO - 16 tasks up for execution:
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_02_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_03_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_07_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_10_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_06_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_01_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_09_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_04_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_05_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_08_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_12_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_11_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_02_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_03_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_07_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_10_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
2025-05-05 08:33:12,402 INFO - DAG bank_transactions_validation has 0/16 running and queued tasks
2025-05-05 08:33:12,403 INFO - DAG bank_transactions_validation has 1/16 running and queued tasks
2025-05-05 08:33:12,404 INFO - DAG bank_transactions_validation has 2/16 running and queued tasks
2025-05-05 08:33:12,404 INFO - DAG bank_transactions_validation has 3/16 running and queued tasks
2025-05-05 08:33:12,405 INFO - DAG bank_transactions_validation has 4/16 running and queued tasks
2025-05-05 08:33:12,405 INFO - DAG bank_transactions_validation has 5/16 running and queued tasks
2025-05-05 08:33:12,406 INFO - DAG bank_transactions_validation has 6/16 running and queued tasks
2025-05-05 08:33:12,406 INFO - DAG bank_transactions_validation has 7/16 running and queued tasks
2025-05-05 08:33:12,406 INFO - DAG bank_transactions_validation has 8/16 running and queued tasks
2025-05-05 08:33:12,407 INFO - DAG bank_transactions_validation has 9/16 running and queued tasks
2025-05-05 08:33:12,407 INFO - DAG bank_transactions_validation has 10/16 running and queued tasks
2025-05-05 08:33:12,407 INFO - DAG bank_transactions_validation has 11/16 running and queued tasks
2025-05-05 08:33:12,408 INFO - DAG bank_transactions_validation has 12/16 running and queued tasks
2025-05-05 08:33:12,408 INFO - DAG bank_transactions_validation has 13/16 running and queued tasks
2025-05-05 08:33:12,408 INFO - DAG bank_transactions_validation has 14/16 running and queued tasks
2025-05-05 08:33:12,409 INFO - DAG bank_transactions_validation has 15/16 running and queued tasks
2025-05-05 08:33:12,409 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_02_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_03_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_07_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_10_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_06_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_01_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_09_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_04_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_05_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_08_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_12_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_11_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_02_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_03_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_07_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_10_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
2025-05-05 08:33:12,412 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_02_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_03_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_07_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_10_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_06_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_01_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_09_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_04_json scheduled__2025-05-04T00:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_05_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_08_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_12_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_11_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_02_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_03_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_07_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_10_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:33:12,413 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_02_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,413 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_02_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,413 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_03_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,414 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_03_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,414 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_07_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,414 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_07_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,415 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_10_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,415 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_10_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,416 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_06_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,416 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_06_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,417 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_01_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,417 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_01_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,417 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_09_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,418 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_09_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,419 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_04_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,419 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_04_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,420 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_05_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_05_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,421 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_08_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,421 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_08_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,421 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_12_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,422 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_12_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,422 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_11_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,422 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_11_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,423 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_02_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,423 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_02_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,423 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_03_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_03_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,424 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_07_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_07_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,425 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_10_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:33:12,425 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_10_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:12,796 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_02_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:18,580 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_03_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:23,973 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_07_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:29,594 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_10_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:35,339 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_06_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:41,398 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_01_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:47,649 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_09_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:33:54,387 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_04_json', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:00,708 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_05_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:09,109 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_08_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:16,638 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_12_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:24,537 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_11_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:31,379 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_02_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:37,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_03_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:43,148 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_07_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:49,556 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_10_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:56,158 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_02_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,159 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_03_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,159 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_07_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,160 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_10_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,160 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_06_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,160 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_01_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,161 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_09_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,161 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_04_json', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,162 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_05_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,162 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_08_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,163 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_12_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,163 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_11_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,164 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_02_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,164 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_03_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,165 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_07_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,165 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_10_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:34:56,171 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_02_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:33.849755+00:00, run_end_date=2025-05-05 11:34:35.276201+00:00, run_duration=1.426446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=89, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64892
2025-05-05 08:34:56,172 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_03_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:39.769064+00:00, run_end_date=2025-05-05 11:34:41.237333+00:00, run_duration=1.468269, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=90, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64935
2025-05-05 08:34:56,173 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_05_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:04.128265+00:00, run_end_date=2025-05-05 11:34:06.490672+00:00, run_duration=2.362407, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=85, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64663
2025-05-05 08:34:56,173 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_07_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:45.824629+00:00, run_end_date=2025-05-05 11:34:47.397840+00:00, run_duration=1.573211, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=91, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64974
2025-05-05 08:34:56,174 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_08_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:12.280616+00:00, run_end_date=2025-05-05 11:34:14.332269+00:00, run_duration=2.051653, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=86, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64716
2025-05-05 08:34:56,174 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_10_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:52.948584+00:00, run_end_date=2025-05-05 11:34:54.575341+00:00, run_duration=1.626757, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=65017
2025-05-05 08:34:56,175 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_11_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:27.154211+00:00, run_end_date=2025-05-05 11:34:29.471597+00:00, run_duration=2.317386, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=88, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64827
2025-05-05 08:34:56,175 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_12_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:34:20.007851+00:00, run_end_date=2025-05-05 11:34:22.108707+00:00, run_duration=2.100856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=87, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64772
2025-05-05 08:34:56,176 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_01_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:44.313994+00:00, run_end_date=2025-05-05 11:33:45.796446+00:00, run_duration=1.482452, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=82, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64521
2025-05-05 08:34:56,176 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_02_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:15.393927+00:00, run_end_date=2025-05-05 11:33:17.039274+00:00, run_duration=1.645347, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=77, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64307
2025-05-05 08:34:56,177 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_03_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:21.213057+00:00, run_end_date=2025-05-05 11:33:22.621351+00:00, run_duration=1.408294, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=78, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64354
2025-05-05 08:34:56,178 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_04_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:57.007588+00:00, run_end_date=2025-05-05 11:33:58.608632+00:00, run_duration=1.601044, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=84, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64621
2025-05-05 08:34:56,178 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_06_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:37.848105+00:00, run_end_date=2025-05-05 11:33:39.513763+00:00, run_duration=1.665658, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=81, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64483
2025-05-05 08:34:56,180 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_07_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:26.328197+00:00, run_end_date=2025-05-05 11:33:27.889386+00:00, run_duration=1.561189, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=79, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64396
2025-05-05 08:34:56,181 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_09_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:50.554229+00:00, run_end_date=2025-05-05 11:33:52.390523+00:00, run_duration=1.836294, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=83, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64574
2025-05-05 08:34:56,181 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_10_json, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 11:33:32.109899+00:00, run_end_date=2025-05-05 11:33:33.610873+00:00, run_duration=1.500974, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=80, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:33:12.410551+00:00, queued_by_job_id=36, pid=64443
2025-05-05 08:34:56,192 ERROR - DagFileProcessorManager (PID=64272) last sent a heartbeat 104.05 seconds ago! Restarting it
2025-05-05 08:34:56,207 INFO - Sending 15 to group 64272. PIDs of all processes in the group: [64272]
2025-05-05 08:34:56,207 INFO - Sending the signal 15 to group 64272
2025-05-05 08:34:56,340 INFO - Process psutil.Process(pid=64272, status='terminated', exitcode=0, started='08:33:11') (64272) terminated with exit code 0
2025-05-05 08:34:56,345 INFO - Launched DagFileProcessorManager with pid: 65037
2025-05-05 08:34:56,351 INFO - Configured default timezone UTC
2025-05-05 08:34:56,737 INFO - Heartbeat recovered after 105.39 seconds
2025-05-05 08:34:57,388 INFO - Marking run <DagRun bank_transactions_validation @ 2025-05-04 00:00:00+00:00: scheduled__2025-05-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 11:29:36.028994+00:00. externally triggered: False> successful
2025-05-05 08:34:57,389 INFO - DagRun Finished: dag_id=bank_transactions_validation, execution_date=2025-05-04 00:00:00+00:00, run_id=scheduled__2025-05-04T00:00:00+00:00, run_start_date=2025-05-05 11:29:36.315885+00:00, run_end_date=2025-05-05 11:34:57.389413+00:00, run_duration=321.073528, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=662ad860aa16959fddbfb707ae56c607
2025-05-05 08:34:57,392 INFO - Setting next_dagrun for bank_transactions_validation to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 08:34:57,688 INFO - 4 tasks up for execution:
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_06_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_01_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_09_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_04_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
2025-05-05 08:34:57,689 INFO - DAG bank_transactions_validation has 0/16 running and queued tasks
2025-05-05 08:34:57,690 INFO - DAG bank_transactions_validation has 1/16 running and queued tasks
2025-05-05 08:34:57,691 INFO - DAG bank_transactions_validation has 2/16 running and queued tasks
2025-05-05 08:34:57,691 INFO - DAG bank_transactions_validation has 3/16 running and queued tasks
2025-05-05 08:34:57,692 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_06_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_01_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_09_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
	<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_04_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>
2025-05-05 08:34:57,695 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_06_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_01_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_09_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>, <TaskInstance: bank_transactions_validation.report_validate_transacoes_2023_04_json manual__2025-05-05T11:29:37.578935+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 08:34:57,696 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_06_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:34:57,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_06_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:57,697 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_01_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:34:57,697 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_01_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:57,698 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_09_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:34:57,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_09_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:57,699 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_04_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 08:34:57,700 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_04_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:34:57,994 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_06_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:35:04,316 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_01_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:35:10,702 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_09_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:35:16,090 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_validation', 'report_validate_transacoes_2023_04_json', 'manual__2025-05-05T11:29:37.578935+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_validation.py']
2025-05-05 08:35:22,174 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_06_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:35:22,175 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_01_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:35:22,175 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_09_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:35:22,176 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_validation', task_id='report_validate_transacoes_2023_04_json', run_id='manual__2025-05-05T11:29:37.578935+00:00', try_number=1, map_index=-1)
2025-05-05 08:35:22,183 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_01_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:35:07.533353+00:00, run_end_date=2025-05-05 11:35:09.034650+00:00, run_duration=1.501297, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:34:57.693816+00:00, queued_by_job_id=36, pid=65124
2025-05-05 08:35:22,184 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_04_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:35:18.829204+00:00, run_end_date=2025-05-05 11:35:20.662789+00:00, run_duration=1.833585, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:34:57.693816+00:00, queued_by_job_id=36, pid=65208
2025-05-05 08:35:22,185 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_06_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:35:00.804156+00:00, run_end_date=2025-05-05 11:35:02.784004+00:00, run_duration=1.979848, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=93, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:34:57.693816+00:00, queued_by_job_id=36, pid=65073
2025-05-05 08:35:22,186 INFO - TaskInstance Finished: dag_id=bank_transactions_validation, task_id=report_validate_transacoes_2023_09_json, run_id=manual__2025-05-05T11:29:37.578935+00:00, map_index=-1, run_start_date=2025-05-05 11:35:13.078089+00:00, run_end_date=2025-05-05 11:35:14.288975+00:00, run_duration=1.210886, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 11:34:57.693816+00:00, queued_by_job_id=36, pid=65166
2025-05-05 08:35:24,234 INFO - Marking run <DagRun bank_transactions_validation @ 2025-05-05 11:29:37.578935+00:00: manual__2025-05-05T11:29:37.578935+00:00, state:running, queued_at: 2025-05-05 11:29:37.593376+00:00. externally triggered: True> successful
2025-05-05 08:35:24,235 INFO - DagRun Finished: dag_id=bank_transactions_validation, execution_date=2025-05-05 11:29:37.578935+00:00, run_id=manual__2025-05-05T11:29:37.578935+00:00, run_start_date=2025-05-05 11:31:23.131537+00:00, run_end_date=2025-05-05 11:35:24.235578+00:00, run_duration=241.104041, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-05-04 11:29:37.578935+00:00, data_interval_end=2025-05-05 11:29:37.578935+00:00, dag_hash=662ad860aa16959fddbfb707ae56c607
2025-05-05 08:36:22,993 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:41:23,101 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:46:23,157 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:51:23,310 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 08:56:23,433 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:01:25,307 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:05:22,897 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 09:05:23,154 INFO - Sending 15 to group 65037. PIDs of all processes in the group: []
2025-05-05 09:05:23,154 INFO - Sending the signal 15 to group 65037
2025-05-05 09:05:23,155 INFO - Sending the signal 15 to process 65037 as process group is missing.
2025-05-05 09:05:23,159 INFO - Sending 15 to group 65037. PIDs of all processes in the group: []
2025-05-05 09:05:23,159 INFO - Sending the signal 15 to group 65037
2025-05-05 09:05:23,160 INFO - Sending the signal 15 to process 65037 as process group is missing.
2025-05-05 09:05:23,161 INFO - Exited execute loop
2025-05-05 09:05:37,623 INFO - Loaded executor: SequentialExecutor
2025-05-05 09:05:38,166 INFO - Starting the scheduler
2025-05-05 09:05:38,171 INFO - Processing each file at most -1 times
2025-05-05 09:05:38,247 INFO - Launched DagFileProcessorManager with pid: 76788
2025-05-05 09:05:38,254 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:05:38,260 INFO - Configured default timezone UTC
2025-05-05 09:05:49,970 INFO - Setting next_dagrun for bank_transactions_ml_append to 2025-05-05 12:00:00+00:00, run_after=2025-05-05 18:00:00+00:00
2025-05-05 09:05:53,114 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.generate_fake_data scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
2025-05-05 09:05:53,115 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 09:05:53,116 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.generate_fake_data scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
2025-05-05 09:05:53,120 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.generate_fake_data scheduled__2025-05-05T06:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:05:53,121 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='generate_fake_data', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-05-05 09:05:53,122 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'generate_fake_data', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:05:53,595 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'generate_fake_data', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:03,683 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='generate_fake_data', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:06:04,931 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=generate_fake_data, run_id=scheduled__2025-05-05T06:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:05:57.244874+00:00, run_end_date=2025-05-05 12:05:59.338246+00:00, run_duration=2.093372, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=98, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-05-05 12:05:53.118232+00:00, queued_by_job_id=97, pid=77068
2025-05-05 09:06:05,559 INFO - 1 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.extract scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
2025-05-05 09:06:05,560 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 09:06:05,560 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.extract scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
2025-05-05 09:06:05,562 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.extract scheduled__2025-05-05T06:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:06:05,562 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='extract', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-05-05 09:06:05,563 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'extract', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:05,924 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'extract', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:18,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='extract', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:06:18,590 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=extract, run_id=scheduled__2025-05-05T06:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:06:12.928088+00:00, run_end_date=2025-05-05 12:06:15.701716+00:00, run_duration=2.773628, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=99, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-05-05 12:06:05.561194+00:00, queued_by_job_id=97, pid=77163
2025-05-05 09:06:21,376 INFO - Setting next_dagrun for otimizador_ml to 2023-01-02 00:00:00+00:00, run_after=2023-01-03 00:00:00+00:00
2025-05-05 09:06:22,276 INFO - 3 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.transform scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: otimizador_ml.executar_otimizacao manual__2025-05-05T12:06:09.601511+00:00 [scheduled]>
2025-05-05 09:06:22,276 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 09:06:22,277 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:06:22,277 INFO - DAG otimizador_ml has 1/16 running and queued tasks
2025-05-05 09:06:22,277 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.transform scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: otimizador_ml.executar_otimizacao manual__2025-05-05T12:06:09.601511+00:00 [scheduled]>
2025-05-05 09:06:22,279 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.transform scheduled__2025-05-05T06:00:00+00:00 [scheduled]>, <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-01T00:00:00+00:00 [scheduled]>, <TaskInstance: otimizador_ml.executar_otimizacao manual__2025-05-05T12:06:09.601511+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:06:22,280 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='transform', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-05-05 09:06:22,280 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'transform', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:22,280 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:06:22,281 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:06:22,281 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:06:09.601511+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:06:22,281 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'manual__2025-05-05T12:06:09.601511+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:06:22,664 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'transform', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:30,606 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:06:40,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'manual__2025-05-05T12:06:09.601511+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:06:48,792 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='transform', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:06:48,793 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:06:48,793 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:06:09.601511+00:00', try_number=1, map_index=-1)
2025-05-05 09:06:49,041 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=manual__2025-05-05T12:06:09.601511+00:00, map_index=-1, run_start_date=2025-05-05 12:06:45.129603+00:00, run_end_date=2025-05-05 12:06:46.845877+00:00, run_duration=1.716274, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:06:22.278367+00:00, queued_by_job_id=97, pid=77393
2025-05-05 09:06:49,044 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:06:35.208696+00:00, run_end_date=2025-05-05 12:06:38.077203+00:00, run_duration=2.868507, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:06:22.278367+00:00, queued_by_job_id=97, pid=77317
2025-05-05 09:06:49,047 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=transform, run_id=scheduled__2025-05-05T06:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:06:26.267141+00:00, run_end_date=2025-05-05 12:06:28.500547+00:00, run_duration=2.233406, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=100, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-05-05 12:06:22.278367+00:00, queued_by_job_id=97, pid=77257
2025-05-05 09:06:49,303 INFO - Heartbeat recovered after 30.69 seconds
2025-05-05 09:06:49,762 INFO - Setting next_dagrun for otimizador_ml to 2023-01-03 00:00:00+00:00, run_after=2023-01-04 00:00:00+00:00
2025-05-05 09:06:50,188 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-01 00:00:00+00:00: scheduled__2023-01-01T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:06:21.370734+00:00. externally triggered: False> failed
2025-05-05 09:06:50,189 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-01 00:00:00+00:00, run_id=scheduled__2023-01-01T00:00:00+00:00, run_start_date=2025-05-05 12:06:21.579632+00:00, run_end_date=2025-05-05 12:06:50.189111+00:00, run_duration=28.609479, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-01 00:00:00+00:00, data_interval_end=2023-01-02 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:06:50,193 INFO - Setting next_dagrun for otimizador_ml to 2023-01-02 00:00:00+00:00, run_after=2023-01-03 00:00:00+00:00
2025-05-05 09:06:50,196 ERROR - Marking run <DagRun otimizador_ml @ 2025-05-05 12:06:09.601511+00:00: manual__2025-05-05T12:06:09.601511+00:00, state:running, queued_at: 2025-05-05 12:06:10.384377+00:00. externally triggered: True> failed
2025-05-05 09:06:50,197 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2025-05-05 12:06:09.601511+00:00, run_id=manual__2025-05-05T12:06:09.601511+00:00, run_start_date=2025-05-05 12:06:21.580252+00:00, run_end_date=2025-05-05 12:06:50.197162+00:00, run_duration=28.61691, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:06:50,489 INFO - 4 tasks up for execution:
	<TaskInstance: bank_transactions_ml_append.load scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.data_quality scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.detect_anomalies scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-02T00:00:00+00:00 [scheduled]>
2025-05-05 09:06:50,490 INFO - DAG bank_transactions_ml_append has 0/16 running and queued tasks
2025-05-05 09:06:50,490 INFO - DAG bank_transactions_ml_append has 1/16 running and queued tasks
2025-05-05 09:06:50,491 INFO - DAG bank_transactions_ml_append has 2/16 running and queued tasks
2025-05-05 09:06:50,492 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:06:50,493 INFO - Setting the following tasks to queued state:
	<TaskInstance: bank_transactions_ml_append.load scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.data_quality scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: bank_transactions_ml_append.detect_anomalies scheduled__2025-05-05T06:00:00+00:00 [scheduled]>
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-02T00:00:00+00:00 [scheduled]>
2025-05-05 09:06:50,497 INFO - Trying to enqueue tasks: [<TaskInstance: bank_transactions_ml_append.load scheduled__2025-05-05T06:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_ml_append.data_quality scheduled__2025-05-05T06:00:00+00:00 [scheduled]>, <TaskInstance: bank_transactions_ml_append.detect_anomalies scheduled__2025-05-05T06:00:00+00:00 [scheduled]>, <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:06:50,498 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='load', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 09:06:50,498 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'load', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:50,499 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='data_quality', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 09:06:50,499 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'data_quality', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:50,500 INFO - Sending TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='detect_anomalies', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-05 09:06:50,500 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'detect_anomalies', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:50,501 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:06:50,501 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:06:50,684 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'load', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:06:59,044 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'data_quality', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:07:06,713 INFO - Executing command: ['airflow', 'tasks', 'run', 'bank_transactions_ml_append', 'detect_anomalies', 'scheduled__2025-05-05T06:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/bank_transactions_etl.py']
2025-05-05 09:07:15,723 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:23,563 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='load', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:23,564 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='data_quality', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:23,564 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bank_transactions_ml_append', task_id='detect_anomalies', run_id='scheduled__2025-05-05T06:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:23,565 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:23,573 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:07:20.464843+00:00, run_end_date=2025-05-05 12:07:21.500155+00:00, run_duration=1.035312, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:06:50.494881+00:00, queued_by_job_id=97, pid=77665
2025-05-05 09:07:23,574 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=data_quality, run_id=scheduled__2025-05-05T06:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:07:02.651606+00:00, run_end_date=2025-05-05 12:07:04.501542+00:00, run_duration=1.849936, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=104, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 12:06:50.494881+00:00, queued_by_job_id=97, pid=77520
2025-05-05 09:07:23,574 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=detect_anomalies, run_id=scheduled__2025-05-05T06:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:07:10.502895+00:00, run_end_date=2025-05-05 12:07:13.714351+00:00, run_duration=3.211456, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=105, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 12:06:50.494881+00:00, queued_by_job_id=97, pid=77582
2025-05-05 09:07:23,575 INFO - TaskInstance Finished: dag_id=bank_transactions_ml_append, task_id=load, run_id=scheduled__2025-05-05T06:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:06:55.493465+00:00, run_end_date=2025-05-05 12:06:57.283757+00:00, run_duration=1.790292, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=103, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-05 12:06:50.494881+00:00, queued_by_job_id=97, pid=77464
2025-05-05 09:07:24,125 INFO - Heartbeat recovered after 35.06 seconds
2025-05-05 09:07:26,619 INFO - Setting next_dagrun for otimizador_ml to 2023-01-04 00:00:00+00:00, run_after=2023-01-05 00:00:00+00:00
2025-05-05 09:07:27,259 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-02 00:00:00+00:00: scheduled__2023-01-02T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:06:49.756384+00:00. externally triggered: False> failed
2025-05-05 09:07:27,260 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-02 00:00:00+00:00, run_id=scheduled__2023-01-02T00:00:00+00:00, run_start_date=2025-05-05 12:06:49.982299+00:00, run_end_date=2025-05-05 12:07:27.260388+00:00, run_duration=37.278089, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-02 00:00:00+00:00, data_interval_end=2023-01-03 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:07:27,263 INFO - Setting next_dagrun for otimizador_ml to 2023-01-03 00:00:00+00:00, run_after=2023-01-04 00:00:00+00:00
2025-05-05 09:07:27,558 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-03T00:00:00+00:00 [scheduled]>
2025-05-05 09:07:27,559 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:07:27,560 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-03T00:00:00+00:00 [scheduled]>
2025-05-05 09:07:27,563 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:07:27,564 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:07:27,565 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:27,777 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:35,535 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:35,539 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:07:32.657938+00:00, run_end_date=2025-05-05 12:07:33.746122+00:00, run_duration=1.088184, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:07:27.562148+00:00, queued_by_job_id=97, pid=77763
2025-05-05 09:07:37,312 INFO - Setting next_dagrun for otimizador_ml to 2023-01-04 00:00:00+00:00, run_after=2023-01-05 00:00:00+00:00
2025-05-05 09:07:37,687 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-03 00:00:00+00:00: scheduled__2023-01-03T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:07:26.613755+00:00. externally triggered: False> failed
2025-05-05 09:07:37,688 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-03 00:00:00+00:00, run_id=scheduled__2023-01-03T00:00:00+00:00, run_start_date=2025-05-05 12:07:26.894915+00:00, run_end_date=2025-05-05 12:07:37.688162+00:00, run_duration=10.793247, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-03 00:00:00+00:00, data_interval_end=2023-01-04 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:07:37,693 INFO - Setting next_dagrun for otimizador_ml to 2023-01-04 00:00:00+00:00, run_after=2023-01-05 00:00:00+00:00
2025-05-05 09:07:37,697 INFO - Marking run <DagRun bank_transactions_ml_append @ 2025-05-05 06:00:00+00:00: scheduled__2025-05-05T06:00:00+00:00, state:running, queued_at: 2025-05-05 12:05:49.947849+00:00. externally triggered: False> successful
2025-05-05 09:07:37,698 INFO - DagRun Finished: dag_id=bank_transactions_ml_append, execution_date=2025-05-05 06:00:00+00:00, run_id=scheduled__2025-05-05T06:00:00+00:00, run_start_date=2025-05-05 12:05:50.309829+00:00, run_end_date=2025-05-05 12:07:37.698529+00:00, run_duration=107.3887, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-05 06:00:00+00:00, data_interval_end=2025-05-05 12:00:00+00:00, dag_hash=633de723d94ca85f7f154cb5a97ec3e6
2025-05-05 09:07:37,701 INFO - Setting next_dagrun for bank_transactions_ml_append to 2025-05-05 12:00:00+00:00, run_after=2025-05-05 18:00:00+00:00
2025-05-05 09:07:39,313 INFO - Setting next_dagrun for otimizador_ml to 2023-01-05 00:00:00+00:00, run_after=2023-01-06 00:00:00+00:00
2025-05-05 09:07:40,134 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:07:40,136 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:07:40,138 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:07:40,141 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:07:40,142 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:07:40,143 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:40,321 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:48,165 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:48,170 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:07:45.109226+00:00, run_end_date=2025-05-05 12:07:46.353255+00:00, run_duration=1.244029, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=108, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:07:40.140157+00:00, queued_by_job_id=97, pid=77867
2025-05-05 09:07:49,321 INFO - Setting next_dagrun for otimizador_ml to 2023-01-06 00:00:00+00:00, run_after=2023-01-07 00:00:00+00:00
2025-05-05 09:07:50,008 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-04 00:00:00+00:00: scheduled__2023-01-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:07:39.309236+00:00. externally triggered: False> failed
2025-05-05 09:07:50,009 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-04 00:00:00+00:00, run_id=scheduled__2023-01-04T00:00:00+00:00, run_start_date=2025-05-05 12:07:39.671158+00:00, run_end_date=2025-05-05 12:07:50.009442+00:00, run_duration=10.338284, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-04 00:00:00+00:00, data_interval_end=2023-01-05 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:07:50,013 INFO - Setting next_dagrun for otimizador_ml to 2023-01-05 00:00:00+00:00, run_after=2023-01-06 00:00:00+00:00
2025-05-05 09:07:50,322 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-05T00:00:00+00:00 [scheduled]>
2025-05-05 09:07:50,323 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:07:50,323 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-05T00:00:00+00:00 [scheduled]>
2025-05-05 09:07:50,324 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:07:50,325 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:07:50,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:50,623 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:07:59,592 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:07:59,596 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:07:56.142962+00:00, run_end_date=2025-05-05 12:07:57.795566+00:00, run_duration=1.652604, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:07:50.324149+00:00, queued_by_job_id=97, pid=77940
2025-05-05 09:08:02,655 INFO - Setting next_dagrun for otimizador_ml to 2023-01-07 00:00:00+00:00, run_after=2023-01-08 00:00:00+00:00
2025-05-05 09:08:03,200 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-05 00:00:00+00:00: scheduled__2023-01-05T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:07:49.315980+00:00. externally triggered: False> failed
2025-05-05 09:08:03,201 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-05 00:00:00+00:00, run_id=scheduled__2023-01-05T00:00:00+00:00, run_start_date=2025-05-05 12:07:49.673004+00:00, run_end_date=2025-05-05 12:08:03.201225+00:00, run_duration=13.528221, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-05 00:00:00+00:00, data_interval_end=2023-01-06 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:08:03,205 INFO - Setting next_dagrun for otimizador_ml to 2023-01-06 00:00:00+00:00, run_after=2023-01-07 00:00:00+00:00
2025-05-05 09:08:03,396 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-06T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:03,397 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:08:03,397 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-06T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:03,400 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:08:03,401 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:08:03,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:03,597 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:11,225 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:08:11,229 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:08:08.436078+00:00, run_end_date=2025-05-05 12:08:09.507312+00:00, run_duration=1.071234, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:08:03.398952+00:00, queued_by_job_id=97, pid=78031
2025-05-05 09:08:11,803 INFO - Setting next_dagrun for otimizador_ml to 2023-01-07 00:00:00+00:00, run_after=2023-01-08 00:00:00+00:00
2025-05-05 09:08:12,082 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-06 00:00:00+00:00: scheduled__2023-01-06T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:08:02.651447+00:00. externally triggered: False> failed
2025-05-05 09:08:12,083 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-06 00:00:00+00:00, run_id=scheduled__2023-01-06T00:00:00+00:00, run_start_date=2025-05-05 12:08:02.864371+00:00, run_end_date=2025-05-05 12:08:12.083340+00:00, run_duration=9.218969, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-06 00:00:00+00:00, data_interval_end=2023-01-07 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:08:12,086 INFO - Setting next_dagrun for otimizador_ml to 2023-01-07 00:00:00+00:00, run_after=2023-01-08 00:00:00+00:00
2025-05-05 09:08:14,773 INFO - Setting next_dagrun for otimizador_ml to 2023-01-08 00:00:00+00:00, run_after=2023-01-09 00:00:00+00:00
2025-05-05 09:08:15,751 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-07T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:15,752 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:08:15,753 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-07T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:15,755 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:08:15,756 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:08:15,757 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:16,118 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:24,073 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:08:24,078 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:08:20.664525+00:00, run_end_date=2025-05-05 12:08:21.942433+00:00, run_duration=1.277908, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:08:15.754082+00:00, queued_by_job_id=97, pid=78131
2025-05-05 09:08:24,343 INFO - Setting next_dagrun for otimizador_ml to 2023-01-09 00:00:00+00:00, run_after=2023-01-10 00:00:00+00:00
2025-05-05 09:08:24,961 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-07 00:00:00+00:00: scheduled__2023-01-07T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:08:14.769270+00:00. externally triggered: False> failed
2025-05-05 09:08:24,963 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-07 00:00:00+00:00, run_id=scheduled__2023-01-07T00:00:00+00:00, run_start_date=2025-05-05 12:08:14.974342+00:00, run_end_date=2025-05-05 12:08:24.963112+00:00, run_duration=9.98877, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-07 00:00:00+00:00, data_interval_end=2023-01-08 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:08:24,974 INFO - Setting next_dagrun for otimizador_ml to 2023-01-08 00:00:00+00:00, run_after=2023-01-09 00:00:00+00:00
2025-05-05 09:08:25,215 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-08T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:25,216 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:08:25,216 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-08T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:25,218 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:08:25,218 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:08:25,219 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:25,458 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:32,651 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:08:32,656 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:08:29.828056+00:00, run_end_date=2025-05-05 12:08:30.831577+00:00, run_duration=1.003521, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:08:25.217152+00:00, queued_by_job_id=97, pid=78203
2025-05-05 09:08:34,969 INFO - Setting next_dagrun for otimizador_ml to 2023-01-10 00:00:00+00:00, run_after=2023-01-11 00:00:00+00:00
2025-05-05 09:08:35,503 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-08 00:00:00+00:00: scheduled__2023-01-08T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:08:24.339503+00:00. externally triggered: False> failed
2025-05-05 09:08:35,503 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-08 00:00:00+00:00, run_id=scheduled__2023-01-08T00:00:00+00:00, run_start_date=2025-05-05 12:08:24.556078+00:00, run_end_date=2025-05-05 12:08:35.503918+00:00, run_duration=10.94784, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-08 00:00:00+00:00, data_interval_end=2023-01-09 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:08:35,508 INFO - Setting next_dagrun for otimizador_ml to 2023-01-09 00:00:00+00:00, run_after=2023-01-10 00:00:00+00:00
2025-05-05 09:08:35,716 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-09T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:35,717 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:08:35,718 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-09T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:35,723 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:08:35,725 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:08:35,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:36,016 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:44,041 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:08:44,046 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:08:40.737226+00:00, run_end_date=2025-05-05 12:08:42.244459+00:00, run_duration=1.507233, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:08:35.720571+00:00, queued_by_job_id=97, pid=78295
2025-05-05 09:08:44,652 INFO - Setting next_dagrun for otimizador_ml to 2023-01-10 00:00:00+00:00, run_after=2023-01-11 00:00:00+00:00
2025-05-05 09:08:44,907 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-09 00:00:00+00:00: scheduled__2023-01-09T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:08:34.965126+00:00. externally triggered: False> failed
2025-05-05 09:08:44,908 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-09 00:00:00+00:00, run_id=scheduled__2023-01-09T00:00:00+00:00, run_start_date=2025-05-05 12:08:35.302500+00:00, run_end_date=2025-05-05 12:08:44.908842+00:00, run_duration=9.606342, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-09 00:00:00+00:00, data_interval_end=2023-01-10 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:08:44,913 INFO - Setting next_dagrun for otimizador_ml to 2023-01-10 00:00:00+00:00, run_after=2023-01-11 00:00:00+00:00
2025-05-05 09:08:47,289 INFO - Setting next_dagrun for otimizador_ml to 2023-01-11 00:00:00+00:00, run_after=2023-01-12 00:00:00+00:00
2025-05-05 09:08:48,121 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-10T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:48,123 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:08:48,124 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-10T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:48,128 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:08:48,129 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:08:48,130 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:48,327 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:55,572 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:08:55,576 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:08:52.681207+00:00, run_end_date=2025-05-05 12:08:53.711534+00:00, run_duration=1.030327, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:08:48.126050+00:00, queued_by_job_id=97, pid=78390
2025-05-05 09:08:55,921 INFO - Setting next_dagrun for otimizador_ml to 2023-01-12 00:00:00+00:00, run_after=2023-01-13 00:00:00+00:00
2025-05-05 09:08:56,405 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-10 00:00:00+00:00: scheduled__2023-01-10T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:08:47.284206+00:00. externally triggered: False> failed
2025-05-05 09:08:56,406 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-10 00:00:00+00:00, run_id=scheduled__2023-01-10T00:00:00+00:00, run_start_date=2025-05-05 12:08:47.583873+00:00, run_end_date=2025-05-05 12:08:56.406683+00:00, run_duration=8.82281, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-10 00:00:00+00:00, data_interval_end=2023-01-11 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:08:56,412 INFO - Setting next_dagrun for otimizador_ml to 2023-01-11 00:00:00+00:00, run_after=2023-01-12 00:00:00+00:00
2025-05-05 09:08:56,623 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-11T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:56,625 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:08:56,625 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-11T00:00:00+00:00 [scheduled]>
2025-05-05 09:08:56,629 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:08:56,630 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:08:56,631 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:08:56,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:04,722 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:09:04,728 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:09:01.583148+00:00, run_end_date=2025-05-05 12:09:02.936235+00:00, run_duration=1.353087, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:08:56.627305+00:00, queued_by_job_id=97, pid=78462
2025-05-05 09:09:07,248 INFO - Setting next_dagrun for otimizador_ml to 2023-01-13 00:00:00+00:00, run_after=2023-01-14 00:00:00+00:00
2025-05-05 09:09:07,668 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-11 00:00:00+00:00: scheduled__2023-01-11T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:08:55.915345+00:00. externally triggered: False> failed
2025-05-05 09:09:07,669 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-11 00:00:00+00:00, run_id=scheduled__2023-01-11T00:00:00+00:00, run_start_date=2025-05-05 12:08:56.138445+00:00, run_end_date=2025-05-05 12:09:07.669253+00:00, run_duration=11.530808, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-11 00:00:00+00:00, data_interval_end=2023-01-12 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:09:07,674 INFO - Setting next_dagrun for otimizador_ml to 2023-01-12 00:00:00+00:00, run_after=2023-01-13 00:00:00+00:00
2025-05-05 09:09:07,872 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-12T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:07,873 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:09:07,874 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-12T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:07,877 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:09:07,878 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:09:07,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:08,160 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:15,146 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:09:15,151 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:09:12.405394+00:00, run_end_date=2025-05-05 12:09:13.490083+00:00, run_duration=1.084689, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:09:07.875468+00:00, queued_by_job_id=97, pid=78551
2025-05-05 09:09:15,874 INFO - Setting next_dagrun for otimizador_ml to 2023-01-13 00:00:00+00:00, run_after=2023-01-14 00:00:00+00:00
2025-05-05 09:09:16,122 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-12 00:00:00+00:00: scheduled__2023-01-12T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:09:07.243208+00:00. externally triggered: False> failed
2025-05-05 09:09:16,123 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-12 00:00:00+00:00, run_id=scheduled__2023-01-12T00:00:00+00:00, run_start_date=2025-05-05 12:09:07.459737+00:00, run_end_date=2025-05-05 12:09:16.123840+00:00, run_duration=8.664103, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-12 00:00:00+00:00, data_interval_end=2023-01-13 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:09:16,129 INFO - Setting next_dagrun for otimizador_ml to 2023-01-13 00:00:00+00:00, run_after=2023-01-14 00:00:00+00:00
2025-05-05 09:09:18,733 INFO - Setting next_dagrun for otimizador_ml to 2023-01-14 00:00:00+00:00, run_after=2023-01-15 00:00:00+00:00
2025-05-05 09:09:19,531 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-13T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:19,532 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:09:19,533 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-13T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:19,537 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-13T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:09:19,537 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:09:19,538 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:19,828 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:26,826 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:09:26,832 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:09:24.114731+00:00, run_end_date=2025-05-05 12:09:25.179833+00:00, run_duration=1.065102, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:09:19.534869+00:00, queued_by_job_id=97, pid=78654
2025-05-05 09:09:27,097 INFO - Setting next_dagrun for otimizador_ml to 2023-01-15 00:00:00+00:00, run_after=2023-01-16 00:00:00+00:00
2025-05-05 09:09:27,553 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-13 00:00:00+00:00: scheduled__2023-01-13T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:09:18.724372+00:00. externally triggered: False> failed
2025-05-05 09:09:27,554 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-13 00:00:00+00:00, run_id=scheduled__2023-01-13T00:00:00+00:00, run_start_date=2025-05-05 12:09:18.929751+00:00, run_end_date=2025-05-05 12:09:27.554726+00:00, run_duration=8.624975, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-13 00:00:00+00:00, data_interval_end=2023-01-14 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:09:27,559 INFO - Setting next_dagrun for otimizador_ml to 2023-01-14 00:00:00+00:00, run_after=2023-01-15 00:00:00+00:00
2025-05-05 09:09:27,885 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-14T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:27,886 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:09:27,887 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-14T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:27,891 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:09:27,892 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:09:27,893 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:28,072 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:35,945 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:09:35,950 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:09:32.615020+00:00, run_end_date=2025-05-05 12:09:33.936537+00:00, run_duration=1.321517, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:09:27.889692+00:00, queued_by_job_id=97, pid=78720
2025-05-05 09:09:36,270 INFO - Setting next_dagrun for otimizador_ml to 2023-01-15 00:00:00+00:00, run_after=2023-01-16 00:00:00+00:00
2025-05-05 09:09:36,408 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-14 00:00:00+00:00: scheduled__2023-01-14T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:09:27.090781+00:00. externally triggered: False> failed
2025-05-05 09:09:36,409 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-14 00:00:00+00:00, run_id=scheduled__2023-01-14T00:00:00+00:00, run_start_date=2025-05-05 12:09:27.288166+00:00, run_end_date=2025-05-05 12:09:36.409804+00:00, run_duration=9.121638, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-14 00:00:00+00:00, data_interval_end=2023-01-15 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:09:36,415 INFO - Setting next_dagrun for otimizador_ml to 2023-01-15 00:00:00+00:00, run_after=2023-01-16 00:00:00+00:00
2025-05-05 09:09:37,074 INFO - Setting next_dagrun for otimizador_ml to 2023-01-16 00:00:00+00:00, run_after=2023-01-17 00:00:00+00:00
2025-05-05 09:09:37,995 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-15T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:37,996 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:09:37,997 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-15T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:38,000 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-15T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:09:38,001 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:09:38,001 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:38,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:46,551 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:09:46,555 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:09:42.910775+00:00, run_end_date=2025-05-05 12:09:44.258125+00:00, run_duration=1.34735, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:09:37.998683+00:00, queued_by_job_id=97, pid=78798
2025-05-05 09:09:49,035 INFO - Setting next_dagrun for otimizador_ml to 2023-01-17 00:00:00+00:00, run_after=2023-01-18 00:00:00+00:00
2025-05-05 09:09:49,746 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-15 00:00:00+00:00: scheduled__2023-01-15T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:09:37.071143+00:00. externally triggered: False> failed
2025-05-05 09:09:49,747 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-15 00:00:00+00:00, run_id=scheduled__2023-01-15T00:00:00+00:00, run_start_date=2025-05-05 12:09:37.321104+00:00, run_end_date=2025-05-05 12:09:49.747023+00:00, run_duration=12.425919, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-15 00:00:00+00:00, data_interval_end=2023-01-16 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:09:49,749 INFO - Setting next_dagrun for otimizador_ml to 2023-01-16 00:00:00+00:00, run_after=2023-01-17 00:00:00+00:00
2025-05-05 09:09:49,990 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-16T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:49,991 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:09:49,991 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-16T00:00:00+00:00 [scheduled]>
2025-05-05 09:09:49,994 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-16T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:09:49,995 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:09:49,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:50,226 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:09:58,826 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:09:58,830 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:09:54.790045+00:00, run_end_date=2025-05-05 12:09:56.851771+00:00, run_duration=2.061726, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:09:49.993072+00:00, queued_by_job_id=97, pid=78894
2025-05-05 09:09:59,421 INFO - Setting next_dagrun for otimizador_ml to 2023-01-17 00:00:00+00:00, run_after=2023-01-18 00:00:00+00:00
2025-05-05 09:09:59,671 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-16 00:00:00+00:00: scheduled__2023-01-16T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:09:49.028191+00:00. externally triggered: False> failed
2025-05-05 09:09:59,671 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-16 00:00:00+00:00, run_id=scheduled__2023-01-16T00:00:00+00:00, run_start_date=2025-05-05 12:09:49.274210+00:00, run_end_date=2025-05-05 12:09:59.671467+00:00, run_duration=10.397257, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-16 00:00:00+00:00, data_interval_end=2023-01-17 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:09:59,674 INFO - Setting next_dagrun for otimizador_ml to 2023-01-17 00:00:00+00:00, run_after=2023-01-18 00:00:00+00:00
2025-05-05 09:10:02,098 INFO - Setting next_dagrun for otimizador_ml to 2023-01-18 00:00:00+00:00, run_after=2023-01-19 00:00:00+00:00
2025-05-05 09:10:03,070 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-17T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:03,071 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:10:03,073 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-17T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:03,076 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-17T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:10:03,077 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:10:03,078 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:03,291 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:12,950 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:10:12,955 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:10:07.695061+00:00, run_end_date=2025-05-05 12:10:09.837948+00:00, run_duration=2.142887, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:10:03.074733+00:00, queued_by_job_id=97, pid=78999
2025-05-05 09:10:13,544 INFO - Setting next_dagrun for otimizador_ml to 2023-01-19 00:00:00+00:00, run_after=2023-01-20 00:00:00+00:00
2025-05-05 09:10:14,560 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-17 00:00:00+00:00: scheduled__2023-01-17T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:10:02.094227+00:00. externally triggered: False> failed
2025-05-05 09:10:14,561 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-17 00:00:00+00:00, run_id=scheduled__2023-01-17T00:00:00+00:00, run_start_date=2025-05-05 12:10:02.507633+00:00, run_end_date=2025-05-05 12:10:14.561178+00:00, run_duration=12.053545, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-17 00:00:00+00:00, data_interval_end=2023-01-18 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:10:14,566 INFO - Setting next_dagrun for otimizador_ml to 2023-01-18 00:00:00+00:00, run_after=2023-01-19 00:00:00+00:00
2025-05-05 09:10:14,999 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-18T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:14,999 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:10:15,000 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-18T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:15,003 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:10:15,003 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:10:15,004 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:15,271 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:22,442 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:10:22,446 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:10:19.747285+00:00, run_end_date=2025-05-05 12:10:20.685347+00:00, run_duration=0.938062, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:10:15.001586+00:00, queued_by_job_id=97, pid=79105
2025-05-05 09:10:25,019 INFO - Setting next_dagrun for otimizador_ml to 2023-01-20 00:00:00+00:00, run_after=2023-01-21 00:00:00+00:00
2025-05-05 09:10:25,493 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-18 00:00:00+00:00: scheduled__2023-01-18T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:10:13.538826+00:00. externally triggered: False> failed
2025-05-05 09:10:25,494 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-18 00:00:00+00:00, run_id=scheduled__2023-01-18T00:00:00+00:00, run_start_date=2025-05-05 12:10:14.093094+00:00, run_end_date=2025-05-05 12:10:25.494441+00:00, run_duration=11.401347, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-18 00:00:00+00:00, data_interval_end=2023-01-19 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:10:25,500 INFO - Setting next_dagrun for otimizador_ml to 2023-01-19 00:00:00+00:00, run_after=2023-01-20 00:00:00+00:00
2025-05-05 09:10:25,888 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-19T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:25,890 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:10:25,891 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-19T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:25,896 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-19T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:10:25,897 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:10:25,898 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:26,198 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:33,338 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:10:33,343 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:10:30.602292+00:00, run_end_date=2025-05-05 12:10:31.713449+00:00, run_duration=1.111157, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:10:25.893417+00:00, queued_by_job_id=97, pid=79227
2025-05-05 09:10:34,083 INFO - Setting next_dagrun for otimizador_ml to 2023-01-20 00:00:00+00:00, run_after=2023-01-21 00:00:00+00:00
2025-05-05 09:10:34,223 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-19 00:00:00+00:00: scheduled__2023-01-19T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:10:25.016401+00:00. externally triggered: False> failed
2025-05-05 09:10:34,223 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-19 00:00:00+00:00, run_id=scheduled__2023-01-19T00:00:00+00:00, run_start_date=2025-05-05 12:10:25.270198+00:00, run_end_date=2025-05-05 12:10:34.223493+00:00, run_duration=8.953295, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-19 00:00:00+00:00, data_interval_end=2023-01-20 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:10:34,227 INFO - Setting next_dagrun for otimizador_ml to 2023-01-20 00:00:00+00:00, run_after=2023-01-21 00:00:00+00:00
2025-05-05 09:10:36,901 INFO - Setting next_dagrun for otimizador_ml to 2023-01-21 00:00:00+00:00, run_after=2023-01-22 00:00:00+00:00
2025-05-05 09:10:37,553 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-20T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:37,554 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:10:37,555 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-20T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:37,558 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:10:37,559 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:10:37,560 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:37,894 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:45,802 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:10:45,806 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:10:42.413541+00:00, run_end_date=2025-05-05 12:10:43.652756+00:00, run_duration=1.239215, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:10:37.556769+00:00, queued_by_job_id=97, pid=79327
2025-05-05 09:10:46,043 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:10:46,096 INFO - Setting next_dagrun for otimizador_ml to 2023-01-22 00:00:00+00:00, run_after=2023-01-23 00:00:00+00:00
2025-05-05 09:10:46,726 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-20 00:00:00+00:00: scheduled__2023-01-20T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:10:36.896556+00:00. externally triggered: False> failed
2025-05-05 09:10:46,726 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-20 00:00:00+00:00, run_id=scheduled__2023-01-20T00:00:00+00:00, run_start_date=2025-05-05 12:10:37.110006+00:00, run_end_date=2025-05-05 12:10:46.726834+00:00, run_duration=9.616828, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-20 00:00:00+00:00, data_interval_end=2023-01-21 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:10:46,732 INFO - Setting next_dagrun for otimizador_ml to 2023-01-21 00:00:00+00:00, run_after=2023-01-22 00:00:00+00:00
2025-05-05 09:10:46,954 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-21T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:46,954 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:10:46,955 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-21T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:46,956 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:10:46,957 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:10:46,957 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:47,179 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:55,738 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:10:55,742 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:10:51.783298+00:00, run_end_date=2025-05-05 12:10:53.848948+00:00, run_duration=2.06565, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:10:46.955910+00:00, queued_by_job_id=97, pid=79402
2025-05-05 09:10:58,227 INFO - Setting next_dagrun for otimizador_ml to 2023-01-23 00:00:00+00:00, run_after=2023-01-24 00:00:00+00:00
2025-05-05 09:10:58,765 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-21 00:00:00+00:00: scheduled__2023-01-21T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:10:46.092900+00:00. externally triggered: False> failed
2025-05-05 09:10:58,766 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-21 00:00:00+00:00, run_id=scheduled__2023-01-21T00:00:00+00:00, run_start_date=2025-05-05 12:10:46.473648+00:00, run_end_date=2025-05-05 12:10:58.766144+00:00, run_duration=12.292496, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-21 00:00:00+00:00, data_interval_end=2023-01-22 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:10:58,772 INFO - Setting next_dagrun for otimizador_ml to 2023-01-22 00:00:00+00:00, run_after=2023-01-23 00:00:00+00:00
2025-05-05 09:10:59,007 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-22T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:59,008 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:10:59,010 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-22T00:00:00+00:00 [scheduled]>
2025-05-05 09:10:59,013 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:10:59,015 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:10:59,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:10:59,288 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:07,010 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:11:07,014 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:11:03.690389+00:00, run_end_date=2025-05-05 12:11:04.780261+00:00, run_duration=1.089872, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:10:59.011928+00:00, queued_by_job_id=97, pid=79498
2025-05-05 09:11:07,658 INFO - Setting next_dagrun for otimizador_ml to 2023-01-23 00:00:00+00:00, run_after=2023-01-24 00:00:00+00:00
2025-05-05 09:11:07,912 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-22 00:00:00+00:00: scheduled__2023-01-22T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:10:58.221333+00:00. externally triggered: False> failed
2025-05-05 09:11:07,913 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-22 00:00:00+00:00, run_id=scheduled__2023-01-22T00:00:00+00:00, run_start_date=2025-05-05 12:10:58.504911+00:00, run_end_date=2025-05-05 12:11:07.913286+00:00, run_duration=9.408375, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-22 00:00:00+00:00, data_interval_end=2023-01-23 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:11:07,917 INFO - Setting next_dagrun for otimizador_ml to 2023-01-23 00:00:00+00:00, run_after=2023-01-24 00:00:00+00:00
2025-05-05 09:11:10,355 INFO - Setting next_dagrun for otimizador_ml to 2023-01-24 00:00:00+00:00, run_after=2023-01-25 00:00:00+00:00
2025-05-05 09:11:11,064 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-23T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:11,065 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:11:11,066 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-23T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:11,069 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:11:11,069 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:11:11,070 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:11,478 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:20,619 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:11:20,625 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:11:16.339821+00:00, run_end_date=2025-05-05 12:11:18.628008+00:00, run_duration=2.288187, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:11:11.067756+00:00, queued_by_job_id=97, pid=79604
2025-05-05 09:11:21,159 INFO - Setting next_dagrun for otimizador_ml to 2023-01-25 00:00:00+00:00, run_after=2023-01-26 00:00:00+00:00
2025-05-05 09:11:21,696 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-23 00:00:00+00:00: scheduled__2023-01-23T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:11:10.344739+00:00. externally triggered: False> failed
2025-05-05 09:11:21,697 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-23 00:00:00+00:00, run_id=scheduled__2023-01-23T00:00:00+00:00, run_start_date=2025-05-05 12:11:10.595552+00:00, run_end_date=2025-05-05 12:11:21.697598+00:00, run_duration=11.102046, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-23 00:00:00+00:00, data_interval_end=2023-01-24 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:11:21,709 INFO - Setting next_dagrun for otimizador_ml to 2023-01-24 00:00:00+00:00, run_after=2023-01-25 00:00:00+00:00
2025-05-05 09:11:21,956 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-24T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:21,958 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:11:21,960 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-24T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:21,968 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-24T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:11:21,971 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:11:21,973 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:22,316 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:30,649 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:11:30,653 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:11:27.046349+00:00, run_end_date=2025-05-05 12:11:28.228961+00:00, run_duration=1.182612, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:11:21.963980+00:00, queued_by_job_id=97, pid=79670
2025-05-05 09:11:33,180 INFO - Setting next_dagrun for otimizador_ml to 2023-01-26 00:00:00+00:00, run_after=2023-01-27 00:00:00+00:00
2025-05-05 09:11:34,086 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-24 00:00:00+00:00: scheduled__2023-01-24T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:11:21.153058+00:00. externally triggered: False> failed
2025-05-05 09:11:34,087 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-24 00:00:00+00:00, run_id=scheduled__2023-01-24T00:00:00+00:00, run_start_date=2025-05-05 12:11:21.436251+00:00, run_end_date=2025-05-05 12:11:34.087008+00:00, run_duration=12.650757, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-24 00:00:00+00:00, data_interval_end=2023-01-25 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:11:34,091 INFO - Setting next_dagrun for otimizador_ml to 2023-01-25 00:00:00+00:00, run_after=2023-01-26 00:00:00+00:00
2025-05-05 09:11:34,496 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-25T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:34,497 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:11:34,498 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-25T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:34,501 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-25T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:11:34,502 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:11:34,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:34,720 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:48,215 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:11:48,223 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:11:40.176908+00:00, run_end_date=2025-05-05 12:11:44.338806+00:00, run_duration=4.161898, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:11:34.499829+00:00, queued_by_job_id=97, pid=79774
2025-05-05 09:11:51,480 INFO - Setting next_dagrun for otimizador_ml to 2023-01-26 00:00:00+00:00, run_after=2023-01-27 00:00:00+00:00
2025-05-05 09:11:52,190 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-25 00:00:00+00:00: scheduled__2023-01-25T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:11:33.175122+00:00. externally triggered: False> failed
2025-05-05 09:11:52,190 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-25 00:00:00+00:00, run_id=scheduled__2023-01-25T00:00:00+00:00, run_start_date=2025-05-05 12:11:33.453775+00:00, run_end_date=2025-05-05 12:11:52.190770+00:00, run_duration=18.736995, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-25 00:00:00+00:00, data_interval_end=2023-01-26 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:11:52,194 INFO - Setting next_dagrun for otimizador_ml to 2023-01-26 00:00:00+00:00, run_after=2023-01-27 00:00:00+00:00
2025-05-05 09:11:55,382 INFO - Setting next_dagrun for otimizador_ml to 2023-01-27 00:00:00+00:00, run_after=2023-01-28 00:00:00+00:00
2025-05-05 09:11:56,946 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-26T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:56,946 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:11:56,947 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-26T00:00:00+00:00 [scheduled]>
2025-05-05 09:11:56,949 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:11:56,949 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:11:56,950 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:11:57,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:06,257 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:12:06,261 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:12:02.225361+00:00, run_end_date=2025-05-05 12:12:03.711896+00:00, run_duration=1.486535, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:11:56.947947+00:00, queued_by_job_id=97, pid=79927
2025-05-05 09:12:08,845 INFO - Setting next_dagrun for otimizador_ml to 2023-01-28 00:00:00+00:00, run_after=2023-01-29 00:00:00+00:00
2025-05-05 09:12:09,250 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-26 00:00:00+00:00: scheduled__2023-01-26T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:11:55.377999+00:00. externally triggered: False> failed
2025-05-05 09:12:09,251 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-26 00:00:00+00:00, run_id=scheduled__2023-01-26T00:00:00+00:00, run_start_date=2025-05-05 12:11:55.941004+00:00, run_end_date=2025-05-05 12:12:09.251404+00:00, run_duration=13.3104, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-26 00:00:00+00:00, data_interval_end=2023-01-27 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:12:09,255 INFO - Setting next_dagrun for otimizador_ml to 2023-01-27 00:00:00+00:00, run_after=2023-01-28 00:00:00+00:00
2025-05-05 09:12:09,529 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-27T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:09,530 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:12:09,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-27T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:09,532 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-27T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:12:09,533 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:12:09,533 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:09,770 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:18,496 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-27T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:12:19,438 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-27T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:12:15.095121+00:00, run_end_date=2025-05-05 12:12:16.489825+00:00, run_duration=1.394704, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:12:09.531438+00:00, queued_by_job_id=97, pid=80019
2025-05-05 09:12:19,734 INFO - Setting next_dagrun for otimizador_ml to 2023-01-28 00:00:00+00:00, run_after=2023-01-29 00:00:00+00:00
2025-05-05 09:12:20,025 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-27 00:00:00+00:00: scheduled__2023-01-27T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:12:08.838819+00:00. externally triggered: False> failed
2025-05-05 09:12:20,027 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-27 00:00:00+00:00, run_id=scheduled__2023-01-27T00:00:00+00:00, run_start_date=2025-05-05 12:12:09.056184+00:00, run_end_date=2025-05-05 12:12:20.027535+00:00, run_duration=10.971351, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-27 00:00:00+00:00, data_interval_end=2023-01-28 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:12:20,040 INFO - Setting next_dagrun for otimizador_ml to 2023-01-28 00:00:00+00:00, run_after=2023-01-29 00:00:00+00:00
2025-05-05 09:12:21,167 INFO - Setting next_dagrun for otimizador_ml to 2023-01-29 00:00:00+00:00, run_after=2023-01-30 00:00:00+00:00
2025-05-05 09:12:22,030 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-28T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:22,031 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:12:22,032 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-28T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:22,035 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-28T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:12:22,035 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:12:22,036 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:22,594 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:30,687 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-28T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:12:30,691 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-28T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:12:27.302187+00:00, run_end_date=2025-05-05 12:12:28.834200+00:00, run_duration=1.532013, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:12:22.033339+00:00, queued_by_job_id=97, pid=80096
2025-05-05 09:12:31,225 INFO - Setting next_dagrun for otimizador_ml to 2023-01-30 00:00:00+00:00, run_after=2023-01-31 00:00:00+00:00
2025-05-05 09:12:31,703 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-28 00:00:00+00:00: scheduled__2023-01-28T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:12:21.154398+00:00. externally triggered: False> failed
2025-05-05 09:12:31,703 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-28 00:00:00+00:00, run_id=scheduled__2023-01-28T00:00:00+00:00, run_start_date=2025-05-05 12:12:21.489093+00:00, run_end_date=2025-05-05 12:12:31.703737+00:00, run_duration=10.214644, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-28 00:00:00+00:00, data_interval_end=2023-01-29 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:12:31,708 INFO - Setting next_dagrun for otimizador_ml to 2023-01-29 00:00:00+00:00, run_after=2023-01-30 00:00:00+00:00
2025-05-05 09:12:31,905 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-29T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:31,906 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:12:31,907 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-29T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:31,909 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-29T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:12:31,909 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-29T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:12:31,910 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:32,143 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:40,163 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-29T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:12:40,167 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-29T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:12:37.179815+00:00, run_end_date=2025-05-05 12:12:38.271596+00:00, run_duration=1.091781, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=133, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:12:31.907827+00:00, queued_by_job_id=97, pid=80171
2025-05-05 09:12:41,539 INFO - Setting next_dagrun for otimizador_ml to 2023-01-30 00:00:00+00:00, run_after=2023-01-31 00:00:00+00:00
2025-05-05 09:12:41,700 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-29 00:00:00+00:00: scheduled__2023-01-29T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:12:31.221849+00:00. externally triggered: False> failed
2025-05-05 09:12:41,701 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-29 00:00:00+00:00, run_id=scheduled__2023-01-29T00:00:00+00:00, run_start_date=2025-05-05 12:12:31.491267+00:00, run_end_date=2025-05-05 12:12:41.701401+00:00, run_duration=10.210134, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-29 00:00:00+00:00, data_interval_end=2023-01-30 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:12:41,706 INFO - Setting next_dagrun for otimizador_ml to 2023-01-30 00:00:00+00:00, run_after=2023-01-31 00:00:00+00:00
2025-05-05 09:12:45,435 INFO - Setting next_dagrun for otimizador_ml to 2023-01-31 00:00:00+00:00, run_after=2023-02-01 00:00:00+00:00
2025-05-05 09:12:46,422 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-30T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:46,423 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:12:46,426 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-30T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:46,435 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:12:46,436 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:12:46,437 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:46,802 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:55,289 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-30T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:12:55,296 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-30T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:12:52.048127+00:00, run_end_date=2025-05-05 12:12:53.292698+00:00, run_duration=1.244571, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=134, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:12:46.431685+00:00, queued_by_job_id=97, pid=80291
2025-05-05 09:12:55,604 INFO - Setting next_dagrun for otimizador_ml to 2023-02-01 00:00:00+00:00, run_after=2023-02-02 00:00:00+00:00
2025-05-05 09:12:56,166 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-30 00:00:00+00:00: scheduled__2023-01-30T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:12:45.431282+00:00. externally triggered: False> failed
2025-05-05 09:12:56,168 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-30 00:00:00+00:00, run_id=scheduled__2023-01-30T00:00:00+00:00, run_start_date=2025-05-05 12:12:45.649965+00:00, run_end_date=2025-05-05 12:12:56.168096+00:00, run_duration=10.518131, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-30 00:00:00+00:00, data_interval_end=2023-01-31 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:12:56,181 INFO - Setting next_dagrun for otimizador_ml to 2023-01-31 00:00:00+00:00, run_after=2023-02-01 00:00:00+00:00
2025-05-05 09:12:56,368 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-31T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:56,368 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:12:56,369 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-31T00:00:00+00:00 [scheduled]>
2025-05-05 09:12:56,371 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-01-31T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:12:56,371 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-31T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:12:56,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:12:56,711 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-01-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:05,874 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-01-31T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:13:05,879 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-01-31T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:13:02.266079+00:00, run_end_date=2025-05-05 12:13:03.891205+00:00, run_duration=1.625126, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=135, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:12:56.370121+00:00, queued_by_job_id=97, pid=80371
2025-05-05 09:13:06,646 INFO - Setting next_dagrun for otimizador_ml to 2023-02-01 00:00:00+00:00, run_after=2023-02-02 00:00:00+00:00
2025-05-05 09:13:06,821 ERROR - Marking run <DagRun otimizador_ml @ 2023-01-31 00:00:00+00:00: scheduled__2023-01-31T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:12:55.599515+00:00. externally triggered: False> failed
2025-05-05 09:13:06,822 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-01-31 00:00:00+00:00, run_id=scheduled__2023-01-31T00:00:00+00:00, run_start_date=2025-05-05 12:12:55.870009+00:00, run_end_date=2025-05-05 12:13:06.822665+00:00, run_duration=10.952656, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-31 00:00:00+00:00, data_interval_end=2023-02-01 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:13:06,831 INFO - Setting next_dagrun for otimizador_ml to 2023-02-01 00:00:00+00:00, run_after=2023-02-02 00:00:00+00:00
2025-05-05 09:13:08,142 INFO - Setting next_dagrun for otimizador_ml to 2023-02-02 00:00:00+00:00, run_after=2023-02-03 00:00:00+00:00
2025-05-05 09:13:08,850 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-01T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:08,850 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:13:08,851 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-01T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:08,854 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:13:08,854 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:13:08,855 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:09,156 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:17,566 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:13:17,573 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:13:14.469057+00:00, run_end_date=2025-05-05 12:13:15.760033+00:00, run_duration=1.290976, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=136, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:13:08.852553+00:00, queued_by_job_id=97, pid=80451
2025-05-05 09:13:20,532 INFO - Setting next_dagrun for otimizador_ml to 2023-02-03 00:00:00+00:00, run_after=2023-02-04 00:00:00+00:00
2025-05-05 09:13:20,942 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-01 00:00:00+00:00: scheduled__2023-02-01T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:13:08.134103+00:00. externally triggered: False> failed
2025-05-05 09:13:20,942 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-01 00:00:00+00:00, run_id=scheduled__2023-02-01T00:00:00+00:00, run_start_date=2025-05-05 12:13:08.416366+00:00, run_end_date=2025-05-05 12:13:20.942869+00:00, run_duration=12.526503, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-01 00:00:00+00:00, data_interval_end=2023-02-02 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:13:20,946 INFO - Setting next_dagrun for otimizador_ml to 2023-02-02 00:00:00+00:00, run_after=2023-02-03 00:00:00+00:00
2025-05-05 09:13:21,270 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-02T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:21,272 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:13:21,274 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-02T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:21,279 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:13:21,281 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:13:21,282 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:21,476 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:29,865 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:13:29,870 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:13:26.776959+00:00, run_end_date=2025-05-05 12:13:27.755159+00:00, run_duration=0.9782, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=137, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:13:21.276022+00:00, queued_by_job_id=97, pid=80525
2025-05-05 09:13:31,391 INFO - Setting next_dagrun for otimizador_ml to 2023-02-03 00:00:00+00:00, run_after=2023-02-04 00:00:00+00:00
2025-05-05 09:13:31,584 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-02 00:00:00+00:00: scheduled__2023-02-02T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:13:20.528487+00:00. externally triggered: False> failed
2025-05-05 09:13:31,586 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-02 00:00:00+00:00, run_id=scheduled__2023-02-02T00:00:00+00:00, run_start_date=2025-05-05 12:13:20.722729+00:00, run_end_date=2025-05-05 12:13:31.586160+00:00, run_duration=10.863431, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-02 00:00:00+00:00, data_interval_end=2023-02-03 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:13:31,593 INFO - Setting next_dagrun for otimizador_ml to 2023-02-03 00:00:00+00:00, run_after=2023-02-04 00:00:00+00:00
2025-05-05 09:13:32,806 INFO - Setting next_dagrun for otimizador_ml to 2023-02-04 00:00:00+00:00, run_after=2023-02-05 00:00:00+00:00
2025-05-05 09:13:33,617 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-03T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:33,618 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:13:33,619 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-03T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:33,621 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:13:33,622 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:13:33,623 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:33,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:42,675 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:13:42,682 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:13:39.191412+00:00, run_end_date=2025-05-05 12:13:40.672055+00:00, run_duration=1.480643, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=138, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:13:33.620339+00:00, queued_by_job_id=97, pid=80625
2025-05-05 09:13:43,636 INFO - Setting next_dagrun for otimizador_ml to 2023-02-05 00:00:00+00:00, run_after=2023-02-06 00:00:00+00:00
2025-05-05 09:13:44,117 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-03 00:00:00+00:00: scheduled__2023-02-03T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:13:32.800896+00:00. externally triggered: False> failed
2025-05-05 09:13:44,118 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-03 00:00:00+00:00, run_id=scheduled__2023-02-03T00:00:00+00:00, run_start_date=2025-05-05 12:13:33.044857+00:00, run_end_date=2025-05-05 12:13:44.118008+00:00, run_duration=11.073151, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-03 00:00:00+00:00, data_interval_end=2023-02-04 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:13:44,121 INFO - Setting next_dagrun for otimizador_ml to 2023-02-04 00:00:00+00:00, run_after=2023-02-05 00:00:00+00:00
2025-05-05 09:13:44,319 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:44,320 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:13:44,320 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:44,322 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:13:44,322 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:13:44,322 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:44,897 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:54,222 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:13:54,225 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:13:50.060504+00:00, run_end_date=2025-05-05 12:13:51.894592+00:00, run_duration=1.834088, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=139, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:13:44.321236+00:00, queued_by_job_id=97, pid=80705
2025-05-05 09:13:57,252 INFO - Setting next_dagrun for otimizador_ml to 2023-02-06 00:00:00+00:00, run_after=2023-02-07 00:00:00+00:00
2025-05-05 09:13:58,015 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-04 00:00:00+00:00: scheduled__2023-02-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:13:43.631417+00:00. externally triggered: False> failed
2025-05-05 09:13:58,017 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-04 00:00:00+00:00, run_id=scheduled__2023-02-04T00:00:00+00:00, run_start_date=2025-05-05 12:13:43.864435+00:00, run_end_date=2025-05-05 12:13:58.016977+00:00, run_duration=14.152542, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-04 00:00:00+00:00, data_interval_end=2023-02-05 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:13:58,022 INFO - Setting next_dagrun for otimizador_ml to 2023-02-05 00:00:00+00:00, run_after=2023-02-06 00:00:00+00:00
2025-05-05 09:13:58,388 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-05T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:58,389 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:13:58,390 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-05T00:00:00+00:00 [scheduled]>
2025-05-05 09:13:58,393 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:13:58,394 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:13:58,394 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:13:58,601 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:07,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:14:07,123 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:14:03.449570+00:00, run_end_date=2025-05-05 12:14:05.040767+00:00, run_duration=1.591197, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=140, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:13:58.391467+00:00, queued_by_job_id=97, pid=80793
2025-05-05 09:14:08,692 INFO - Setting next_dagrun for otimizador_ml to 2023-02-06 00:00:00+00:00, run_after=2023-02-07 00:00:00+00:00
2025-05-05 09:14:08,837 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-05 00:00:00+00:00: scheduled__2023-02-05T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:13:57.247044+00:00. externally triggered: False> failed
2025-05-05 09:14:08,838 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-05 00:00:00+00:00, run_id=scheduled__2023-02-05T00:00:00+00:00, run_start_date=2025-05-05 12:13:57.477383+00:00, run_end_date=2025-05-05 12:14:08.838098+00:00, run_duration=11.360715, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-05 00:00:00+00:00, data_interval_end=2023-02-06 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:14:08,841 INFO - Setting next_dagrun for otimizador_ml to 2023-02-06 00:00:00+00:00, run_after=2023-02-07 00:00:00+00:00
2025-05-05 09:14:10,342 INFO - Setting next_dagrun for otimizador_ml to 2023-02-07 00:00:00+00:00, run_after=2023-02-08 00:00:00+00:00
2025-05-05 09:14:11,569 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-06T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:11,571 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:14:11,574 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-06T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:11,584 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:14:11,587 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:14:11,589 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:11,829 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:21,358 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:14:21,364 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:14:17.367948+00:00, run_end_date=2025-05-05 12:14:19.011580+00:00, run_duration=1.643632, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=141, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:14:11.578519+00:00, queued_by_job_id=97, pid=80880
2025-05-05 09:14:22,152 INFO - Setting next_dagrun for otimizador_ml to 2023-02-08 00:00:00+00:00, run_after=2023-02-09 00:00:00+00:00
2025-05-05 09:14:23,261 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-06 00:00:00+00:00: scheduled__2023-02-06T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:14:10.321850+00:00. externally triggered: False> failed
2025-05-05 09:14:23,261 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-06 00:00:00+00:00, run_id=scheduled__2023-02-06T00:00:00+00:00, run_start_date=2025-05-05 12:14:10.738597+00:00, run_end_date=2025-05-05 12:14:23.261548+00:00, run_duration=12.522951, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-06 00:00:00+00:00, data_interval_end=2023-02-07 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:14:23,265 INFO - Setting next_dagrun for otimizador_ml to 2023-02-07 00:00:00+00:00, run_after=2023-02-08 00:00:00+00:00
2025-05-05 09:14:23,829 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-07T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:23,830 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:14:23,832 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-07T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:23,836 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:14:23,837 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:14:23,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:24,430 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:32,719 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:14:32,725 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:14:29.440719+00:00, run_end_date=2025-05-05 12:14:30.609652+00:00, run_duration=1.168933, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=142, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:14:23.834012+00:00, queued_by_job_id=97, pid=80968
2025-05-05 09:14:35,700 INFO - Setting next_dagrun for otimizador_ml to 2023-02-09 00:00:00+00:00, run_after=2023-02-10 00:00:00+00:00
2025-05-05 09:14:36,260 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-07 00:00:00+00:00: scheduled__2023-02-07T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:14:22.147038+00:00. externally triggered: False> failed
2025-05-05 09:14:36,260 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-07 00:00:00+00:00, run_id=scheduled__2023-02-07T00:00:00+00:00, run_start_date=2025-05-05 12:14:22.393075+00:00, run_end_date=2025-05-05 12:14:36.260753+00:00, run_duration=13.867678, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-07 00:00:00+00:00, data_interval_end=2023-02-08 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:14:36,264 INFO - Setting next_dagrun for otimizador_ml to 2023-02-08 00:00:00+00:00, run_after=2023-02-09 00:00:00+00:00
2025-05-05 09:14:36,861 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-08T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:36,862 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:14:36,863 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-08T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:36,866 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:14:36,867 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:14:36,867 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:37,224 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:42,466 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']' returned non-zero exit status 1..
2025-05-05 09:14:42,467 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:14:42,471 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-08T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:14:36.864791+00:00, queued_by_job_id=97, pid=None
2025-05-05 09:14:42,472 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-08T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:14:42,807 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-08T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:14:42,826 INFO - Marking task as FAILED. dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-08T00:00:00+00:00, execution_date=20230208T000000, start_date=, end_date=20250505T121442
2025-05-05 09:14:44,885 INFO - Setting next_dagrun for otimizador_ml to 2023-02-09 00:00:00+00:00, run_after=2023-02-10 00:00:00+00:00
2025-05-05 09:14:45,126 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-08 00:00:00+00:00: scheduled__2023-02-08T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:14:35.695401+00:00. externally triggered: False> failed
2025-05-05 09:14:45,127 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-08 00:00:00+00:00, run_id=scheduled__2023-02-08T00:00:00+00:00, run_start_date=2025-05-05 12:14:35.903550+00:00, run_end_date=2025-05-05 12:14:45.127232+00:00, run_duration=9.223682, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-08 00:00:00+00:00, data_interval_end=2023-02-09 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:14:45,131 INFO - Setting next_dagrun for otimizador_ml to 2023-02-09 00:00:00+00:00, run_after=2023-02-10 00:00:00+00:00
2025-05-05 09:14:46,545 INFO - Setting next_dagrun for otimizador_ml to 2023-02-10 00:00:00+00:00, run_after=2023-02-11 00:00:00+00:00
2025-05-05 09:14:47,365 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-09T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:47,367 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:14:47,369 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-09T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:47,373 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:14:47,375 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:14:47,375 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:47,669 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:52,841 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']' returned non-zero exit status 1..
2025-05-05 09:14:52,841 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:14:52,845 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-09T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:14:47.371143+00:00, queued_by_job_id=97, pid=None
2025-05-05 09:14:52,846 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-09T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:14:53,142 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-09T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:14:53,161 INFO - Marking task as FAILED. dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-09T00:00:00+00:00, execution_date=20230209T000000, start_date=, end_date=20250505T121453
2025-05-05 09:14:54,644 INFO - Setting next_dagrun for otimizador_ml to 2023-02-11 00:00:00+00:00, run_after=2023-02-12 00:00:00+00:00
2025-05-05 09:14:55,198 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-09 00:00:00+00:00: scheduled__2023-02-09T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:14:46.533395+00:00. externally triggered: False> failed
2025-05-05 09:14:55,199 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-09 00:00:00+00:00, run_id=scheduled__2023-02-09T00:00:00+00:00, run_start_date=2025-05-05 12:14:46.815110+00:00, run_end_date=2025-05-05 12:14:55.199037+00:00, run_duration=8.383927, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-09 00:00:00+00:00, data_interval_end=2023-02-10 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:14:55,202 INFO - Setting next_dagrun for otimizador_ml to 2023-02-10 00:00:00+00:00, run_after=2023-02-11 00:00:00+00:00
2025-05-05 09:14:55,675 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-10T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:55,675 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:14:55,676 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-10T00:00:00+00:00 [scheduled]>
2025-05-05 09:14:55,678 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:14:55,679 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:14:55,679 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:14:56,047 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:15:01,322 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']' returned non-zero exit status 1..
2025-05-05 09:15:01,323 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:15:01,326 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-10T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:14:55.677684+00:00, queued_by_job_id=97, pid=None
2025-05-05 09:15:01,327 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-10T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:15:01,640 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-10T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:15:01,652 INFO - Marking task as FAILED. dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-10T00:00:00+00:00, execution_date=20230210T000000, start_date=, end_date=20250505T121501
2025-05-05 09:15:02,493 INFO - Setting next_dagrun for otimizador_ml to 2023-02-11 00:00:00+00:00, run_after=2023-02-12 00:00:00+00:00
2025-05-05 09:15:02,678 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-10 00:00:00+00:00: scheduled__2023-02-10T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:14:54.636285+00:00. externally triggered: False> failed
2025-05-05 09:15:02,678 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-10 00:00:00+00:00, run_id=scheduled__2023-02-10T00:00:00+00:00, run_start_date=2025-05-05 12:14:54.877045+00:00, run_end_date=2025-05-05 12:15:02.678428+00:00, run_duration=7.801383, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-10 00:00:00+00:00, data_interval_end=2023-02-11 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:15:02,681 INFO - Setting next_dagrun for otimizador_ml to 2023-02-11 00:00:00+00:00, run_after=2023-02-12 00:00:00+00:00
2025-05-05 09:15:04,031 INFO - Setting next_dagrun for otimizador_ml to 2023-02-12 00:00:00+00:00, run_after=2023-02-13 00:00:00+00:00
2025-05-05 09:15:04,643 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-11T00:00:00+00:00 [scheduled]>
2025-05-05 09:15:04,644 INFO - DAG otimizador_ml has 0/16 running and queued tasks
2025-05-05 09:15:04,645 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-11T00:00:00+00:00 [scheduled]>
2025-05-05 09:15:04,647 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:15:04,647 INFO - Sending TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:15:04,648 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:15:04,876 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:15:10,528 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'otimizador_ml', 'executar_otimizacao', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']' returned non-zero exit status 1..
2025-05-05 09:15:10,528 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='otimizador_ml', task_id='executar_otimizacao', run_id='scheduled__2023-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:15:10,532 INFO - TaskInstance Finished: dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-11T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:15:04.645773+00:00, queued_by_job_id=97, pid=None
2025-05-05 09:15:10,533 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-11T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:15:10,875 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: otimizador_ml.executar_otimizacao scheduled__2023-02-11T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-05-05 09:15:10,897 INFO - Marking task as FAILED. dag_id=otimizador_ml, task_id=executar_otimizacao, run_id=scheduled__2023-02-11T00:00:00+00:00, execution_date=20230211T000000, start_date=, end_date=20250505T121510
2025-05-05 09:15:14,208 ERROR - Marking run <DagRun otimizador_ml @ 2023-02-11 00:00:00+00:00: scheduled__2023-02-11T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:15:04.021374+00:00. externally triggered: False> failed
2025-05-05 09:15:14,208 INFO - DagRun Finished: dag_id=otimizador_ml, execution_date=2023-02-11 00:00:00+00:00, run_id=scheduled__2023-02-11T00:00:00+00:00, run_start_date=2025-05-05 12:15:04.225750+00:00, run_end_date=2025-05-05 12:15:14.208895+00:00, run_duration=9.983145, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-11 00:00:00+00:00, data_interval_end=2023-02-12 00:00:00+00:00, dag_hash=176447e35215f3a5980c55b006312afc
2025-05-05 09:15:14,212 INFO - Setting next_dagrun for otimizador_ml to 2023-02-12 00:00:00+00:00, run_after=2023-02-13 00:00:00+00:00
2025-05-05 09:15:46,151 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:20:47,119 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:24:41,839 INFO - Setting next_dagrun for otimizador_rotas to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 09:24:42,590 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:24:42,592 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:24:42,594 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:24:42,598 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:24:42,600 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:24:42,600 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:24:42,787 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:24:50,278 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:24:50,282 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:24:47.385548+00:00, run_end_date=2025-05-05 12:24:48.588780+00:00, run_duration=1.203232, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=143, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:24:42.596164+00:00, queued_by_job_id=97, pid=85587
2025-05-05 09:25:47,368 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:25:53,817 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:25:51.119934+00:00 [scheduled]>
2025-05-05 09:25:53,818 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:25:53,819 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:25:51.119934+00:00 [scheduled]>
2025-05-05 09:25:53,822 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:25:51.119934+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:25:53,823 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:25:51.119934+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:25:53,824 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:25:51.119934+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:25:54,037 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:25:51.119934+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:26:05,495 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:25:51.119934+00:00', try_number=1, map_index=-1)
2025-05-05 09:26:05,500 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=manual__2025-05-05T12:25:51.119934+00:00, map_index=-1, run_start_date=2025-05-05 12:26:00.905370+00:00, run_end_date=2025-05-05 12:26:03.110581+00:00, run_duration=2.205211, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=144, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:25:53.821029+00:00, queued_by_job_id=97, pid=86080
2025-05-05 09:27:07,335 INFO - Marking run <DagRun otimizador_rotas @ 2025-05-05 12:25:51.119934+00:00: manual__2025-05-05T12:25:51.119934+00:00, state:running, queued_at: 2025-05-05 12:25:51.163628+00:00. externally triggered: True> successful
2025-05-05 09:27:07,336 INFO - DagRun Finished: dag_id=otimizador_rotas, execution_date=2025-05-05 12:25:51.119934+00:00, run_id=manual__2025-05-05T12:25:51.119934+00:00, run_start_date=2025-05-05 12:25:52.971897+00:00, run_end_date=2025-05-05 12:27:07.336333+00:00, run_duration=74.364436, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=3b628b4207642918d66f42a8f7af0374
2025-05-05 09:27:07,342 INFO - Marking run <DagRun otimizador_rotas @ 2025-05-04 00:00:00+00:00: scheduled__2025-05-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:24:41.828457+00:00. externally triggered: False> successful
2025-05-05 09:27:07,343 INFO - DagRun Finished: dag_id=otimizador_rotas, execution_date=2025-05-04 00:00:00+00:00, run_id=scheduled__2025-05-04T00:00:00+00:00, run_start_date=2025-05-05 12:24:42.061718+00:00, run_end_date=2025-05-05 12:27:07.343210+00:00, run_duration=145.281492, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=3b628b4207642918d66f42a8f7af0374
2025-05-05 09:27:07,348 INFO - Setting next_dagrun for otimizador_rotas to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 09:27:50,839 INFO - Setting next_dagrun for otimizador_rotas to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 09:27:52,092 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:27:52,094 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:27:52,095 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:27:52,100 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:27:52,101 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:27:52,102 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:27:52,370 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:28:02,356 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:28:02,360 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:27:57.530358+00:00, run_end_date=2025-05-05 12:27:59.973592+00:00, run_duration=2.443234, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=145, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:27:52.097237+00:00, queued_by_job_id=97, pid=86753
2025-05-05 09:29:11,464 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:29:10.635456+00:00 [scheduled]>
2025-05-05 09:29:11,466 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:29:11,468 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:29:10.635456+00:00 [scheduled]>
2025-05-05 09:29:11,475 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:29:10.635456+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:29:11,479 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:29:10.635456+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:29:11,480 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:29:10.635456+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:29:11,726 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:29:10.635456+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:29:20,001 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:29:10.635456+00:00', try_number=1, map_index=-1)
2025-05-05 09:29:20,007 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=manual__2025-05-05T12:29:10.635456+00:00, map_index=-1, run_start_date=2025-05-05 12:29:16.752401+00:00, run_end_date=2025-05-05 12:29:17.859086+00:00, run_duration=1.106685, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=146, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:29:11.471685+00:00, queued_by_job_id=97, pid=87299
2025-05-05 09:30:47,533 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:33:00,586 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:33:00,587 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:33:00,588 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:33:00,591 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:33:00,593 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:33:00,593 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:33:00,770 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:33:08,077 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=2, map_index=-1)
2025-05-05 09:33:08,081 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:33:05.444599+00:00, run_end_date=2025-05-05 12:33:06.196947+00:00, run_duration=0.752348, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=147, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:33:00.589786+00:00, queued_by_job_id=97, pid=88808
2025-05-05 09:33:08,518 ERROR - Marking run <DagRun otimizador_rotas @ 2025-05-04 00:00:00+00:00: scheduled__2025-05-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:27:50.835166+00:00. externally triggered: False> failed
2025-05-05 09:33:08,518 INFO - DagRun Finished: dag_id=otimizador_rotas, execution_date=2025-05-04 00:00:00+00:00, run_id=scheduled__2025-05-04T00:00:00+00:00, run_start_date=2025-05-05 12:27:51.250522+00:00, run_end_date=2025-05-05 12:33:08.518692+00:00, run_duration=317.26817, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=3b628b4207642918d66f42a8f7af0374
2025-05-05 09:33:08,522 INFO - Setting next_dagrun for otimizador_rotas to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 09:34:19,295 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:29:10.635456+00:00 [scheduled]>
2025-05-05 09:34:19,295 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:34:19,295 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:29:10.635456+00:00 [scheduled]>
2025-05-05 09:34:19,297 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:29:10.635456+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:34:19,298 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:29:10.635456+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:34:19,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:29:10.635456+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:34:19,561 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:29:10.635456+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:34:27,577 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:29:10.635456+00:00', try_number=2, map_index=-1)
2025-05-05 09:34:27,581 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=manual__2025-05-05T12:29:10.635456+00:00, map_index=-1, run_start_date=2025-05-05 12:34:24.765013+00:00, run_end_date=2025-05-05 12:34:25.680066+00:00, run_duration=0.915053, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=148, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:34:19.296641+00:00, queued_by_job_id=97, pid=89310
2025-05-05 09:34:30,581 ERROR - Marking run <DagRun otimizador_rotas @ 2025-05-05 12:29:10.635456+00:00: manual__2025-05-05T12:29:10.635456+00:00, state:running, queued_at: 2025-05-05 12:29:10.673912+00:00. externally triggered: True> failed
2025-05-05 09:34:30,582 INFO - DagRun Finished: dag_id=otimizador_rotas, execution_date=2025-05-05 12:29:10.635456+00:00, run_id=manual__2025-05-05T12:29:10.635456+00:00, run_start_date=2025-05-05 12:29:11.097549+00:00, run_end_date=2025-05-05 12:34:30.582197+00:00, run_duration=319.484648, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=3b628b4207642918d66f42a8f7af0374
2025-05-05 09:35:47,595 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:36:24,167 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 09:36:24,417 INFO - Sending 15 to group 76788. PIDs of all processes in the group: []
2025-05-05 09:36:24,418 INFO - Sending the signal 15 to group 76788
2025-05-05 09:36:24,419 INFO - Sending the signal 15 to process 76788 as process group is missing.
2025-05-05 09:36:24,422 INFO - Sending 15 to group 76788. PIDs of all processes in the group: []
2025-05-05 09:36:24,423 INFO - Sending the signal 15 to group 76788
2025-05-05 09:36:24,424 INFO - Sending the signal 15 to process 76788 as process group is missing.
2025-05-05 09:36:24,424 INFO - Exited execute loop
2025-05-05 09:36:32,014 INFO - Loaded executor: SequentialExecutor
2025-05-05 09:36:32,282 INFO - Starting the scheduler
2025-05-05 09:36:32,284 INFO - Processing each file at most -1 times
2025-05-05 09:36:32,300 INFO - Launched DagFileProcessorManager with pid: 90218
2025-05-05 09:36:32,303 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:36:32,308 INFO - Configured default timezone UTC
2025-05-05 09:41:32,373 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:46:32,428 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:47:51,388 INFO - Setting next_dagrun for otimizador_rotas to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 09:47:52,458 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:47:52,458 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:47:52,459 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 09:47:52,461 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:47:52,461 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:47:52,461 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:47:52,747 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:47:59,170 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 09:47:59,179 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 12:47:55.651675+00:00, run_end_date=2025-05-05 12:47:57.986362+00:00, run_duration=2.334687, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=150, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:47:52.459873+00:00, queued_by_job_id=149, pid=94630
2025-05-05 09:48:01,446 INFO - Marking run <DagRun otimizador_rotas @ 2025-05-04 00:00:00+00:00: scheduled__2025-05-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 12:47:51.373038+00:00. externally triggered: False> successful
2025-05-05 09:48:01,452 INFO - DagRun Finished: dag_id=otimizador_rotas, execution_date=2025-05-04 00:00:00+00:00, run_id=scheduled__2025-05-04T00:00:00+00:00, run_start_date=2025-05-05 12:47:51.755763+00:00, run_end_date=2025-05-05 12:48:01.452566+00:00, run_duration=9.696803, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=eff367d0492d31c42277493231c0dd56
2025-05-05 09:48:01,646 INFO - Setting next_dagrun for otimizador_rotas to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 09:49:13,231 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:49:10.502142+00:00 [scheduled]>
2025-05-05 09:49:13,231 INFO - DAG otimizador_rotas has 0/16 running and queued tasks
2025-05-05 09:49:13,232 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:49:10.502142+00:00 [scheduled]>
2025-05-05 09:49:13,235 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas.executar_otimizacao manual__2025-05-05T12:49:10.502142+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 09:49:13,236 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:49:10.502142+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 09:49:13,237 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:49:10.502142+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:49:13,561 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas', 'executar_otimizacao', 'manual__2025-05-05T12:49:10.502142+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 09:49:21,244 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas', task_id='executar_otimizacao', run_id='manual__2025-05-05T12:49:10.502142+00:00', try_number=1, map_index=-1)
2025-05-05 09:49:21,247 INFO - TaskInstance Finished: dag_id=otimizador_rotas, task_id=executar_otimizacao, run_id=manual__2025-05-05T12:49:10.502142+00:00, map_index=-1, run_start_date=2025-05-05 12:49:16.316104+00:00, run_end_date=2025-05-05 12:49:19.721504+00:00, run_duration=3.4054, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=151, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 12:49:13.233428+00:00, queued_by_job_id=149, pid=95093
2025-05-05 09:49:22,719 INFO - Marking run <DagRun otimizador_rotas @ 2025-05-05 12:49:10.502142+00:00: manual__2025-05-05T12:49:10.502142+00:00, state:running, queued_at: 2025-05-05 12:49:10.554470+00:00. externally triggered: True> successful
2025-05-05 09:49:22,719 INFO - DagRun Finished: dag_id=otimizador_rotas, execution_date=2025-05-05 12:49:10.502142+00:00, run_id=manual__2025-05-05T12:49:10.502142+00:00, run_start_date=2025-05-05 12:49:12.623733+00:00, run_end_date=2025-05-05 12:49:22.719871+00:00, run_duration=10.096138, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=eff367d0492d31c42277493231c0dd56
2025-05-05 09:51:32,490 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 09:56:32,553 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:01:33,308 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:06:33,341 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:11:33,373 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:16:33,431 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:16:45,132 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 10:16:45,338 INFO - Sending 15 to group 90218. PIDs of all processes in the group: []
2025-05-05 10:16:45,340 INFO - Sending the signal 15 to group 90218
2025-05-05 10:16:45,342 INFO - Sending the signal 15 to process 90218 as process group is missing.
2025-05-05 10:16:45,350 INFO - Sending 15 to group 90218. PIDs of all processes in the group: []
2025-05-05 10:16:45,352 INFO - Sending the signal 15 to group 90218
2025-05-05 10:16:45,354 INFO - Sending the signal 15 to process 90218 as process group is missing.
2025-05-05 10:16:45,355 INFO - Exited execute loop
2025-05-05 10:44:18,458 INFO - Loaded executor: SequentialExecutor
2025-05-05 10:44:19,240 INFO - Starting the scheduler
2025-05-05 10:44:19,241 INFO - Processing each file at most -1 times
2025-05-05 10:44:19,250 INFO - Launched DagFileProcessorManager with pid: 115713
2025-05-05 10:44:19,253 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:44:19,256 INFO - Configured default timezone UTC
2025-05-05 10:45:52,294 INFO - Setting next_dagrun for otimizador_rotas_avancado to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 10:45:54,490 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas_avancado.otimizar_rotas scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 10:45:54,491 INFO - DAG otimizador_rotas_avancado has 0/16 running and queued tasks
2025-05-05 10:45:54,491 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas_avancado.otimizar_rotas scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 10:45:54,496 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas_avancado.otimizar_rotas scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 10:45:54,497 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas_avancado', task_id='otimizar_rotas', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 10:45:54,498 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas_avancado', 'otimizar_rotas', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 10:45:54,800 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas_avancado', 'otimizar_rotas', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 10:46:08,609 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas_avancado', task_id='otimizar_rotas', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-05 10:46:08,616 INFO - TaskInstance Finished: dag_id=otimizador_rotas_avancado, task_id=otimizar_rotas, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 13:46:00.350376+00:00, run_end_date=2025-05-05 13:46:04.473840+00:00, run_duration=4.123464, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=153, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 13:45:54.493252+00:00, queued_by_job_id=152, pid=116261
2025-05-05 10:49:19,356 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:51:04,999 INFO - 1 tasks up for execution:
	<TaskInstance: otimizador_rotas_avancado.otimizar_rotas scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 10:51:05,003 INFO - DAG otimizador_rotas_avancado has 0/16 running and queued tasks
2025-05-05 10:51:05,007 INFO - Setting the following tasks to queued state:
	<TaskInstance: otimizador_rotas_avancado.otimizar_rotas scheduled__2025-05-04T00:00:00+00:00 [scheduled]>
2025-05-05 10:51:05,020 INFO - Trying to enqueue tasks: [<TaskInstance: otimizador_rotas_avancado.otimizar_rotas scheduled__2025-05-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-05 10:51:05,026 INFO - Sending TaskInstanceKey(dag_id='otimizador_rotas_avancado', task_id='otimizar_rotas', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-05 10:51:05,030 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'otimizador_rotas_avancado', 'otimizar_rotas', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 10:51:05,329 INFO - Executing command: ['airflow', 'tasks', 'run', 'otimizador_rotas_avancado', 'otimizar_rotas', 'scheduled__2025-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_rotas.py']
2025-05-05 10:51:18,299 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='otimizador_rotas_avancado', task_id='otimizar_rotas', run_id='scheduled__2025-05-04T00:00:00+00:00', try_number=2, map_index=-1)
2025-05-05 10:51:19,573 INFO - TaskInstance Finished: dag_id=otimizador_rotas_avancado, task_id=otimizar_rotas, run_id=scheduled__2025-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-05 13:51:10.069226+00:00, run_end_date=2025-05-05 13:51:14.735845+00:00, run_duration=4.666619, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=154, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-05 13:51:05.013326+00:00, queued_by_job_id=152, pid=118140
2025-05-05 10:51:19,957 ERROR - Marking run <DagRun otimizador_rotas_avancado @ 2025-05-04 00:00:00+00:00: scheduled__2025-05-04T00:00:00+00:00, state:running, queued_at: 2025-05-05 13:45:52.129520+00:00. externally triggered: False> failed
2025-05-05 10:51:19,958 INFO - DagRun Finished: dag_id=otimizador_rotas_avancado, execution_date=2025-05-04 00:00:00+00:00, run_id=scheduled__2025-05-04T00:00:00+00:00, run_start_date=2025-05-05 13:45:52.676052+00:00, run_end_date=2025-05-05 13:51:19.958296+00:00, run_duration=327.282244, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-05-04 00:00:00+00:00, data_interval_end=2025-05-05 00:00:00+00:00, dag_hash=4244eaab777b8663bebe6200482da749
2025-05-05 10:51:19,962 INFO - Setting next_dagrun for otimizador_rotas_avancado to 2025-05-05 00:00:00+00:00, run_after=2025-05-06 00:00:00+00:00
2025-05-05 10:54:19,401 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 10:59:19,470 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:04:19,540 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:09:20,687 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:14:20,720 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:19:20,969 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:24:21,062 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:26:11,734 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 11:26:13,017 INFO - Sending 15 to group 115713. PIDs of all processes in the group: [131649, 115713]
2025-05-05 11:26:13,018 INFO - Sending the signal 15 to group 115713
2025-05-05 11:26:15,865 INFO - Process psutil.Process(pid=131649, status='terminated', started='11:26:10') (131649) terminated with exit code None
2025-05-05 11:26:15,962 INFO - Process psutil.Process(pid=115713, status='terminated', exitcode=0, started='10:44:19') (115713) terminated with exit code 0
2025-05-05 11:26:15,984 INFO - Sending 15 to group 115713. PIDs of all processes in the group: []
2025-05-05 11:26:15,985 INFO - Sending the signal 15 to group 115713
2025-05-05 11:26:15,986 INFO - Sending the signal 15 to process 115713 as process group is missing.
2025-05-05 11:26:15,986 INFO - Exited execute loop
2025-05-05 11:26:46,135 INFO - Loaded executor: SequentialExecutor
2025-05-05 11:26:46,820 INFO - Starting the scheduler
2025-05-05 11:26:46,822 INFO - Processing each file at most -1 times
2025-05-05 11:26:46,840 INFO - Launched DagFileProcessorManager with pid: 131955
2025-05-05 11:26:46,846 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:26:46,860 INFO - Configured default timezone UTC
2025-05-05 11:31:46,949 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:36:47,025 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:41:47,383 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:46:47,425 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:51:47,532 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 11:56:47,576 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:01:47,672 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:06:39,279 INFO - Exiting gracefully upon receiving signal 15
2025-05-05 12:06:40,084 INFO - Sending 15 to group 131955. PIDs of all processes in the group: []
2025-05-05 12:06:40,085 INFO - Sending the signal 15 to group 131955
2025-05-05 12:06:40,086 INFO - Sending the signal 15 to process 131955 as process group is missing.
2025-05-05 12:06:40,091 INFO - Sending 15 to group 131955. PIDs of all processes in the group: []
2025-05-05 12:06:40,092 INFO - Sending the signal 15 to group 131955
2025-05-05 12:06:40,093 INFO - Sending the signal 15 to process 131955 as process group is missing.
2025-05-05 12:06:40,094 INFO - Exited execute loop
2025-05-05 12:07:53,716 INFO - Loaded executor: SequentialExecutor
2025-05-05 12:07:54,033 INFO - Starting the scheduler
2025-05-05 12:07:54,035 INFO - Processing each file at most -1 times
2025-05-05 12:07:54,048 INFO - Launched DagFileProcessorManager with pid: 143935
2025-05-05 12:07:54,050 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:07:54,054 INFO - Configured default timezone UTC
2025-05-05 12:12:54,112 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:17:54,173 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:22:54,536 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:27:54,571 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:32:54,629 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:37:54,994 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:42:55,068 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:47:55,117 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:52:55,191 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 12:57:55,226 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:02:55,266 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:07:55,339 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:12:55,355 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:17:55,420 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:22:55,478 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:27:55,550 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:32:55,621 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:37:55,986 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:42:56,023 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:47:56,085 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:52:56,137 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 13:57:56,220 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:02:56,731 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:07:56,787 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:12:56,846 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:17:56,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:22:56,963 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:27:58,047 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:32:58,102 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:37:58,106 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:42:58,322 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:47:58,356 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:52:58,387 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 14:57:58,434 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:02:58,539 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:07:58,856 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:12:59,038 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:17:59,045 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:22:59,300 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:27:59,331 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:32:59,354 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:37:59,388 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:42:59,430 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:47:59,487 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:52:59,556 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 15:57:59,612 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:02:59,687 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:07:59,742 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:13:00,088 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:18:00,155 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:23:00,217 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:28:00,257 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:33:00,524 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:38:00,573 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:43:00,642 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:48:01,175 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:53:01,223 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 16:58:01,587 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:03:01,601 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:08:02,078 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:13:02,135 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:18:02,226 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:23:02,261 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:28:02,295 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:33:02,379 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:38:02,420 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:43:02,429 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:48:02,498 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:53:03,796 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 17:58:03,863 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:03:04,056 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:08:04,095 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:13:04,687 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:18:04,745 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:23:04,787 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:28:04,852 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:33:04,930 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-05 18:38:04,977 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-06 06:39:58,433 INFO - Loaded executor: SequentialExecutor
2025-05-06 06:39:59,047 INFO - Starting the scheduler
2025-05-06 06:39:59,048 INFO - Processing each file at most -1 times
2025-05-06 06:39:59,059 INFO - Launched DagFileProcessorManager with pid: 10149
2025-05-06 06:39:59,060 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-06 06:39:59,063 INFO - Configured default timezone UTC
2025-05-06 06:39:59,069 INFO - Marked 1 SchedulerJob instances as failed
2025-05-06 06:40:30,172 INFO - Heartbeat recovered after 32.33 seconds
2025-05-06 06:44:59,592 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-06 06:49:59,676 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-06 06:54:59,701 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-06 06:57:44,318 INFO - Exiting gracefully upon receiving signal 15
2025-05-06 06:57:45,481 INFO - Sending 15 to group 10149. PIDs of all processes in the group: [10149]
2025-05-06 06:57:45,482 INFO - Sending the signal 15 to group 10149
2025-05-06 06:57:45,896 INFO - Process psutil.Process(pid=10149, status='terminated', exitcode=0, started='06:39:58') (10149) terminated with exit code 0
2025-05-06 06:57:45,918 INFO - Sending 15 to group 10149. PIDs of all processes in the group: []
2025-05-06 06:57:45,919 INFO - Sending the signal 15 to group 10149
2025-05-06 06:57:45,920 INFO - Sending the signal 15 to process 10149 as process group is missing.
2025-05-06 06:57:45,920 INFO - Exited execute loop
2025-05-07 10:27:07,594 INFO - Loaded executor: SequentialExecutor
2025-05-07 10:27:08,775 INFO - Starting the scheduler
2025-05-07 10:27:08,778 INFO - Processing each file at most -1 times
2025-05-07 10:27:08,836 INFO - Launched DagFileProcessorManager with pid: 24639
2025-05-07 10:27:08,838 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 10:27:08,841 INFO - Configured default timezone UTC
2025-05-07 10:32:08,969 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 10:37:09,061 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 10:42:09,425 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 10:47:12,924 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 10:52:13,000 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 10:57:13,068 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 11:02:13,101 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 11:07:13,342 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 11:12:13,386 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 11:16:51,696 INFO - Exiting gracefully upon receiving signal 15
2025-05-07 11:16:52,727 INFO - Sending 15 to group 24639. PIDs of all processes in the group: [24639]
2025-05-07 11:16:52,728 INFO - Sending the signal 15 to group 24639
2025-05-07 11:16:52,729 INFO - Process psutil.Process(pid=24639, status='terminated', exitcode=0, started='10:27:07') (24639) terminated with exit code 0
2025-05-07 11:16:52,769 INFO - Sending 15 to group 24639. PIDs of all processes in the group: []
2025-05-07 11:16:52,770 INFO - Sending the signal 15 to group 24639
2025-05-07 11:16:52,771 INFO - Sending the signal 15 to process 24639 as process group is missing.
2025-05-07 11:16:52,772 INFO - Exited execute loop
2025-05-07 14:30:24,970 INFO - Loaded executor: SequentialExecutor
2025-05-07 14:30:25,669 INFO - Starting the scheduler
2025-05-07 14:30:25,671 INFO - Processing each file at most -1 times
2025-05-07 14:30:25,684 INFO - Launched DagFileProcessorManager with pid: 37750
2025-05-07 14:30:25,686 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 14:30:25,689 INFO - Configured default timezone UTC
2025-05-07 14:30:48,267 INFO - Setting next_dagrun for anomaly_detection to 2023-01-02 00:00:00+00:00, run_after=2023-01-03 00:00:00+00:00
2025-05-07 14:30:48,854 ERROR - Failed to get task for ti <TaskInstance: anomaly_detection.extract_data manual__2025-05-07T17:17:37.273379+00:00 [None]>. Marking it as removed.
2025-05-07 14:30:48,857 ERROR - Failed to get task for ti <TaskInstance: anomaly_detection.train_predict manual__2025-05-07T17:17:37.273379+00:00 [None]>. Marking it as removed.
2025-05-07 14:30:48,857 ERROR - Failed to get task for ti <TaskInstance: anomaly_detection.detect_anomalies manual__2025-05-07T17:17:37.273379+00:00 [None]>. Marking it as removed.
2025-05-07 14:30:48,858 ERROR - Failed to get task for ti <TaskInstance: anomaly_detection.explain_anomalies manual__2025-05-07T17:17:37.273379+00:00 [None]>. Marking it as removed.
2025-05-07 14:30:49,211 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data manual__2025-05-07T17:17:37.273379+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-01T00:00:00+00:00 [scheduled]>
2025-05-07 14:30:49,212 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 14:30:49,212 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 14:30:49,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data manual__2025-05-07T17:17:37.273379+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-01T00:00:00+00:00 [scheduled]>
2025-05-07 14:30:49,216 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data manual__2025-05-07T17:17:37.273379+00:00 [scheduled]>, <TaskInstance: anomaly_detection.validate_data scheduled__2023-01-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 14:30:49,217 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='manual__2025-05-07T17:17:37.273379+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-05-07 14:30:49,217 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'manual__2025-05-07T17:17:37.273379+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:30:49,218 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 14:30:49,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:30:49,627 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'manual__2025-05-07T17:17:37.273379+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:14,050 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:25,558 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='manual__2025-05-07T17:17:37.273379+00:00', try_number=1, map_index=-1)
2025-05-07 14:31:25,559 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 14:31:25,601 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=manual__2025-05-07T17:17:37.273379+00:00, map_index=-1, run_start_date=2025-05-07 17:31:06.292825+00:00, run_end_date=2025-05-07 17:31:09.748971+00:00, run_duration=3.456146, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=160, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 17:30:49.214068+00:00, queued_by_job_id=159, pid=37883
2025-05-07 14:31:25,602 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 17:31:20.157545+00:00, run_end_date=2025-05-07 17:31:21.796470+00:00, run_duration=1.638925, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=161, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 17:30:49.214068+00:00, queued_by_job_id=159, pid=37911
2025-05-07 14:31:26,389 INFO - Heartbeat recovered after 61.91 seconds
2025-05-07 14:31:27,597 INFO - Setting next_dagrun for anomaly_detection to 2023-01-03 00:00:00+00:00, run_after=2023-01-04 00:00:00+00:00
2025-05-07 14:31:28,666 INFO - 3 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model manual__2025-05-07T17:17:37.273379+00:00 [scheduled]>
2025-05-07 14:31:28,668 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 14:31:28,669 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 14:31:28,670 INFO - DAG anomaly_detection has 2/16 running and queued tasks
2025-05-07 14:31:28,671 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model manual__2025-05-07T17:17:37.273379+00:00 [scheduled]>
2025-05-07 14:31:28,677 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-02T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-01T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model manual__2025-05-07T17:17:37.273379+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 14:31:28,679 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 14:31:28,680 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:28,680 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 14:31:28,681 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:28,682 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='manual__2025-05-07T17:17:37.273379+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 14:31:28,682 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'manual__2025-05-07T17:17:37.273379+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:28,958 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:40,275 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:31:55,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'manual__2025-05-07T17:17:37.273379+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:05,619 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 14:32:05,620 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 14:32:05,620 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='manual__2025-05-07T17:17:37.273379+00:00', try_number=1, map_index=-1)
2025-05-07 14:32:05,895 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 17:31:46.165734+00:00, run_end_date=2025-05-07 17:31:52.414816+00:00, run_duration=6.249082, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=163, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 17:31:28.673713+00:00, queued_by_job_id=159, pid=37960
2025-05-07 14:32:05,898 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=manual__2025-05-07T17:17:37.273379+00:00, map_index=-1, run_start_date=2025-05-07 17:32:00.721876+00:00, run_end_date=2025-05-07 17:32:02.819990+00:00, run_duration=2.098114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=164, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 17:31:28.673713+00:00, queued_by_job_id=159, pid=37989
2025-05-07 14:32:05,900 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 17:31:34.781986+00:00, run_end_date=2025-05-07 17:31:37.787214+00:00, run_duration=3.005228, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=162, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 17:31:28.673713+00:00, queued_by_job_id=159, pid=37936
2025-05-07 14:32:06,864 INFO - Heartbeat recovered after 41.25 seconds
2025-05-07 14:32:09,132 INFO - Setting next_dagrun for anomaly_detection to 2023-01-04 00:00:00+00:00, run_after=2023-01-05 00:00:00+00:00
2025-05-07 14:32:09,811 INFO - Marking run <DagRun anomaly_detection @ 2023-01-01 00:00:00+00:00: scheduled__2023-01-01T00:00:00+00:00, state:running, queued_at: 2025-05-07 17:30:48.246615+00:00. externally triggered: False> successful
2025-05-07 14:32:09,812 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-01 00:00:00+00:00, run_id=scheduled__2023-01-01T00:00:00+00:00, run_start_date=2025-05-07 17:30:48.496017+00:00, run_end_date=2025-05-07 17:32:09.812289+00:00, run_duration=81.316272, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-01 00:00:00+00:00, data_interval_end=2023-01-02 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 14:32:09,816 INFO - Setting next_dagrun for anomaly_detection to 2023-01-02 00:00:00+00:00, run_after=2023-01-03 00:00:00+00:00
2025-05-07 14:32:09,819 INFO - Marking run <DagRun anomaly_detection @ 2025-05-07 17:17:37.273379+00:00: manual__2025-05-07T17:17:37.273379+00:00, state:running, queued_at: 2025-05-07 17:17:37.515623+00:00. externally triggered: True> successful
2025-05-07 14:32:09,820 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2025-05-07 17:17:37.273379+00:00, run_id=manual__2025-05-07T17:17:37.273379+00:00, run_start_date=2025-05-07 17:30:48.496831+00:00, run_end_date=2025-05-07 17:32:09.820291+00:00, run_duration=81.32346, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-05-06 00:00:00+00:00, data_interval_end=2025-05-07 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 14:32:10,074 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-02T00:00:00+00:00 [scheduled]>
2025-05-07 14:32:10,074 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 14:32:10,075 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 14:32:10,076 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-02T00:00:00+00:00 [scheduled]>
2025-05-07 14:32:10,081 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-03T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 14:32:10,082 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 14:32:10,082 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:10,083 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 14:32:10,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:10,373 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:20,924 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:32,427 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 14:32:32,427 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 14:32:32,434 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 17:32:16.089097+00:00, run_end_date=2025-05-07 17:32:17.222892+00:00, run_duration=1.133795, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=165, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 17:32:10.078264+00:00, queued_by_job_id=159, pid=38021
2025-05-07 14:32:32,434 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 17:32:26.725908+00:00, run_end_date=2025-05-07 17:32:28.942631+00:00, run_duration=2.216723, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=166, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 17:32:10.078264+00:00, queued_by_job_id=159, pid=38046
2025-05-07 14:32:37,440 INFO - Setting next_dagrun for anomaly_detection to 2023-01-05 00:00:00+00:00, run_after=2023-01-06 00:00:00+00:00
2025-05-07 14:32:38,222 INFO - Marking run <DagRun anomaly_detection @ 2023-01-02 00:00:00+00:00: scheduled__2023-01-02T00:00:00+00:00, state:running, queued_at: 2025-05-07 17:31:27.568736+00:00. externally triggered: False> successful
2025-05-07 14:32:38,223 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-02 00:00:00+00:00, run_id=scheduled__2023-01-02T00:00:00+00:00, run_start_date=2025-05-07 17:31:27.909401+00:00, run_end_date=2025-05-07 17:32:38.223500+00:00, run_duration=70.314099, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-02 00:00:00+00:00, data_interval_end=2023-01-03 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 14:32:38,227 INFO - Setting next_dagrun for anomaly_detection to 2023-01-03 00:00:00+00:00, run_after=2023-01-04 00:00:00+00:00
2025-05-07 14:32:38,607 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-03T00:00:00+00:00 [scheduled]>
2025-05-07 14:32:38,608 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 14:32:38,609 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 14:32:38,609 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-03T00:00:00+00:00 [scheduled]>
2025-05-07 14:32:38,613 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-04T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 14:32:38,614 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 14:32:38,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:38,615 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 14:32:38,615 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:38,942 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:44,506 INFO - Exiting gracefully upon receiving signal 15
2025-05-07 14:32:45,536 INFO - Sending 15 to group 37750. PIDs of all processes in the group: [37750]
2025-05-07 14:32:45,537 INFO - Sending the signal 15 to group 37750
2025-05-07 14:32:46,031 INFO - Process psutil.Process(pid=37750, status='terminated', exitcode=0, started='14:30:24') (37750) terminated with exit code 0
2025-05-07 14:32:46,033 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:32:57,599 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 14:33:09,107 INFO - Sending 15 to group 37750. PIDs of all processes in the group: []
2025-05-07 14:33:09,107 INFO - Sending the signal 15 to group 37750
2025-05-07 14:33:09,108 INFO - Sending the signal 15 to process 37750 as process group is missing.
2025-05-07 14:33:09,108 INFO - Exited execute loop
2025-05-07 15:16:36,092 INFO - Loaded executor: SequentialExecutor
2025-05-07 15:16:36,504 INFO - Starting the scheduler
2025-05-07 15:16:36,508 INFO - Processing each file at most -1 times
2025-05-07 15:16:36,537 INFO - Launched DagFileProcessorManager with pid: 39318
2025-05-07 15:16:36,541 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:16:36,546 INFO - Configured default timezone UTC
2025-05-07 15:16:39,823 INFO - Setting next_dagrun for anomaly_detection to 2023-01-06 00:00:00+00:00, run_after=2023-01-07 00:00:00+00:00
2025-05-07 15:16:40,478 INFO - Marking run <DagRun anomaly_detection @ 2023-01-03 00:00:00+00:00: scheduled__2023-01-03T00:00:00+00:00, state:running, queued_at: 2025-05-07 17:32:09.128759+00:00. externally triggered: False> successful
2025-05-07 15:16:40,478 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-03 00:00:00+00:00, run_id=scheduled__2023-01-03T00:00:00+00:00, run_start_date=2025-05-07 17:32:09.472156+00:00, run_end_date=2025-05-07 18:16:40.478769+00:00, run_duration=2671.006613, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-03 00:00:00+00:00, data_interval_end=2023-01-04 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:16:40,483 INFO - Setting next_dagrun for anomaly_detection to 2023-01-04 00:00:00+00:00, run_after=2023-01-05 00:00:00+00:00
2025-05-07 15:16:41,136 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-04T00:00:00+00:00 [scheduled]>
2025-05-07 15:16:41,136 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:16:41,137 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:16:41,137 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-04T00:00:00+00:00 [scheduled]>
2025-05-07 15:16:41,140 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-05T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:16:41,141 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:16:41,142 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:16:41,142 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:16:41,142 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:16:41,468 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:16:52,996 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:05,204 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:17:05,204 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:17:05,212 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:16:59.817998+00:00, run_end_date=2025-05-07 18:17:02.519624+00:00, run_duration=2.701626, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=171, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:16:41.138559+00:00, queued_by_job_id=169, pid=39525
2025-05-07 15:17:05,213 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:16:47.032385+00:00, run_end_date=2025-05-07 18:16:50.233387+00:00, run_duration=3.201002, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=170, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:16:41.138559+00:00, queued_by_job_id=169, pid=39441
2025-05-07 15:17:05,549 INFO - Heartbeat recovered after 30.13 seconds
2025-05-07 15:17:06,037 INFO - Setting next_dagrun for anomaly_detection to 2023-01-05 00:00:00+00:00, run_after=2023-01-06 00:00:00+00:00
2025-05-07 15:17:06,280 INFO - Marking run <DagRun anomaly_detection @ 2023-01-04 00:00:00+00:00: scheduled__2023-01-04T00:00:00+00:00, state:running, queued_at: 2025-05-07 17:32:37.436336+00:00. externally triggered: False> successful
2025-05-07 15:17:06,281 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-04 00:00:00+00:00, run_id=scheduled__2023-01-04T00:00:00+00:00, run_start_date=2025-05-07 17:32:37.864279+00:00, run_end_date=2025-05-07 18:17:06.281225+00:00, run_duration=2668.416946, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-04 00:00:00+00:00, data_interval_end=2023-01-05 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:17:06,285 INFO - Setting next_dagrun for anomaly_detection to 2023-01-05 00:00:00+00:00, run_after=2023-01-06 00:00:00+00:00
2025-05-07 15:17:06,631 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-05T00:00:00+00:00 [scheduled]>
2025-05-07 15:17:06,632 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:17:06,634 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-05T00:00:00+00:00 [scheduled]>
2025-05-07 15:17:06,639 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:17:06,640 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:17:06,641 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:06,895 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:22,801 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:17:22,807 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:17:18.015850+00:00, run_end_date=2025-05-07 18:17:20.311586+00:00, run_duration=2.295736, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=172, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:17:06.635901+00:00, queued_by_job_id=169, pid=39553
2025-05-07 15:17:25,012 INFO - Setting next_dagrun for anomaly_detection to 2023-01-06 00:00:00+00:00, run_after=2023-01-07 00:00:00+00:00
2025-05-07 15:17:25,309 INFO - Marking run <DagRun anomaly_detection @ 2023-01-05 00:00:00+00:00: scheduled__2023-01-05T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:16:39.809041+00:00. externally triggered: False> successful
2025-05-07 15:17:25,310 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-05 00:00:00+00:00, run_id=scheduled__2023-01-05T00:00:00+00:00, run_start_date=2025-05-07 18:16:40.076486+00:00, run_end_date=2025-05-07 18:17:25.310279+00:00, run_duration=45.233793, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-05 00:00:00+00:00, data_interval_end=2023-01-06 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:17:25,315 INFO - Setting next_dagrun for anomaly_detection to 2023-01-06 00:00:00+00:00, run_after=2023-01-07 00:00:00+00:00
2025-05-07 15:17:30,519 INFO - Setting next_dagrun for anomaly_detection to 2023-01-07 00:00:00+00:00, run_after=2023-01-08 00:00:00+00:00
2025-05-07 15:17:31,442 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:17:31,444 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:17:31,445 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:17:31,450 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:17:31,452 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:17:31,453 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:31,750 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:41,693 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:17:41,697 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:17:37.761056+00:00, run_end_date=2025-05-07 18:17:39.225392+00:00, run_duration=1.464336, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=173, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:17:31.448151+00:00, queued_by_job_id=169, pid=39595
2025-05-07 15:17:42,758 INFO - Setting next_dagrun for anomaly_detection to 2023-01-08 00:00:00+00:00, run_after=2023-01-09 00:00:00+00:00
2025-05-07 15:17:44,114 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:17:44,115 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:17:44,116 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:17:44,117 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:17:44,120 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-07T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:17:44,121 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:17:44,121 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:44,122 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:17:44,123 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:44,469 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:17:54,146 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:03,217 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:18:03,218 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:18:03,222 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:17:59.234323+00:00, run_end_date=2025-05-07 18:18:01.120812+00:00, run_duration=1.886489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=175, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:17:44.118491+00:00, queued_by_job_id=169, pid=39641
2025-05-07 15:18:03,222 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:17:49.921468+00:00, run_end_date=2025-05-07 18:17:51.570183+00:00, run_duration=1.648715, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=174, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:17:44.118491+00:00, queued_by_job_id=169, pid=39619
2025-05-07 15:18:06,649 INFO - Setting next_dagrun for anomaly_detection to 2023-01-09 00:00:00+00:00, run_after=2023-01-10 00:00:00+00:00
2025-05-07 15:18:07,255 INFO - Marking run <DagRun anomaly_detection @ 2023-01-06 00:00:00+00:00: scheduled__2023-01-06T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:17:30.510340+00:00. externally triggered: False> successful
2025-05-07 15:18:07,255 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-06 00:00:00+00:00, run_id=scheduled__2023-01-06T00:00:00+00:00, run_start_date=2025-05-07 18:17:30.730366+00:00, run_end_date=2025-05-07 18:18:07.255646+00:00, run_duration=36.52528, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-06 00:00:00+00:00, data_interval_end=2023-01-07 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:18:07,259 INFO - Setting next_dagrun for anomaly_detection to 2023-01-07 00:00:00+00:00, run_after=2023-01-08 00:00:00+00:00
2025-05-07 15:18:07,621 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:07,622 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:18:07,623 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:18:07,623 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:07,625 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-08T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:18:07,626 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:18:07,626 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:07,627 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:18:07,627 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:07,918 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:17,572 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:26,923 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:18:26,923 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:18:26,927 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:18:12.934614+00:00, run_end_date=2025-05-07 18:18:14.666534+00:00, run_duration=1.73192, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=176, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:18:07.624746+00:00, queued_by_job_id=169, pid=39675
2025-05-07 15:18:26,928 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:18:22.707668+00:00, run_end_date=2025-05-07 18:18:24.782560+00:00, run_duration=2.074892, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=177, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:18:07.624746+00:00, queued_by_job_id=169, pid=39698
2025-05-07 15:18:28,715 INFO - Setting next_dagrun for anomaly_detection to 2023-01-08 00:00:00+00:00, run_after=2023-01-09 00:00:00+00:00
2025-05-07 15:18:29,023 INFO - Marking run <DagRun anomaly_detection @ 2023-01-07 00:00:00+00:00: scheduled__2023-01-07T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:17:42.698829+00:00. externally triggered: False> successful
2025-05-07 15:18:29,023 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-07 00:00:00+00:00, run_id=scheduled__2023-01-07T00:00:00+00:00, run_start_date=2025-05-07 18:17:43.070089+00:00, run_end_date=2025-05-07 18:18:29.023793+00:00, run_duration=45.953704, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-07 00:00:00+00:00, data_interval_end=2023-01-08 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:18:29,028 INFO - Setting next_dagrun for anomaly_detection to 2023-01-08 00:00:00+00:00, run_after=2023-01-09 00:00:00+00:00
2025-05-07 15:18:29,400 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-08T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:29,401 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:18:29,402 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-08T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:29,405 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:18:29,407 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:18:29,407 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:29,694 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:39,058 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:18:39,064 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:18:34.812827+00:00, run_end_date=2025-05-07 18:18:36.902352+00:00, run_duration=2.089525, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=178, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:18:29.403790+00:00, queued_by_job_id=169, pid=39729
2025-05-07 15:18:42,477 INFO - Setting next_dagrun for anomaly_detection to 2023-01-10 00:00:00+00:00, run_after=2023-01-11 00:00:00+00:00
2025-05-07 15:18:43,223 INFO - Marking run <DagRun anomaly_detection @ 2023-01-08 00:00:00+00:00: scheduled__2023-01-08T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:18:06.644101+00:00. externally triggered: False> successful
2025-05-07 15:18:43,224 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-08 00:00:00+00:00, run_id=scheduled__2023-01-08T00:00:00+00:00, run_start_date=2025-05-07 18:18:06.928064+00:00, run_end_date=2025-05-07 18:18:43.224115+00:00, run_duration=36.296051, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-08 00:00:00+00:00, data_interval_end=2023-01-09 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:18:43,228 INFO - Setting next_dagrun for anomaly_detection to 2023-01-09 00:00:00+00:00, run_after=2023-01-10 00:00:00+00:00
2025-05-07 15:18:43,588 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:43,589 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:18:43,590 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:43,593 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:18:43,594 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:18:43,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:43,896 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:53,283 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:18:53,288 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:18:49.031017+00:00, run_end_date=2025-05-07 18:18:50.652370+00:00, run_duration=1.621353, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=179, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:18:43.591622+00:00, queued_by_job_id=169, pid=39762
2025-05-07 15:18:54,224 INFO - Setting next_dagrun for anomaly_detection to 2023-01-10 00:00:00+00:00, run_after=2023-01-11 00:00:00+00:00
2025-05-07 15:18:54,821 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:54,822 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:18:54,823 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:18:54,827 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:18:54,828 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:18:54,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:18:55,131 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:04,503 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:19:04,507 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:19:00.205949+00:00, run_end_date=2025-05-07 18:19:02.260551+00:00, run_duration=2.054602, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=180, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:18:54.825664+00:00, queued_by_job_id=169, pid=39785
2025-05-07 15:19:06,289 INFO - Setting next_dagrun for anomaly_detection to 2023-01-11 00:00:00+00:00, run_after=2023-01-12 00:00:00+00:00
2025-05-07 15:19:06,881 INFO - Marking run <DagRun anomaly_detection @ 2023-01-09 00:00:00+00:00: scheduled__2023-01-09T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:18:42.473166+00:00. externally triggered: False> successful
2025-05-07 15:19:06,882 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-09 00:00:00+00:00, run_id=scheduled__2023-01-09T00:00:00+00:00, run_start_date=2025-05-07 18:18:42.680298+00:00, run_end_date=2025-05-07 18:19:06.882418+00:00, run_duration=24.20212, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-09 00:00:00+00:00, data_interval_end=2023-01-10 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:19:06,886 INFO - Setting next_dagrun for anomaly_detection to 2023-01-10 00:00:00+00:00, run_after=2023-01-11 00:00:00+00:00
2025-05-07 15:19:07,445 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:19:07,447 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:19:07,449 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:19:07,454 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:19:07,456 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:19:07,457 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:07,754 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:17,471 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:19:17,474 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:19:12.803084+00:00, run_end_date=2025-05-07 18:19:14.602786+00:00, run_duration=1.799702, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=181, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:19:07.452040+00:00, queued_by_job_id=169, pid=39816
2025-05-07 15:19:20,771 INFO - Setting next_dagrun for anomaly_detection to 2023-01-12 00:00:00+00:00, run_after=2023-01-13 00:00:00+00:00
2025-05-07 15:19:21,623 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:19:21,625 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:19:21,627 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:19:21,628 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:19:21,632 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-11T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:19:21,634 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:19:21,634 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:21,635 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:19:21,635 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:21,901 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:31,060 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:40,096 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:19:40,096 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:19:40,100 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:19:27.061127+00:00, run_end_date=2025-05-07 18:19:28.634905+00:00, run_duration=1.573778, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=182, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:19:21.630795+00:00, queued_by_job_id=169, pid=39848
2025-05-07 15:19:40,101 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:19:36.069777+00:00, run_end_date=2025-05-07 18:19:37.940671+00:00, run_duration=1.870894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=183, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:19:21.630795+00:00, queued_by_job_id=169, pid=39870
2025-05-07 15:19:41,278 INFO - Setting next_dagrun for anomaly_detection to 2023-01-13 00:00:00+00:00, run_after=2023-01-14 00:00:00+00:00
2025-05-07 15:19:42,077 INFO - Marking run <DagRun anomaly_detection @ 2023-01-10 00:00:00+00:00: scheduled__2023-01-10T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:19:06.277745+00:00. externally triggered: False> successful
2025-05-07 15:19:42,077 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-10 00:00:00+00:00, run_id=scheduled__2023-01-10T00:00:00+00:00, run_start_date=2025-05-07 18:19:06.487932+00:00, run_end_date=2025-05-07 18:19:42.077790+00:00, run_duration=35.589858, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-10 00:00:00+00:00, data_interval_end=2023-01-11 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:19:42,082 INFO - Setting next_dagrun for anomaly_detection to 2023-01-11 00:00:00+00:00, run_after=2023-01-12 00:00:00+00:00
2025-05-07 15:19:42,689 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:19:42,690 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:19:42,691 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:19:42,691 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:19:42,695 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-12T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:19:42,695 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:19:42,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:42,697 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:19:42,698 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:43,143 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:19:52,363 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:01,493 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:20:01,493 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:20:01,498 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:19:57.409670+00:00, run_end_date=2025-05-07 18:19:59.298962+00:00, run_duration=1.889292, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=185, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:19:42.693424+00:00, queued_by_job_id=169, pid=39916
2025-05-07 15:20:01,499 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:19:48.308372+00:00, run_end_date=2025-05-07 18:19:49.938844+00:00, run_duration=1.630472, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=184, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:19:42.693424+00:00, queued_by_job_id=169, pid=39894
2025-05-07 15:20:03,023 INFO - Setting next_dagrun for anomaly_detection to 2023-01-12 00:00:00+00:00, run_after=2023-01-13 00:00:00+00:00
2025-05-07 15:20:03,276 INFO - Marking run <DagRun anomaly_detection @ 2023-01-11 00:00:00+00:00: scheduled__2023-01-11T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:19:20.766347+00:00. externally triggered: False> successful
2025-05-07 15:20:03,277 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-11 00:00:00+00:00, run_id=scheduled__2023-01-11T00:00:00+00:00, run_start_date=2025-05-07 18:19:21.028035+00:00, run_end_date=2025-05-07 18:20:03.276953+00:00, run_duration=42.248918, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-11 00:00:00+00:00, data_interval_end=2023-01-12 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:20:03,280 INFO - Setting next_dagrun for anomaly_detection to 2023-01-12 00:00:00+00:00, run_after=2023-01-13 00:00:00+00:00
2025-05-07 15:20:03,680 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-12T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:03,681 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:20:03,682 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-12T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:03,685 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:20:03,685 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:20:03,686 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:03,992 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:13,857 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:20:13,861 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:20:09.055854+00:00, run_end_date=2025-05-07 18:20:11.467995+00:00, run_duration=2.412141, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=186, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:20:03.683608+00:00, queued_by_job_id=169, pid=39951
2025-05-07 15:20:17,193 INFO - Setting next_dagrun for anomaly_detection to 2023-01-14 00:00:00+00:00, run_after=2023-01-15 00:00:00+00:00
2025-05-07 15:20:17,825 INFO - Marking run <DagRun anomaly_detection @ 2023-01-12 00:00:00+00:00: scheduled__2023-01-12T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:19:41.273017+00:00. externally triggered: False> successful
2025-05-07 15:20:17,826 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-12 00:00:00+00:00, run_id=scheduled__2023-01-12T00:00:00+00:00, run_start_date=2025-05-07 18:19:41.584623+00:00, run_end_date=2025-05-07 18:20:17.826495+00:00, run_duration=36.241872, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-12 00:00:00+00:00, data_interval_end=2023-01-13 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:20:17,830 INFO - Setting next_dagrun for anomaly_detection to 2023-01-13 00:00:00+00:00, run_after=2023-01-14 00:00:00+00:00
2025-05-07 15:20:18,189 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:18,190 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:20:18,191 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:18,192 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-13T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:20:18,193 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:20:18,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:18,642 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:28,331 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:20:28,336 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:20:23.916031+00:00, run_end_date=2025-05-07 18:20:25.590618+00:00, run_duration=1.674587, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=187, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:20:18.191805+00:00, queued_by_job_id=169, pid=40019
2025-05-07 15:20:29,400 INFO - Setting next_dagrun for anomaly_detection to 2023-01-14 00:00:00+00:00, run_after=2023-01-15 00:00:00+00:00
2025-05-07 15:20:30,020 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:30,021 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:20:30,023 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:30,027 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-13T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:20:30,028 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:20:30,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:30,394 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:39,630 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:20:39,636 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:20:35.489823+00:00, run_end_date=2025-05-07 18:20:37.525856+00:00, run_duration=2.036033, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=188, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:20:30.025412+00:00, queued_by_job_id=169, pid=40042
2025-05-07 15:20:41,203 INFO - Setting next_dagrun for anomaly_detection to 2023-01-15 00:00:00+00:00, run_after=2023-01-16 00:00:00+00:00
2025-05-07 15:20:41,756 INFO - Marking run <DagRun anomaly_detection @ 2023-01-13 00:00:00+00:00: scheduled__2023-01-13T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:20:17.190579+00:00. externally triggered: False> successful
2025-05-07 15:20:41,756 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-13 00:00:00+00:00, run_id=scheduled__2023-01-13T00:00:00+00:00, run_start_date=2025-05-07 18:20:17.420492+00:00, run_end_date=2025-05-07 18:20:41.756786+00:00, run_duration=24.336294, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-13 00:00:00+00:00, data_interval_end=2023-01-14 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:20:41,761 INFO - Setting next_dagrun for anomaly_detection to 2023-01-14 00:00:00+00:00, run_after=2023-01-15 00:00:00+00:00
2025-05-07 15:20:42,156 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:42,157 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:20:42,158 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:42,161 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:20:42,162 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:20:42,162 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:42,488 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:52,010 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:20:52,014 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:20:48.034174+00:00, run_end_date=2025-05-07 18:20:49.554208+00:00, run_duration=1.520034, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=189, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:20:42.159235+00:00, queued_by_job_id=169, pid=40074
2025-05-07 15:20:55,422 INFO - Setting next_dagrun for anomaly_detection to 2023-01-16 00:00:00+00:00, run_after=2023-01-17 00:00:00+00:00
2025-05-07 15:20:56,284 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:56,286 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:20:56,286 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:20:56,288 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:20:56,291 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-15T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:20:56,292 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:20:56,293 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:56,294 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:20:56,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:20:56,583 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:05,774 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:16,622 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:21:16,622 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:21:16,627 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:21:11.556686+00:00, run_end_date=2025-05-07 18:21:13.905595+00:00, run_duration=2.348909, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=191, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:20:56.289854+00:00, queued_by_job_id=169, pid=40134
2025-05-07 15:21:16,628 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:21:01.682219+00:00, run_end_date=2025-05-07 18:21:03.266112+00:00, run_duration=1.583893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=190, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:20:56.289854+00:00, queued_by_job_id=169, pid=40112
2025-05-07 15:21:17,774 INFO - Setting next_dagrun for anomaly_detection to 2023-01-17 00:00:00+00:00, run_after=2023-01-18 00:00:00+00:00
2025-05-07 15:21:18,697 INFO - Marking run <DagRun anomaly_detection @ 2023-01-14 00:00:00+00:00: scheduled__2023-01-14T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:20:41.198889+00:00. externally triggered: False> successful
2025-05-07 15:21:18,698 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-14 00:00:00+00:00, run_id=scheduled__2023-01-14T00:00:00+00:00, run_start_date=2025-05-07 18:20:41.411549+00:00, run_end_date=2025-05-07 18:21:18.698098+00:00, run_duration=37.286549, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-14 00:00:00+00:00, data_interval_end=2023-01-15 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:21:18,701 INFO - Setting next_dagrun for anomaly_detection to 2023-01-15 00:00:00+00:00, run_after=2023-01-16 00:00:00+00:00
2025-05-07 15:21:19,286 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:21:19,288 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:21:19,289 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:21:19,291 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:21:19,299 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-16T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-15T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:21:19,302 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:21:19,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:19,304 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:21:19,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:19,585 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:30,690 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:41,518 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:21:41,519 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:21:41,525 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:21:36.587461+00:00, run_end_date=2025-05-07 18:21:38.846732+00:00, run_duration=2.259271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=193, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:21:19.295071+00:00, queued_by_job_id=169, pid=40183
2025-05-07 15:21:41,526 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:21:26.134540+00:00, run_end_date=2025-05-07 18:21:27.985960+00:00, run_duration=1.85142, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=192, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:21:19.295071+00:00, queued_by_job_id=169, pid=40161
2025-05-07 15:21:41,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:21:43,253 INFO - Setting next_dagrun for anomaly_detection to 2023-01-16 00:00:00+00:00, run_after=2023-01-17 00:00:00+00:00
2025-05-07 15:21:43,510 INFO - Marking run <DagRun anomaly_detection @ 2023-01-15 00:00:00+00:00: scheduled__2023-01-15T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:20:55.419177+00:00. externally triggered: False> successful
2025-05-07 15:21:43,511 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-15 00:00:00+00:00, run_id=scheduled__2023-01-15T00:00:00+00:00, run_start_date=2025-05-07 18:20:55.653988+00:00, run_end_date=2025-05-07 18:21:43.511297+00:00, run_duration=47.857309, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-15 00:00:00+00:00, data_interval_end=2023-01-16 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:21:43,514 INFO - Setting next_dagrun for anomaly_detection to 2023-01-16 00:00:00+00:00, run_after=2023-01-17 00:00:00+00:00
2025-05-07 15:21:43,831 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-16T00:00:00+00:00 [scheduled]>
2025-05-07 15:21:43,831 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:21:43,832 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-16T00:00:00+00:00 [scheduled]>
2025-05-07 15:21:43,833 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-16T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:21:43,834 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:21:43,834 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:44,572 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:21:56,108 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:21:56,112 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:21:50.459301+00:00, run_end_date=2025-05-07 18:21:53.478940+00:00, run_duration=3.019639, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=194, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:21:43.832842+00:00, queued_by_job_id=169, pid=40214
2025-05-07 15:22:00,011 INFO - Setting next_dagrun for anomaly_detection to 2023-01-18 00:00:00+00:00, run_after=2023-01-19 00:00:00+00:00
2025-05-07 15:22:00,564 INFO - Marking run <DagRun anomaly_detection @ 2023-01-16 00:00:00+00:00: scheduled__2023-01-16T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:21:17.767811+00:00. externally triggered: False> successful
2025-05-07 15:22:00,564 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-16 00:00:00+00:00, run_id=scheduled__2023-01-16T00:00:00+00:00, run_start_date=2025-05-07 18:21:18.086078+00:00, run_end_date=2025-05-07 18:22:00.564917+00:00, run_duration=42.478839, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-16 00:00:00+00:00, data_interval_end=2023-01-17 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:22:00,568 INFO - Setting next_dagrun for anomaly_detection to 2023-01-17 00:00:00+00:00, run_after=2023-01-18 00:00:00+00:00
2025-05-07 15:22:00,880 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:00,881 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:22:00,881 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:00,883 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-17T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:22:00,884 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:22:00,884 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:01,191 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:10,987 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:22:10,990 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:22:06.766755+00:00, run_end_date=2025-05-07 18:22:08.302151+00:00, run_duration=1.535396, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=195, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:22:00.882531+00:00, queued_by_job_id=169, pid=40247
2025-05-07 15:22:12,099 INFO - Setting next_dagrun for anomaly_detection to 2023-01-18 00:00:00+00:00, run_after=2023-01-19 00:00:00+00:00
2025-05-07 15:22:13,088 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:13,088 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:22:13,089 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:13,092 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-17T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:22:13,093 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:22:13,094 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:13,372 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:24,506 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:22:24,510 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:22:18.900579+00:00, run_end_date=2025-05-07 18:22:21.096358+00:00, run_duration=2.195779, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=196, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:22:13.091049+00:00, queued_by_job_id=169, pid=40272
2025-05-07 15:22:26,058 INFO - Setting next_dagrun for anomaly_detection to 2023-01-19 00:00:00+00:00, run_after=2023-01-20 00:00:00+00:00
2025-05-07 15:22:26,682 INFO - Marking run <DagRun anomaly_detection @ 2023-01-17 00:00:00+00:00: scheduled__2023-01-17T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:22:00.007135+00:00. externally triggered: False> successful
2025-05-07 15:22:26,683 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-17 00:00:00+00:00, run_id=scheduled__2023-01-17T00:00:00+00:00, run_start_date=2025-05-07 18:22:00.229392+00:00, run_end_date=2025-05-07 18:22:26.683494+00:00, run_duration=26.454102, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-17 00:00:00+00:00, data_interval_end=2023-01-18 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:22:26,688 INFO - Setting next_dagrun for anomaly_detection to 2023-01-18 00:00:00+00:00, run_after=2023-01-19 00:00:00+00:00
2025-05-07 15:22:27,092 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:27,094 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:22:27,096 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:27,100 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:22:27,101 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:22:27,102 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:27,400 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:38,573 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:22:38,577 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:22:32.920004+00:00, run_end_date=2025-05-07 18:22:35.629246+00:00, run_duration=2.709242, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=197, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:22:27.098545+00:00, queued_by_job_id=169, pid=40304
2025-05-07 15:22:42,372 INFO - Setting next_dagrun for anomaly_detection to 2023-01-20 00:00:00+00:00, run_after=2023-01-21 00:00:00+00:00
2025-05-07 15:22:43,383 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:43,384 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:22:43,384 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:22:43,384 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:22:43,386 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-19T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:22:43,386 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:22:43,386 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:43,387 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:22:43,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:43,685 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:22:53,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:03,828 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:23:03,829 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:23:03,856 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:22:59.660905+00:00, run_end_date=2025-05-07 18:23:01.546012+00:00, run_duration=1.885107, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=199, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:22:43.385412+00:00, queued_by_job_id=169, pid=40358
2025-05-07 15:23:03,858 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:22:49.596943+00:00, run_end_date=2025-05-07 18:22:51.242277+00:00, run_duration=1.645334, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=198, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:22:43.385412+00:00, queued_by_job_id=169, pid=40336
2025-05-07 15:23:05,762 INFO - Setting next_dagrun for anomaly_detection to 2023-01-21 00:00:00+00:00, run_after=2023-01-22 00:00:00+00:00
2025-05-07 15:23:06,333 INFO - Marking run <DagRun anomaly_detection @ 2023-01-18 00:00:00+00:00: scheduled__2023-01-18T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:22:26.045011+00:00. externally triggered: False> successful
2025-05-07 15:23:06,334 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-18 00:00:00+00:00, run_id=scheduled__2023-01-18T00:00:00+00:00, run_start_date=2025-05-07 18:22:26.357813+00:00, run_end_date=2025-05-07 18:23:06.333872+00:00, run_duration=39.976059, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-18 00:00:00+00:00, data_interval_end=2023-01-19 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:23:06,338 INFO - Setting next_dagrun for anomaly_detection to 2023-01-19 00:00:00+00:00, run_after=2023-01-20 00:00:00+00:00
2025-05-07 15:23:06,672 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:06,673 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:23:06,674 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:23:06,675 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:06,679 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-20T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-19T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:23:06,680 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:23:06,680 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:06,681 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:23:06,682 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:07,013 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:16,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:28,513 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:23:28,513 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:23:28,759 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:23:12.594187+00:00, run_end_date=2025-05-07 18:23:14.164294+00:00, run_duration=1.570107, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=200, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:23:06.676858+00:00, queued_by_job_id=169, pid=40383
2025-05-07 15:23:28,763 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:23:23.611990+00:00, run_end_date=2025-05-07 18:23:26.019080+00:00, run_duration=2.40709, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=201, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:23:06.676858+00:00, queued_by_job_id=169, pid=40406
2025-05-07 15:23:30,426 INFO - Setting next_dagrun for anomaly_detection to 2023-01-20 00:00:00+00:00, run_after=2023-01-21 00:00:00+00:00
2025-05-07 15:23:30,687 INFO - Marking run <DagRun anomaly_detection @ 2023-01-19 00:00:00+00:00: scheduled__2023-01-19T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:22:42.368564+00:00. externally triggered: False> successful
2025-05-07 15:23:30,687 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-19 00:00:00+00:00, run_id=scheduled__2023-01-19T00:00:00+00:00, run_start_date=2025-05-07 18:22:42.593684+00:00, run_end_date=2025-05-07 18:23:30.687743+00:00, run_duration=48.094059, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-19 00:00:00+00:00, data_interval_end=2023-01-20 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:23:30,692 INFO - Setting next_dagrun for anomaly_detection to 2023-01-20 00:00:00+00:00, run_after=2023-01-21 00:00:00+00:00
2025-05-07 15:23:31,023 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-20T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:31,024 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:23:31,025 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-20T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:31,027 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:23:31,028 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:23:31,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:31,321 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:41,555 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:23:41,560 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:23:36.808135+00:00, run_end_date=2025-05-07 18:23:38.834392+00:00, run_duration=2.026257, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=202, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:23:31.026496+00:00, queued_by_job_id=169, pid=40437
2025-05-07 15:23:44,856 INFO - Setting next_dagrun for anomaly_detection to 2023-01-22 00:00:00+00:00, run_after=2023-01-23 00:00:00+00:00
2025-05-07 15:23:45,417 INFO - Marking run <DagRun anomaly_detection @ 2023-01-20 00:00:00+00:00: scheduled__2023-01-20T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:23:05.746223+00:00. externally triggered: False> successful
2025-05-07 15:23:45,418 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-20 00:00:00+00:00, run_id=scheduled__2023-01-20T00:00:00+00:00, run_start_date=2025-05-07 18:23:06.003460+00:00, run_end_date=2025-05-07 18:23:45.417966+00:00, run_duration=39.414506, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-20 00:00:00+00:00, data_interval_end=2023-01-21 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:23:45,422 INFO - Setting next_dagrun for anomaly_detection to 2023-01-21 00:00:00+00:00, run_after=2023-01-22 00:00:00+00:00
2025-05-07 15:23:45,722 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:45,723 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:23:45,724 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:45,727 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:23:45,728 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:23:45,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:46,158 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:56,461 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:23:56,465 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:23:52.328812+00:00, run_end_date=2025-05-07 18:23:53.883601+00:00, run_duration=1.554789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=203, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:23:45.726198+00:00, queued_by_job_id=169, pid=40469
2025-05-07 15:23:57,340 INFO - Setting next_dagrun for anomaly_detection to 2023-01-22 00:00:00+00:00, run_after=2023-01-23 00:00:00+00:00
2025-05-07 15:23:58,271 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:58,273 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:23:58,275 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:23:59,012 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:23:59,014 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:23:59,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:23:59,324 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:09,223 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:24:09,227 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:24:05.189994+00:00, run_end_date=2025-05-07 18:24:07.081595+00:00, run_duration=1.891601, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=204, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:23:58.277472+00:00, queued_by_job_id=169, pid=40492
2025-05-07 15:24:11,653 INFO - Setting next_dagrun for anomaly_detection to 2023-01-23 00:00:00+00:00, run_after=2023-01-24 00:00:00+00:00
2025-05-07 15:24:12,218 INFO - Marking run <DagRun anomaly_detection @ 2023-01-21 00:00:00+00:00: scheduled__2023-01-21T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:23:44.846997+00:00. externally triggered: False> successful
2025-05-07 15:24:12,218 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-21 00:00:00+00:00, run_id=scheduled__2023-01-21T00:00:00+00:00, run_start_date=2025-05-07 18:23:45.097763+00:00, run_end_date=2025-05-07 18:24:12.218657+00:00, run_duration=27.120894, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-21 00:00:00+00:00, data_interval_end=2023-01-22 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:24:12,222 INFO - Setting next_dagrun for anomaly_detection to 2023-01-22 00:00:00+00:00, run_after=2023-01-23 00:00:00+00:00
2025-05-07 15:24:12,536 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:24:12,538 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:24:12,539 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:24:12,544 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:24:12,545 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:24:12,546 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:12,833 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:23,436 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:24:23,627 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:24:18.581085+00:00, run_end_date=2025-05-07 18:24:20.231121+00:00, run_duration=1.650036, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=205, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:24:12.541789+00:00, queued_by_job_id=169, pid=40526
2025-05-07 15:24:26,969 INFO - Setting next_dagrun for anomaly_detection to 2023-01-24 00:00:00+00:00, run_after=2023-01-25 00:00:00+00:00
2025-05-07 15:24:28,248 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:24:28,249 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:24:28,250 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:24:28,251 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:24:28,255 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-23T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:24:28,256 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:24:28,257 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:28,258 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:24:28,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:28,631 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:40,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:52,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:24:52,923 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:24:53,041 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:24:45.800074+00:00, run_end_date=2025-05-07 18:24:49.708788+00:00, run_duration=3.908714, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=207, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:24:28.253309+00:00, queued_by_job_id=169, pid=40579
2025-05-07 15:24:53,044 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:24:35.552094+00:00, run_end_date=2025-05-07 18:24:37.413930+00:00, run_duration=1.861836, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=206, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:24:28.253309+00:00, queued_by_job_id=169, pid=40557
2025-05-07 15:24:54,283 INFO - Setting next_dagrun for anomaly_detection to 2023-01-25 00:00:00+00:00, run_after=2023-01-26 00:00:00+00:00
2025-05-07 15:24:54,902 INFO - Marking run <DagRun anomaly_detection @ 2023-01-22 00:00:00+00:00: scheduled__2023-01-22T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:24:11.650194+00:00. externally triggered: False> successful
2025-05-07 15:24:54,903 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-22 00:00:00+00:00, run_id=scheduled__2023-01-22T00:00:00+00:00, run_start_date=2025-05-07 18:24:11.859768+00:00, run_end_date=2025-05-07 18:24:54.903137+00:00, run_duration=43.043369, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-22 00:00:00+00:00, data_interval_end=2023-01-23 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:24:54,907 INFO - Setting next_dagrun for anomaly_detection to 2023-01-23 00:00:00+00:00, run_after=2023-01-24 00:00:00+00:00
2025-05-07 15:24:55,417 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:24:55,418 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:24:55,418 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:24:55,419 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:24:55,422 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-24T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:24:55,423 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:24:55,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:55,425 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:24:55,426 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:24:55,803 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:06,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:15,342 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:25:15,342 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:25:15,346 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:25:11.302471+00:00, run_end_date=2025-05-07 18:25:13.204677+00:00, run_duration=1.902206, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=209, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:24:55.420970+00:00, queued_by_job_id=169, pid=40629
2025-05-07 15:25:15,347 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:25:01.244013+00:00, run_end_date=2025-05-07 18:25:02.958548+00:00, run_duration=1.714535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=208, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:24:55.420970+00:00, queued_by_job_id=169, pid=40607
2025-05-07 15:25:17,365 INFO - Setting next_dagrun for anomaly_detection to 2023-01-24 00:00:00+00:00, run_after=2023-01-25 00:00:00+00:00
2025-05-07 15:25:17,631 INFO - Marking run <DagRun anomaly_detection @ 2023-01-23 00:00:00+00:00: scheduled__2023-01-23T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:24:26.966447+00:00. externally triggered: False> successful
2025-05-07 15:25:17,632 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-23 00:00:00+00:00, run_id=scheduled__2023-01-23T00:00:00+00:00, run_start_date=2025-05-07 18:24:27.473140+00:00, run_end_date=2025-05-07 18:25:17.631965+00:00, run_duration=50.158825, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-23 00:00:00+00:00, data_interval_end=2023-01-24 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:25:17,637 INFO - Setting next_dagrun for anomaly_detection to 2023-01-24 00:00:00+00:00, run_after=2023-01-25 00:00:00+00:00
2025-05-07 15:25:17,960 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-24T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:17,962 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:25:17,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-24T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:17,968 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-24T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:25:17,970 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:25:17,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:18,329 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:28,687 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:25:28,752 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:25:23.993758+00:00, run_end_date=2025-05-07 18:25:26.270406+00:00, run_duration=2.276648, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=210, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:25:17.965338+00:00, queued_by_job_id=169, pid=40691
2025-05-07 15:25:32,333 INFO - Setting next_dagrun for anomaly_detection to 2023-01-26 00:00:00+00:00, run_after=2023-01-27 00:00:00+00:00
2025-05-07 15:25:32,904 INFO - Marking run <DagRun anomaly_detection @ 2023-01-24 00:00:00+00:00: scheduled__2023-01-24T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:24:54.278218+00:00. externally triggered: False> successful
2025-05-07 15:25:32,905 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-24 00:00:00+00:00, run_id=scheduled__2023-01-24T00:00:00+00:00, run_start_date=2025-05-07 18:24:54.512878+00:00, run_end_date=2025-05-07 18:25:32.905180+00:00, run_duration=38.392302, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-24 00:00:00+00:00, data_interval_end=2023-01-25 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:25:32,909 INFO - Setting next_dagrun for anomaly_detection to 2023-01-25 00:00:00+00:00, run_after=2023-01-26 00:00:00+00:00
2025-05-07 15:25:33,221 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:33,221 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:25:33,222 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:33,225 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-25T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:25:33,226 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:25:33,227 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:33,520 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:43,271 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:25:43,274 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:25:39.191014+00:00, run_end_date=2025-05-07 18:25:40.764861+00:00, run_duration=1.573847, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=211, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:25:33.224317+00:00, queued_by_job_id=169, pid=40723
2025-05-07 15:25:44,211 INFO - Setting next_dagrun for anomaly_detection to 2023-01-26 00:00:00+00:00, run_after=2023-01-27 00:00:00+00:00
2025-05-07 15:25:44,783 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:44,784 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:25:44,786 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:44,788 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-25T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:25:44,789 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:25:44,790 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:45,115 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:56,024 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:25:56,028 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:25:50.538681+00:00, run_end_date=2025-05-07 18:25:53.859419+00:00, run_duration=3.320738, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=212, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:25:44.787492+00:00, queued_by_job_id=169, pid=40746
2025-05-07 15:25:57,549 INFO - Setting next_dagrun for anomaly_detection to 2023-01-27 00:00:00+00:00, run_after=2023-01-28 00:00:00+00:00
2025-05-07 15:25:58,179 INFO - Marking run <DagRun anomaly_detection @ 2023-01-25 00:00:00+00:00: scheduled__2023-01-25T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:25:32.329174+00:00. externally triggered: False> successful
2025-05-07 15:25:58,180 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-25 00:00:00+00:00, run_id=scheduled__2023-01-25T00:00:00+00:00, run_start_date=2025-05-07 18:25:32.576226+00:00, run_end_date=2025-05-07 18:25:58.179948+00:00, run_duration=25.603722, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-25 00:00:00+00:00, data_interval_end=2023-01-26 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:25:58,184 INFO - Setting next_dagrun for anomaly_detection to 2023-01-26 00:00:00+00:00, run_after=2023-01-27 00:00:00+00:00
2025-05-07 15:25:58,638 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:58,639 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:25:58,639 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:25:58,642 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:25:58,643 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:25:58,643 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:25:58,928 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:08,946 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:26:08,950 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:26:04.289666+00:00, run_end_date=2025-05-07 18:26:06.522559+00:00, run_duration=2.232893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=213, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:25:58.640729+00:00, queued_by_job_id=169, pid=40780
2025-05-07 15:26:12,607 INFO - Setting next_dagrun for anomaly_detection to 2023-01-28 00:00:00+00:00, run_after=2023-01-29 00:00:00+00:00
2025-05-07 15:26:13,639 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:26:13,640 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:26:13,641 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:26:13,643 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:26:13,647 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-27T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:26:13,648 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:26:13,649 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:13,650 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:26:13,650 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:13,945 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:24,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:35,075 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-27T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:26:35,076 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:26:35,080 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:26:30.596571+00:00, run_end_date=2025-05-07 18:26:32.561381+00:00, run_duration=1.96481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=215, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:26:13.645167+00:00, queued_by_job_id=169, pid=40836
2025-05-07 15:26:35,081 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-27T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:26:19.394499+00:00, run_end_date=2025-05-07 18:26:21.204567+00:00, run_duration=1.810068, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=214, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:26:13.645167+00:00, queued_by_job_id=169, pid=40814
2025-05-07 15:26:36,007 INFO - Setting next_dagrun for anomaly_detection to 2023-01-29 00:00:00+00:00, run_after=2023-01-30 00:00:00+00:00
2025-05-07 15:26:36,783 INFO - Marking run <DagRun anomaly_detection @ 2023-01-26 00:00:00+00:00: scheduled__2023-01-26T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:25:57.545616+00:00. externally triggered: False> successful
2025-05-07 15:26:36,784 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-26 00:00:00+00:00, run_id=scheduled__2023-01-26T00:00:00+00:00, run_start_date=2025-05-07 18:25:57.778321+00:00, run_end_date=2025-05-07 18:26:36.784518+00:00, run_duration=39.006197, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-26 00:00:00+00:00, data_interval_end=2023-01-27 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:26:36,788 INFO - Setting next_dagrun for anomaly_detection to 2023-01-27 00:00:00+00:00, run_after=2023-01-28 00:00:00+00:00
2025-05-07 15:26:37,132 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:26:37,133 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:26:37,134 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:26:37,135 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:26:37,138 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-28T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-27T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:26:37,139 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:26:37,140 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:37,140 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:26:37,141 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:37,461 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:47,745 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:26:57,561 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-28T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:26:57,561 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-27T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:26:57,568 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-28T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:26:43.004321+00:00, run_end_date=2025-05-07 18:26:44.795694+00:00, run_duration=1.791373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=216, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:26:37.136965+00:00, queued_by_job_id=169, pid=40860
2025-05-07 15:26:57,569 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-27T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:26:53.252556+00:00, run_end_date=2025-05-07 18:26:55.347461+00:00, run_duration=2.094905, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=217, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:26:37.136965+00:00, queued_by_job_id=169, pid=40882
2025-05-07 15:26:59,119 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:27:00,291 INFO - Setting next_dagrun for anomaly_detection to 2023-01-28 00:00:00+00:00, run_after=2023-01-29 00:00:00+00:00
2025-05-07 15:27:00,527 INFO - Marking run <DagRun anomaly_detection @ 2023-01-27 00:00:00+00:00: scheduled__2023-01-27T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:26:12.603710+00:00. externally triggered: False> successful
2025-05-07 15:27:00,528 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-27 00:00:00+00:00, run_id=scheduled__2023-01-27T00:00:00+00:00, run_start_date=2025-05-07 18:26:12.860232+00:00, run_end_date=2025-05-07 18:27:00.527950+00:00, run_duration=47.667718, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-27 00:00:00+00:00, data_interval_end=2023-01-28 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:27:00,531 INFO - Setting next_dagrun for anomaly_detection to 2023-01-28 00:00:00+00:00, run_after=2023-01-29 00:00:00+00:00
2025-05-07 15:27:01,022 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-28T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:01,024 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:27:01,026 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-28T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:01,030 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-28T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:27:01,031 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:27:01,032 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:01,342 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:10,883 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-28T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:27:10,887 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-28T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:27:06.823172+00:00, run_end_date=2025-05-07 18:27:08.710589+00:00, run_duration=1.887417, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=218, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:27:01.028227+00:00, queued_by_job_id=169, pid=40914
2025-05-07 15:27:14,378 INFO - Setting next_dagrun for anomaly_detection to 2023-01-30 00:00:00+00:00, run_after=2023-01-31 00:00:00+00:00
2025-05-07 15:27:15,061 INFO - Marking run <DagRun anomaly_detection @ 2023-01-28 00:00:00+00:00: scheduled__2023-01-28T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:26:36.004032+00:00. externally triggered: False> successful
2025-05-07 15:27:15,062 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-28 00:00:00+00:00, run_id=scheduled__2023-01-28T00:00:00+00:00, run_start_date=2025-05-07 18:26:36.344303+00:00, run_end_date=2025-05-07 18:27:15.062173+00:00, run_duration=38.71787, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-28 00:00:00+00:00, data_interval_end=2023-01-29 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:27:15,067 INFO - Setting next_dagrun for anomaly_detection to 2023-01-29 00:00:00+00:00, run_after=2023-01-30 00:00:00+00:00
2025-05-07 15:27:15,369 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-29T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:15,371 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:27:15,372 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-29T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:15,375 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-29T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:27:15,376 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-29T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:27:15,377 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:15,656 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:26,477 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-29T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:27:26,481 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-29T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:27:20.978457+00:00, run_end_date=2025-05-07 18:27:23.838717+00:00, run_duration=2.86026, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=219, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:27:15.373479+00:00, queued_by_job_id=169, pid=40947
2025-05-07 15:27:27,246 INFO - Setting next_dagrun for anomaly_detection to 2023-01-30 00:00:00+00:00, run_after=2023-01-31 00:00:00+00:00
2025-05-07 15:27:27,868 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-29T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:27,869 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:27:27,869 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-29T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:27,873 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-01-29T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:27:27,875 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-29T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:27:27,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:28,343 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:39,281 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-29T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:27:39,284 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-29T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:27:33.971600+00:00, run_end_date=2025-05-07 18:27:37.098349+00:00, run_duration=3.126749, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=220, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:27:27.871445+00:00, queued_by_job_id=169, pid=40970
2025-05-07 15:27:41,535 INFO - Setting next_dagrun for anomaly_detection to 2023-01-31 00:00:00+00:00, run_after=2023-02-01 00:00:00+00:00
2025-05-07 15:27:42,040 INFO - Marking run <DagRun anomaly_detection @ 2023-01-29 00:00:00+00:00: scheduled__2023-01-29T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:27:14.372951+00:00. externally triggered: False> successful
2025-05-07 15:27:42,041 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-29 00:00:00+00:00, run_id=scheduled__2023-01-29T00:00:00+00:00, run_start_date=2025-05-07 18:27:14.747379+00:00, run_end_date=2025-05-07 18:27:42.041410+00:00, run_duration=27.294031, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-29 00:00:00+00:00, data_interval_end=2023-01-30 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:27:42,044 INFO - Setting next_dagrun for anomaly_detection to 2023-01-30 00:00:00+00:00, run_after=2023-01-31 00:00:00+00:00
2025-05-07 15:27:42,343 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-30T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:42,344 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:27:42,346 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-30T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:42,350 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:27:42,352 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:27:42,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:42,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:52,760 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-30T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:27:52,765 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-30T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:27:48.362804+00:00, run_end_date=2025-05-07 18:27:49.837959+00:00, run_duration=1.475155, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=221, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:27:42.348342+00:00, queued_by_job_id=169, pid=41001
2025-05-07 15:27:56,232 INFO - Setting next_dagrun for anomaly_detection to 2023-02-01 00:00:00+00:00, run_after=2023-02-02 00:00:00+00:00
2025-05-07 15:27:57,397 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-30T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:57,398 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:27:57,400 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:27:57,401 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-30T00:00:00+00:00 [scheduled]>
2025-05-07 15:27:57,406 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-01-31T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:27:57,407 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-31T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:27:57,408 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:57,409 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:27:57,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:27:57,693 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-01-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:08,533 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:19,652 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-01-31T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:28:19,652 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-30T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:28:19,657 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-01-31T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:28:03.190085+00:00, run_end_date=2025-05-07 18:28:05.831833+00:00, run_duration=2.641748, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=222, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:27:57.404400+00:00, queued_by_job_id=169, pid=41033
2025-05-07 15:28:19,657 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-30T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:28:14.456773+00:00, run_end_date=2025-05-07 18:28:17.439044+00:00, run_duration=2.982271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=223, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:27:57.404400+00:00, queued_by_job_id=169, pid=41055
2025-05-07 15:28:20,473 INFO - Setting next_dagrun for anomaly_detection to 2023-02-02 00:00:00+00:00, run_after=2023-02-03 00:00:00+00:00
2025-05-07 15:28:21,173 INFO - Marking run <DagRun anomaly_detection @ 2023-01-30 00:00:00+00:00: scheduled__2023-01-30T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:27:41.529046+00:00. externally triggered: False> successful
2025-05-07 15:28:21,174 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-30 00:00:00+00:00, run_id=scheduled__2023-01-30T00:00:00+00:00, run_start_date=2025-05-07 18:27:41.747806+00:00, run_end_date=2025-05-07 18:28:21.173959+00:00, run_duration=39.426153, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-30 00:00:00+00:00, data_interval_end=2023-01-31 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:28:21,177 INFO - Setting next_dagrun for anomaly_detection to 2023-01-31 00:00:00+00:00, run_after=2023-02-01 00:00:00+00:00
2025-05-07 15:28:21,543 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-31T00:00:00+00:00 [scheduled]>
2025-05-07 15:28:21,544 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:28:21,545 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:28:21,546 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-01-31T00:00:00+00:00 [scheduled]>
2025-05-07 15:28:21,550 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-01T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-01-31T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:28:21,551 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:28:21,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:21,552 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-31T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:28:21,553 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:21,911 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:32,889 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-01-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:43,026 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:28:43,026 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-01-31T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:28:43,031 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-01-31T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:28:38.280515+00:00, run_end_date=2025-05-07 18:28:40.245393+00:00, run_duration=1.964878, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=225, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:28:21.548415+00:00, queued_by_job_id=169, pid=41102
2025-05-07 15:28:43,031 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:28:27.394350+00:00, run_end_date=2025-05-07 18:28:30.029661+00:00, run_duration=2.635311, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=224, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:28:21.548415+00:00, queued_by_job_id=169, pid=41080
2025-05-07 15:28:44,621 INFO - Setting next_dagrun for anomaly_detection to 2023-02-01 00:00:00+00:00, run_after=2023-02-02 00:00:00+00:00
2025-05-07 15:28:44,865 INFO - Marking run <DagRun anomaly_detection @ 2023-01-31 00:00:00+00:00: scheduled__2023-01-31T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:27:56.228642+00:00. externally triggered: False> successful
2025-05-07 15:28:44,865 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-01-31 00:00:00+00:00, run_id=scheduled__2023-01-31T00:00:00+00:00, run_start_date=2025-05-07 18:27:56.443598+00:00, run_end_date=2025-05-07 18:28:44.865757+00:00, run_duration=48.422159, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-01-31 00:00:00+00:00, data_interval_end=2023-02-01 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:28:44,869 INFO - Setting next_dagrun for anomaly_detection to 2023-02-01 00:00:00+00:00, run_after=2023-02-02 00:00:00+00:00
2025-05-07 15:28:45,198 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-01T00:00:00+00:00 [scheduled]>
2025-05-07 15:28:45,199 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:28:45,201 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-01T00:00:00+00:00 [scheduled]>
2025-05-07 15:28:45,205 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:28:45,206 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:28:45,207 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:45,504 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:28:56,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:28:56,552 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:28:50.885972+00:00, run_end_date=2025-05-07 18:28:54.188869+00:00, run_duration=3.302897, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=226, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:28:45.203538+00:00, queued_by_job_id=169, pid=41134
2025-05-07 15:29:00,122 INFO - Setting next_dagrun for anomaly_detection to 2023-02-03 00:00:00+00:00, run_after=2023-02-04 00:00:00+00:00
2025-05-07 15:29:00,729 INFO - Marking run <DagRun anomaly_detection @ 2023-02-01 00:00:00+00:00: scheduled__2023-02-01T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:28:20.468390+00:00. externally triggered: False> successful
2025-05-07 15:29:00,730 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-01 00:00:00+00:00, run_id=scheduled__2023-02-01T00:00:00+00:00, run_start_date=2025-05-07 18:28:20.767076+00:00, run_end_date=2025-05-07 18:29:00.730585+00:00, run_duration=39.963509, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-01 00:00:00+00:00, data_interval_end=2023-02-02 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:29:00,734 INFO - Setting next_dagrun for anomaly_detection to 2023-02-02 00:00:00+00:00, run_after=2023-02-03 00:00:00+00:00
2025-05-07 15:29:01,051 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:01,052 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:29:01,053 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:01,057 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:29:01,058 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:29:01,058 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:01,348 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:11,013 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:29:11,017 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:29:06.800377+00:00, run_end_date=2025-05-07 18:29:08.277781+00:00, run_duration=1.477404, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=227, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:29:01.055307+00:00, queued_by_job_id=169, pid=41167
2025-05-07 15:29:11,815 INFO - Setting next_dagrun for anomaly_detection to 2023-02-03 00:00:00+00:00, run_after=2023-02-04 00:00:00+00:00
2025-05-07 15:29:12,439 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:12,440 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:29:12,440 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:12,443 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:29:12,443 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:29:12,444 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:12,735 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:22,823 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:29:22,828 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:29:18.198421+00:00, run_end_date=2025-05-07 18:29:20.125418+00:00, run_duration=1.926997, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=228, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:29:12.441895+00:00, queued_by_job_id=169, pid=41190
2025-05-07 15:29:24,529 INFO - Setting next_dagrun for anomaly_detection to 2023-02-04 00:00:00+00:00, run_after=2023-02-05 00:00:00+00:00
2025-05-07 15:29:25,095 INFO - Marking run <DagRun anomaly_detection @ 2023-02-02 00:00:00+00:00: scheduled__2023-02-02T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:29:00.118850+00:00. externally triggered: False> successful
2025-05-07 15:29:25,096 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-02 00:00:00+00:00, run_id=scheduled__2023-02-02T00:00:00+00:00, run_start_date=2025-05-07 18:29:00.408975+00:00, run_end_date=2025-05-07 18:29:25.096228+00:00, run_duration=24.687253, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-02 00:00:00+00:00, data_interval_end=2023-02-03 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:29:25,100 INFO - Setting next_dagrun for anomaly_detection to 2023-02-03 00:00:00+00:00, run_after=2023-02-04 00:00:00+00:00
2025-05-07 15:29:25,544 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:25,545 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:29:25,546 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:25,549 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:29:25,550 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:29:25,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:26,099 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:36,390 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:29:36,396 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:29:31.629429+00:00, run_end_date=2025-05-07 18:29:33.042776+00:00, run_duration=1.413347, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=229, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:29:25.548162+00:00, queued_by_job_id=169, pid=41222
2025-05-07 15:29:39,882 INFO - Setting next_dagrun for anomaly_detection to 2023-02-05 00:00:00+00:00, run_after=2023-02-06 00:00:00+00:00
2025-05-07 15:29:41,393 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:41,395 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:29:41,397 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:29:41,399 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:29:41,737 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-04T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:29:41,739 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:29:41,740 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:41,742 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:29:41,743 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:42,107 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:29:51,554 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:02,140 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:30:02,141 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:30:02,145 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:29:47.442395+00:00, run_end_date=2025-05-07 18:29:48.970179+00:00, run_duration=1.527784, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=230, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:29:41.402228+00:00, queued_by_job_id=169, pid=41253
2025-05-07 15:30:02,146 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:29:57.046531+00:00, run_end_date=2025-05-07 18:30:00.014599+00:00, run_duration=2.968068, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=231, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:29:41.402228+00:00, queued_by_job_id=169, pid=41275
2025-05-07 15:30:03,196 INFO - Setting next_dagrun for anomaly_detection to 2023-02-06 00:00:00+00:00, run_after=2023-02-07 00:00:00+00:00
2025-05-07 15:30:03,859 INFO - Marking run <DagRun anomaly_detection @ 2023-02-03 00:00:00+00:00: scheduled__2023-02-03T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:29:24.517738+00:00. externally triggered: False> successful
2025-05-07 15:30:03,861 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-03 00:00:00+00:00, run_id=scheduled__2023-02-03T00:00:00+00:00, run_start_date=2025-05-07 18:29:24.776722+00:00, run_end_date=2025-05-07 18:30:03.861524+00:00, run_duration=39.084802, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-03 00:00:00+00:00, data_interval_end=2023-02-04 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:30:03,871 INFO - Setting next_dagrun for anomaly_detection to 2023-02-04 00:00:00+00:00, run_after=2023-02-05 00:00:00+00:00
2025-05-07 15:30:04,456 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-04T00:00:00+00:00 [scheduled]>
2025-05-07 15:30:04,458 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:30:04,459 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:30:04,461 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-04T00:00:00+00:00 [scheduled]>
2025-05-07 15:30:04,468 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-05T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:30:04,470 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:30:04,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:04,472 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:30:04,474 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:04,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:15,670 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:27,143 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:30:27,143 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:30:27,148 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:30:11.130152+00:00, run_end_date=2025-05-07 18:30:13.139365+00:00, run_duration=2.009213, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=232, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:30:04.465075+00:00, queued_by_job_id=169, pid=41310
2025-05-07 15:30:27,149 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:30:21.131329+00:00, run_end_date=2025-05-07 18:30:25.027723+00:00, run_duration=3.896394, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=233, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:30:04.465075+00:00, queued_by_job_id=169, pid=41351
2025-05-07 15:30:29,853 INFO - Setting next_dagrun for anomaly_detection to 2023-02-05 00:00:00+00:00, run_after=2023-02-06 00:00:00+00:00
2025-05-07 15:30:30,251 INFO - Marking run <DagRun anomaly_detection @ 2023-02-04 00:00:00+00:00: scheduled__2023-02-04T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:29:39.875277+00:00. externally triggered: False> successful
2025-05-07 15:30:30,251 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-04 00:00:00+00:00, run_id=scheduled__2023-02-04T00:00:00+00:00, run_start_date=2025-05-07 18:29:40.256205+00:00, run_end_date=2025-05-07 18:30:30.251857+00:00, run_duration=49.995652, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-04 00:00:00+00:00, data_interval_end=2023-02-05 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:30:30,255 INFO - Setting next_dagrun for anomaly_detection to 2023-02-05 00:00:00+00:00, run_after=2023-02-06 00:00:00+00:00
2025-05-07 15:30:30,545 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-05T00:00:00+00:00 [scheduled]>
2025-05-07 15:30:30,545 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:30:30,546 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-05T00:00:00+00:00 [scheduled]>
2025-05-07 15:30:30,549 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:30:30,550 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:30:30,550 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:30,898 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:40,483 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:30:41,226 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:30:36.256182+00:00, run_end_date=2025-05-07 18:30:38.142616+00:00, run_duration=1.886434, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=234, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:30:30.547629+00:00, queued_by_job_id=169, pid=41400
2025-05-07 15:30:44,825 INFO - Setting next_dagrun for anomaly_detection to 2023-02-07 00:00:00+00:00, run_after=2023-02-08 00:00:00+00:00
2025-05-07 15:30:45,432 INFO - Marking run <DagRun anomaly_detection @ 2023-02-05 00:00:00+00:00: scheduled__2023-02-05T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:30:03.184221+00:00. externally triggered: False> successful
2025-05-07 15:30:45,433 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-05 00:00:00+00:00, run_id=scheduled__2023-02-05T00:00:00+00:00, run_start_date=2025-05-07 18:30:03.424895+00:00, run_end_date=2025-05-07 18:30:45.433519+00:00, run_duration=42.008624, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-05 00:00:00+00:00, data_interval_end=2023-02-06 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:30:45,437 INFO - Setting next_dagrun for anomaly_detection to 2023-02-06 00:00:00+00:00, run_after=2023-02-07 00:00:00+00:00
2025-05-07 15:30:45,857 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:30:45,859 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:30:45,860 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:30:45,866 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:30:45,867 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:30:45,869 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:46,208 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:30:57,487 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:30:57,491 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:30:52.917372+00:00, run_end_date=2025-05-07 18:30:54.834653+00:00, run_duration=1.917281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=235, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:30:45.862927+00:00, queued_by_job_id=169, pid=41437
2025-05-07 15:30:59,577 INFO - Setting next_dagrun for anomaly_detection to 2023-02-07 00:00:00+00:00, run_after=2023-02-08 00:00:00+00:00
2025-05-07 15:31:00,153 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:00,154 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:31:00,156 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:00,161 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:31:00,163 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:31:00,164 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:00,469 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:10,205 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:31:10,210 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:31:05.966908+00:00, run_end_date=2025-05-07 18:31:07.965954+00:00, run_duration=1.999046, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=236, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:31:00.158274+00:00, queued_by_job_id=169, pid=41461
2025-05-07 15:31:12,853 INFO - Setting next_dagrun for anomaly_detection to 2023-02-08 00:00:00+00:00, run_after=2023-02-09 00:00:00+00:00
2025-05-07 15:31:13,485 INFO - Marking run <DagRun anomaly_detection @ 2023-02-06 00:00:00+00:00: scheduled__2023-02-06T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:30:44.821366+00:00. externally triggered: False> successful
2025-05-07 15:31:13,486 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-06 00:00:00+00:00, run_id=scheduled__2023-02-06T00:00:00+00:00, run_start_date=2025-05-07 18:30:45.109329+00:00, run_end_date=2025-05-07 18:31:13.486426+00:00, run_duration=28.377097, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-06 00:00:00+00:00, data_interval_end=2023-02-07 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:31:13,490 INFO - Setting next_dagrun for anomaly_detection to 2023-02-07 00:00:00+00:00, run_after=2023-02-08 00:00:00+00:00
2025-05-07 15:31:13,827 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:13,828 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:31:13,829 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:13,832 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:31:13,833 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:31:13,834 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:14,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:25,908 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:31:25,913 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:31:20.583448+00:00, run_end_date=2025-05-07 18:31:23.004390+00:00, run_duration=2.420942, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=237, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:31:13.831025+00:00, queued_by_job_id=169, pid=41494
2025-05-07 15:31:29,541 INFO - Setting next_dagrun for anomaly_detection to 2023-02-09 00:00:00+00:00, run_after=2023-02-10 00:00:00+00:00
2025-05-07 15:31:30,787 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:30,789 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:31:30,790 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:31:30,792 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:30,797 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-08T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:31:30,798 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:31:30,799 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:30,800 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:31:30,801 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:31,133 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:40,948 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:51,653 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:31:51,653 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:31:52,097 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:31:47.292572+00:00, run_end_date=2025-05-07 18:31:49.388574+00:00, run_duration=2.096002, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=239, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:31:30.794575+00:00, queued_by_job_id=169, pid=41548
2025-05-07 15:31:52,101 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:31:36.702497+00:00, run_end_date=2025-05-07 18:31:38.204980+00:00, run_duration=1.502483, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=238, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:31:30.794575+00:00, queued_by_job_id=169, pid=41526
2025-05-07 15:31:53,905 INFO - Setting next_dagrun for anomaly_detection to 2023-02-10 00:00:00+00:00, run_after=2023-02-11 00:00:00+00:00
2025-05-07 15:31:54,474 INFO - Marking run <DagRun anomaly_detection @ 2023-02-07 00:00:00+00:00: scheduled__2023-02-07T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:31:12.849747+00:00. externally triggered: False> successful
2025-05-07 15:31:54,474 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-07 00:00:00+00:00, run_id=scheduled__2023-02-07T00:00:00+00:00, run_start_date=2025-05-07 18:31:13.086264+00:00, run_end_date=2025-05-07 18:31:54.474829+00:00, run_duration=41.388565, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-07 00:00:00+00:00, data_interval_end=2023-02-08 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:31:54,478 INFO - Setting next_dagrun for anomaly_detection to 2023-02-08 00:00:00+00:00, run_after=2023-02-09 00:00:00+00:00
2025-05-07 15:31:54,795 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-08T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:54,797 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:31:54,798 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:31:54,799 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-08T00:00:00+00:00 [scheduled]>
2025-05-07 15:31:54,803 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-09T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:31:54,804 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:31:54,805 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:54,806 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:31:54,806 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:31:55,152 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:05,247 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:15,669 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:32:15,670 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:32:16,013 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:32:00.782984+00:00, run_end_date=2025-05-07 18:32:02.333359+00:00, run_duration=1.550375, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=240, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:31:54.801974+00:00, queued_by_job_id=169, pid=41572
2025-05-07 15:32:16,015 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:32:11.277771+00:00, run_end_date=2025-05-07 18:32:13.273734+00:00, run_duration=1.995963, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=241, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:31:54.801974+00:00, queued_by_job_id=169, pid=41595
2025-05-07 15:32:17,250 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:32:18,589 INFO - Setting next_dagrun for anomaly_detection to 2023-02-09 00:00:00+00:00, run_after=2023-02-10 00:00:00+00:00
2025-05-07 15:32:18,900 INFO - Marking run <DagRun anomaly_detection @ 2023-02-08 00:00:00+00:00: scheduled__2023-02-08T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:31:29.536905+00:00. externally triggered: False> successful
2025-05-07 15:32:18,900 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-08 00:00:00+00:00, run_id=scheduled__2023-02-08T00:00:00+00:00, run_start_date=2025-05-07 18:31:29.788069+00:00, run_end_date=2025-05-07 18:32:18.900750+00:00, run_duration=49.112681, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-08 00:00:00+00:00, data_interval_end=2023-02-09 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:32:18,904 INFO - Setting next_dagrun for anomaly_detection to 2023-02-09 00:00:00+00:00, run_after=2023-02-10 00:00:00+00:00
2025-05-07 15:32:19,302 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:32:19,304 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:32:19,306 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:32:19,311 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:32:19,314 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:32:19,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:19,605 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:31,127 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:32:31,130 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:32:25.048689+00:00, run_end_date=2025-05-07 18:32:26.974868+00:00, run_duration=1.926179, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=242, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:32:19.308177+00:00, queued_by_job_id=169, pid=41627
2025-05-07 15:32:34,537 INFO - Setting next_dagrun for anomaly_detection to 2023-02-11 00:00:00+00:00, run_after=2023-02-12 00:00:00+00:00
2025-05-07 15:32:35,551 INFO - Marking run <DagRun anomaly_detection @ 2023-02-09 00:00:00+00:00: scheduled__2023-02-09T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:31:53.901883+00:00. externally triggered: False> successful
2025-05-07 15:32:35,553 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-09 00:00:00+00:00, run_id=scheduled__2023-02-09T00:00:00+00:00, run_start_date=2025-05-07 18:31:54.139885+00:00, run_end_date=2025-05-07 18:32:35.552999+00:00, run_duration=41.413114, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-09 00:00:00+00:00, data_interval_end=2023-02-10 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:32:35,567 INFO - Setting next_dagrun for anomaly_detection to 2023-02-10 00:00:00+00:00, run_after=2023-02-11 00:00:00+00:00
2025-05-07 15:32:35,928 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:32:35,930 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:32:35,931 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:32:35,937 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:32:35,938 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:32:35,939 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:36,293 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:46,382 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:32:46,572 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:32:41.798977+00:00, run_end_date=2025-05-07 18:32:43.666306+00:00, run_duration=1.867329, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=243, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:32:35.934028+00:00, queued_by_job_id=169, pid=41661
2025-05-07 15:32:47,736 INFO - Setting next_dagrun for anomaly_detection to 2023-02-11 00:00:00+00:00, run_after=2023-02-12 00:00:00+00:00
2025-05-07 15:32:48,353 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:32:48,354 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:32:48,354 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:32:48,357 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:32:48,358 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:32:48,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:48,637 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:32:58,748 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:32:58,932 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:32:54.260024+00:00, run_end_date=2025-05-07 18:32:56.157145+00:00, run_duration=1.897121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:32:48.356071+00:00, queued_by_job_id=169, pid=41685
2025-05-07 15:33:00,864 INFO - Setting next_dagrun for anomaly_detection to 2023-02-12 00:00:00+00:00, run_after=2023-02-13 00:00:00+00:00
2025-05-07 15:33:01,542 INFO - Marking run <DagRun anomaly_detection @ 2023-02-10 00:00:00+00:00: scheduled__2023-02-10T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:32:34.533923+00:00. externally triggered: False> successful
2025-05-07 15:33:01,543 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-10 00:00:00+00:00, run_id=scheduled__2023-02-10T00:00:00+00:00, run_start_date=2025-05-07 18:32:35.177260+00:00, run_end_date=2025-05-07 18:33:01.543481+00:00, run_duration=26.366221, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-10 00:00:00+00:00, data_interval_end=2023-02-11 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:33:01,547 INFO - Setting next_dagrun for anomaly_detection to 2023-02-11 00:00:00+00:00, run_after=2023-02-12 00:00:00+00:00
2025-05-07 15:33:01,892 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:33:01,893 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:33:01,894 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:33:01,896 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:33:01,897 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:33:01,898 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:02,221 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:14,162 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:33:14,168 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:33:08.367779+00:00, run_end_date=2025-05-07 18:33:11.195879+00:00, run_duration=2.8281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=245, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:33:01.895500+00:00, queued_by_job_id=169, pid=41716
2025-05-07 15:33:17,813 INFO - Setting next_dagrun for anomaly_detection to 2023-02-13 00:00:00+00:00, run_after=2023-02-14 00:00:00+00:00
2025-05-07 15:33:19,174 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:33:19,175 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:33:19,176 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:33:19,177 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:33:19,180 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-12T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:33:19,181 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:33:19,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:19,182 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:33:19,183 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:19,588 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:32,245 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:42,750 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:33:42,751 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:33:42,755 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:33:25.512994+00:00, run_end_date=2025-05-07 18:33:27.238281+00:00, run_duration=1.725287, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=246, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:33:19.178844+00:00, queued_by_job_id=169, pid=41748
2025-05-07 15:33:42,756 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:33:38.160926+00:00, run_end_date=2025-05-07 18:33:40.233214+00:00, run_duration=2.072288, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=247, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:33:19.178844+00:00, queued_by_job_id=169, pid=41770
2025-05-07 15:33:43,569 INFO - Setting next_dagrun for anomaly_detection to 2023-02-14 00:00:00+00:00, run_after=2023-02-15 00:00:00+00:00
2025-05-07 15:33:44,134 INFO - Marking run <DagRun anomaly_detection @ 2023-02-11 00:00:00+00:00: scheduled__2023-02-11T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:33:00.860597+00:00. externally triggered: False> successful
2025-05-07 15:33:44,135 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-11 00:00:00+00:00, run_id=scheduled__2023-02-11T00:00:00+00:00, run_start_date=2025-05-07 18:33:01.179980+00:00, run_end_date=2025-05-07 18:33:44.135522+00:00, run_duration=42.955542, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-11 00:00:00+00:00, data_interval_end=2023-02-12 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:33:44,139 INFO - Setting next_dagrun for anomaly_detection to 2023-02-12 00:00:00+00:00, run_after=2023-02-13 00:00:00+00:00
2025-05-07 15:33:44,460 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-12T00:00:00+00:00 [scheduled]>
2025-05-07 15:33:44,461 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:33:44,462 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:33:44,463 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-12T00:00:00+00:00 [scheduled]>
2025-05-07 15:33:44,467 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-13T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:33:44,468 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:33:44,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:44,469 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:33:44,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:44,767 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:33:56,170 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:06,782 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:34:06,783 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:34:06,787 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:33:50.302018+00:00, run_end_date=2025-05-07 18:33:52.873915+00:00, run_duration=2.571897, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=248, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:33:44.465544+00:00, queued_by_job_id=169, pid=41794
2025-05-07 15:34:06,787 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:34:01.529230+00:00, run_end_date=2025-05-07 18:34:03.375699+00:00, run_duration=1.846469, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=249, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:33:44.465544+00:00, queued_by_job_id=169, pid=41816
2025-05-07 15:34:08,273 INFO - Setting next_dagrun for anomaly_detection to 2023-02-13 00:00:00+00:00, run_after=2023-02-14 00:00:00+00:00
2025-05-07 15:34:08,518 INFO - Marking run <DagRun anomaly_detection @ 2023-02-12 00:00:00+00:00: scheduled__2023-02-12T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:33:17.802841+00:00. externally triggered: False> successful
2025-05-07 15:34:08,518 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-12 00:00:00+00:00, run_id=scheduled__2023-02-12T00:00:00+00:00, run_start_date=2025-05-07 18:33:18.077531+00:00, run_end_date=2025-05-07 18:34:08.518748+00:00, run_duration=50.441217, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-12 00:00:00+00:00, data_interval_end=2023-02-13 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:34:08,522 INFO - Setting next_dagrun for anomaly_detection to 2023-02-13 00:00:00+00:00, run_after=2023-02-14 00:00:00+00:00
2025-05-07 15:34:08,888 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:08,889 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:34:08,890 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:08,893 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-13T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:34:08,894 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:34:08,895 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:09,176 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:20,028 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:34:20,032 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:34:14.872760+00:00, run_end_date=2025-05-07 18:34:17.900942+00:00, run_duration=3.028182, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=250, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:34:08.891667+00:00, queued_by_job_id=169, pid=41849
2025-05-07 15:34:24,020 INFO - Setting next_dagrun for anomaly_detection to 2023-02-15 00:00:00+00:00, run_after=2023-02-16 00:00:00+00:00
2025-05-07 15:34:24,632 INFO - Marking run <DagRun anomaly_detection @ 2023-02-13 00:00:00+00:00: scheduled__2023-02-13T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:33:43.563976+00:00. externally triggered: False> successful
2025-05-07 15:34:24,632 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-13 00:00:00+00:00, run_id=scheduled__2023-02-13T00:00:00+00:00, run_start_date=2025-05-07 18:33:43.807642+00:00, run_end_date=2025-05-07 18:34:24.632903+00:00, run_duration=40.825261, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-13 00:00:00+00:00, data_interval_end=2023-02-14 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:34:24,636 INFO - Setting next_dagrun for anomaly_detection to 2023-02-14 00:00:00+00:00, run_after=2023-02-15 00:00:00+00:00
2025-05-07 15:34:24,843 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:24,845 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:34:24,846 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:24,850 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:34:24,851 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:34:24,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:25,140 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:35,256 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:34:35,260 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:34:30.884958+00:00, run_end_date=2025-05-07 18:34:32.598459+00:00, run_duration=1.713501, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=251, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:34:24.849123+00:00, queued_by_job_id=169, pid=41883
2025-05-07 15:34:36,019 INFO - Setting next_dagrun for anomaly_detection to 2023-02-15 00:00:00+00:00, run_after=2023-02-16 00:00:00+00:00
2025-05-07 15:34:36,653 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:36,655 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:34:36,656 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:36,659 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:34:36,660 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:34:36,660 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:36,996 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:46,833 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:34:46,838 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:34:42.627338+00:00, run_end_date=2025-05-07 18:34:44.544471+00:00, run_duration=1.917133, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=252, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:34:36.657531+00:00, queued_by_job_id=169, pid=41906
2025-05-07 15:34:48,495 INFO - Setting next_dagrun for anomaly_detection to 2023-02-16 00:00:00+00:00, run_after=2023-02-17 00:00:00+00:00
2025-05-07 15:34:49,043 INFO - Marking run <DagRun anomaly_detection @ 2023-02-14 00:00:00+00:00: scheduled__2023-02-14T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:34:24.017021+00:00. externally triggered: False> successful
2025-05-07 15:34:49,044 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-14 00:00:00+00:00, run_id=scheduled__2023-02-14T00:00:00+00:00, run_start_date=2025-05-07 18:34:24.321480+00:00, run_end_date=2025-05-07 18:34:49.044517+00:00, run_duration=24.723037, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-14 00:00:00+00:00, data_interval_end=2023-02-15 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:34:49,048 INFO - Setting next_dagrun for anomaly_detection to 2023-02-15 00:00:00+00:00, run_after=2023-02-16 00:00:00+00:00
2025-05-07 15:34:49,409 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:49,410 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:34:49,412 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:34:49,414 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-15T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:34:49,415 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:34:49,416 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:34:49,705 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:00,792 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:35:00,797 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:34:55.377600+00:00, run_end_date=2025-05-07 18:34:56.854581+00:00, run_duration=1.476981, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=253, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:34:49.413403+00:00, queued_by_job_id=169, pid=41938
2025-05-07 15:35:04,585 INFO - Setting next_dagrun for anomaly_detection to 2023-02-17 00:00:00+00:00, run_after=2023-02-18 00:00:00+00:00
2025-05-07 15:35:05,623 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:35:05,624 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:35:05,625 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:35:05,626 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:35:05,959 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-16T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-15T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:35:05,960 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:35:05,960 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:05,961 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:35:05,961 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:06,265 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:16,086 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:27,354 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:35:27,354 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:35:27,359 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:35:11.631592+00:00, run_end_date=2025-05-07 18:35:13.108347+00:00, run_duration=1.476755, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=254, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:35:05.628522+00:00, queued_by_job_id=169, pid=41972
2025-05-07 15:35:27,359 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:35:21.509881+00:00, run_end_date=2025-05-07 18:35:25.192220+00:00, run_duration=3.682339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=255, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:35:05.628522+00:00, queued_by_job_id=169, pid=42013
2025-05-07 15:35:29,528 INFO - Setting next_dagrun for anomaly_detection to 2023-02-18 00:00:00+00:00, run_after=2023-02-19 00:00:00+00:00
2025-05-07 15:35:30,158 INFO - Marking run <DagRun anomaly_detection @ 2023-02-15 00:00:00+00:00: scheduled__2023-02-15T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:34:48.491991+00:00. externally triggered: False> successful
2025-05-07 15:35:30,159 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-15 00:00:00+00:00, run_id=scheduled__2023-02-15T00:00:00+00:00, run_start_date=2025-05-07 18:34:48.715541+00:00, run_end_date=2025-05-07 18:35:30.158983+00:00, run_duration=41.443442, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-15 00:00:00+00:00, data_interval_end=2023-02-16 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:35:30,162 INFO - Setting next_dagrun for anomaly_detection to 2023-02-16 00:00:00+00:00, run_after=2023-02-17 00:00:00+00:00
2025-05-07 15:35:30,578 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-16T00:00:00+00:00 [scheduled]>
2025-05-07 15:35:30,579 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:35:30,580 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:35:30,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-16T00:00:00+00:00 [scheduled]>
2025-05-07 15:35:30,583 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-17T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-16T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:35:30,584 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:35:30,585 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:30,586 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:35:30,586 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:30,910 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:41,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:51,768 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:35:51,769 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:35:52,110 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:35:47.150816+00:00, run_end_date=2025-05-07 18:35:49.547670+00:00, run_duration=2.396854, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:35:30.581744+00:00, queued_by_job_id=169, pid=42071
2025-05-07 15:35:52,113 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:35:36.777214+00:00, run_end_date=2025-05-07 18:35:38.361999+00:00, run_duration=1.584785, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=256, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:35:30.581744+00:00, queued_by_job_id=169, pid=42049
2025-05-07 15:35:54,456 INFO - Setting next_dagrun for anomaly_detection to 2023-02-17 00:00:00+00:00, run_after=2023-02-18 00:00:00+00:00
2025-05-07 15:35:55,010 INFO - Marking run <DagRun anomaly_detection @ 2023-02-16 00:00:00+00:00: scheduled__2023-02-16T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:35:04.576785+00:00. externally triggered: False> successful
2025-05-07 15:35:55,011 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-16 00:00:00+00:00, run_id=scheduled__2023-02-16T00:00:00+00:00, run_start_date=2025-05-07 18:35:04.960441+00:00, run_end_date=2025-05-07 18:35:55.011218+00:00, run_duration=50.050777, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-16 00:00:00+00:00, data_interval_end=2023-02-17 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:35:55,015 INFO - Setting next_dagrun for anomaly_detection to 2023-02-17 00:00:00+00:00, run_after=2023-02-18 00:00:00+00:00
2025-05-07 15:35:55,440 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:35:55,441 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:35:55,442 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:35:55,444 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-17T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:35:55,445 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:35:55,446 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:35:55,820 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:06,574 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:36:06,578 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:36:01.339847+00:00, run_end_date=2025-05-07 18:36:04.190057+00:00, run_duration=2.85021, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=258, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:35:55.443465+00:00, queued_by_job_id=169, pid=42109
2025-05-07 15:36:10,581 INFO - Setting next_dagrun for anomaly_detection to 2023-02-19 00:00:00+00:00, run_after=2023-02-20 00:00:00+00:00
2025-05-07 15:36:11,120 INFO - Marking run <DagRun anomaly_detection @ 2023-02-17 00:00:00+00:00: scheduled__2023-02-17T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:35:29.512211+00:00. externally triggered: False> successful
2025-05-07 15:36:11,120 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-17 00:00:00+00:00, run_id=scheduled__2023-02-17T00:00:00+00:00, run_start_date=2025-05-07 18:35:29.752867+00:00, run_end_date=2025-05-07 18:36:11.120831+00:00, run_duration=41.367964, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-17 00:00:00+00:00, data_interval_end=2023-02-18 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:36:11,124 INFO - Setting next_dagrun for anomaly_detection to 2023-02-18 00:00:00+00:00, run_after=2023-02-19 00:00:00+00:00
2025-05-07 15:36:11,425 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:11,426 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:36:11,426 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:11,428 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:36:11,429 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:36:11,429 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:11,725 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:21,460 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:36:21,464 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:36:17.328135+00:00, run_end_date=2025-05-07 18:36:18.926805+00:00, run_duration=1.59867, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=259, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:36:11.427149+00:00, queued_by_job_id=169, pid=42142
2025-05-07 15:36:23,749 INFO - Setting next_dagrun for anomaly_detection to 2023-02-19 00:00:00+00:00, run_after=2023-02-20 00:00:00+00:00
2025-05-07 15:36:24,391 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:24,392 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:36:24,393 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:24,396 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:36:24,397 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:36:24,398 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:24,790 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:34,853 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:36:34,860 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:36:30.235054+00:00, run_end_date=2025-05-07 18:36:32.132590+00:00, run_duration=1.897536, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=260, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:36:24.394969+00:00, queued_by_job_id=169, pid=42167
2025-05-07 15:36:36,478 INFO - Setting next_dagrun for anomaly_detection to 2023-02-20 00:00:00+00:00, run_after=2023-02-21 00:00:00+00:00
2025-05-07 15:36:37,074 INFO - Marking run <DagRun anomaly_detection @ 2023-02-18 00:00:00+00:00: scheduled__2023-02-18T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:36:10.335971+00:00. externally triggered: False> successful
2025-05-07 15:36:37,075 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-18 00:00:00+00:00, run_id=scheduled__2023-02-18T00:00:00+00:00, run_start_date=2025-05-07 18:36:10.797180+00:00, run_end_date=2025-05-07 18:36:37.075262+00:00, run_duration=26.278082, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-18 00:00:00+00:00, data_interval_end=2023-02-19 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:36:37,080 INFO - Setting next_dagrun for anomaly_detection to 2023-02-19 00:00:00+00:00, run_after=2023-02-20 00:00:00+00:00
2025-05-07 15:36:37,519 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:37,521 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:36:37,522 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:37,526 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-19T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:36:37,527 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:36:37,528 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:37,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:47,276 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:36:47,282 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:36:43.286297+00:00, run_end_date=2025-05-07 18:36:44.679068+00:00, run_duration=1.392771, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=261, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:36:37.524451+00:00, queued_by_job_id=169, pid=42198
2025-05-07 15:36:50,559 INFO - Setting next_dagrun for anomaly_detection to 2023-02-21 00:00:00+00:00, run_after=2023-02-22 00:00:00+00:00
2025-05-07 15:36:51,606 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:51,607 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:36:51,607 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:36:51,608 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:36:51,613 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-20T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-19T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:36:51,614 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:36:51,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:51,616 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:36:51,616 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:36:51,885 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:02,393 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:12,679 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:37:12,680 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:37:12,685 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:36:57.191541+00:00, run_end_date=2025-05-07 18:36:58.860219+00:00, run_duration=1.668678, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=262, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:36:51.610676+00:00, queued_by_job_id=169, pid=42230
2025-05-07 15:37:12,686 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:37:07.826643+00:00, run_end_date=2025-05-07 18:37:09.581695+00:00, run_duration=1.755052, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=263, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:36:51.610676+00:00, queued_by_job_id=169, pid=42252
2025-05-07 15:37:13,504 INFO - Setting next_dagrun for anomaly_detection to 2023-02-22 00:00:00+00:00, run_after=2023-02-23 00:00:00+00:00
2025-05-07 15:37:14,148 INFO - Marking run <DagRun anomaly_detection @ 2023-02-19 00:00:00+00:00: scheduled__2023-02-19T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:36:36.472871+00:00. externally triggered: False> successful
2025-05-07 15:37:14,148 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-19 00:00:00+00:00, run_id=scheduled__2023-02-19T00:00:00+00:00, run_start_date=2025-05-07 18:36:36.688774+00:00, run_end_date=2025-05-07 18:37:14.148824+00:00, run_duration=37.46005, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-19 00:00:00+00:00, data_interval_end=2023-02-20 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:37:14,152 INFO - Setting next_dagrun for anomaly_detection to 2023-02-20 00:00:00+00:00, run_after=2023-02-21 00:00:00+00:00
2025-05-07 15:37:14,434 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-20T00:00:00+00:00 [scheduled]>
2025-05-07 15:37:14,434 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:37:14,434 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:37:14,435 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-20T00:00:00+00:00 [scheduled]>
2025-05-07 15:37:14,436 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-21T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:37:14,437 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:37:14,437 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:14,437 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:37:14,438 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:14,715 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:25,320 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:37,299 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:37:37,299 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:37:37,303 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:37:30.681480+00:00, run_end_date=2025-05-07 18:37:32.695410+00:00, run_duration=2.01393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:37:14.435952+00:00, queued_by_job_id=169, pid=42299
2025-05-07 15:37:37,304 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:37:20.467033+00:00, run_end_date=2025-05-07 18:37:22.089917+00:00, run_duration=1.622884, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=264, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:37:14.435952+00:00, queued_by_job_id=169, pid=42277
2025-05-07 15:37:37,649 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:37:39,053 INFO - Setting next_dagrun for anomaly_detection to 2023-02-21 00:00:00+00:00, run_after=2023-02-22 00:00:00+00:00
2025-05-07 15:37:39,371 INFO - Marking run <DagRun anomaly_detection @ 2023-02-20 00:00:00+00:00: scheduled__2023-02-20T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:36:50.550834+00:00. externally triggered: False> successful
2025-05-07 15:37:39,371 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-20 00:00:00+00:00, run_id=scheduled__2023-02-20T00:00:00+00:00, run_start_date=2025-05-07 18:36:50.773834+00:00, run_end_date=2025-05-07 18:37:39.371662+00:00, run_duration=48.597828, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-20 00:00:00+00:00, data_interval_end=2023-02-21 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:37:39,375 INFO - Setting next_dagrun for anomaly_detection to 2023-02-21 00:00:00+00:00, run_after=2023-02-22 00:00:00+00:00
2025-05-07 15:37:39,710 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:37:39,710 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:37:39,711 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:37:39,714 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:37:39,714 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:37:39,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:40,033 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:51,227 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:37:51,231 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:37:45.413500+00:00, run_end_date=2025-05-07 18:37:48.780667+00:00, run_duration=3.367167, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=266, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:37:39.712778+00:00, queued_by_job_id=169, pid=42338
2025-05-07 15:37:54,897 INFO - Setting next_dagrun for anomaly_detection to 2023-02-23 00:00:00+00:00, run_after=2023-02-24 00:00:00+00:00
2025-05-07 15:37:55,494 INFO - Marking run <DagRun anomaly_detection @ 2023-02-21 00:00:00+00:00: scheduled__2023-02-21T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:37:13.500749+00:00. externally triggered: False> successful
2025-05-07 15:37:55,494 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-21 00:00:00+00:00, run_id=scheduled__2023-02-21T00:00:00+00:00, run_start_date=2025-05-07 18:37:13.747629+00:00, run_end_date=2025-05-07 18:37:55.494873+00:00, run_duration=41.747244, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-21 00:00:00+00:00, data_interval_end=2023-02-22 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:37:55,499 INFO - Setting next_dagrun for anomaly_detection to 2023-02-22 00:00:00+00:00, run_after=2023-02-23 00:00:00+00:00
2025-05-07 15:37:55,813 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:37:55,814 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:37:55,816 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:37:55,820 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:37:55,821 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:37:55,822 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:37:56,180 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:07,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:38:07,552 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:38:01.784972+00:00, run_end_date=2025-05-07 18:38:03.387028+00:00, run_duration=1.602056, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=267, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:37:55.818303+00:00, queued_by_job_id=169, pid=42370
2025-05-07 15:38:08,353 INFO - Setting next_dagrun for anomaly_detection to 2023-02-23 00:00:00+00:00, run_after=2023-02-24 00:00:00+00:00
2025-05-07 15:38:08,949 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:38:08,950 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:38:08,951 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:38:08,955 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:38:08,955 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:38:08,956 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:09,300 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:20,151 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:38:20,156 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:38:14.725476+00:00, run_end_date=2025-05-07 18:38:17.731032+00:00, run_duration=3.005556, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=268, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:38:08.953494+00:00, queued_by_job_id=169, pid=42394
2025-05-07 15:38:21,893 INFO - Setting next_dagrun for anomaly_detection to 2023-02-24 00:00:00+00:00, run_after=2023-02-25 00:00:00+00:00
2025-05-07 15:38:22,561 INFO - Marking run <DagRun anomaly_detection @ 2023-02-22 00:00:00+00:00: scheduled__2023-02-22T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:37:54.893675+00:00. externally triggered: False> successful
2025-05-07 15:38:22,562 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-22 00:00:00+00:00, run_id=scheduled__2023-02-22T00:00:00+00:00, run_start_date=2025-05-07 18:37:55.164743+00:00, run_end_date=2025-05-07 18:38:22.562016+00:00, run_duration=27.397273, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-22 00:00:00+00:00, data_interval_end=2023-02-23 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:38:22,565 INFO - Setting next_dagrun for anomaly_detection to 2023-02-23 00:00:00+00:00, run_after=2023-02-24 00:00:00+00:00
2025-05-07 15:38:23,132 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:38:23,134 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:38:23,136 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:38:23,146 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:38:23,149 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:38:23,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:23,513 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:32,942 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:38:32,946 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:38:29.147892+00:00, run_end_date=2025-05-07 18:38:30.563194+00:00, run_duration=1.415302, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=269, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:38:23.140716+00:00, queued_by_job_id=169, pid=42427
2025-05-07 15:38:36,639 INFO - Setting next_dagrun for anomaly_detection to 2023-02-25 00:00:00+00:00, run_after=2023-02-26 00:00:00+00:00
2025-05-07 15:38:37,588 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:38:37,589 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:38:37,590 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:38:37,591 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:38:37,595 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-24T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:38:37,596 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:38:37,597 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:37,597 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:38:37,598 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:37,884 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:47,522 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:38:57,327 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:38:57,327 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:38:57,331 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:38:43.255125+00:00, run_end_date=2025-05-07 18:38:44.812421+00:00, run_duration=1.557296, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=270, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:38:37.593404+00:00, queued_by_job_id=169, pid=42459
2025-05-07 15:38:57,332 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:38:53.195331+00:00, run_end_date=2025-05-07 18:38:55.105636+00:00, run_duration=1.910305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=271, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:38:37.593404+00:00, queued_by_job_id=169, pid=42480
2025-05-07 15:38:59,217 INFO - Setting next_dagrun for anomaly_detection to 2023-02-26 00:00:00+00:00, run_after=2023-02-27 00:00:00+00:00
2025-05-07 15:38:59,822 INFO - Marking run <DagRun anomaly_detection @ 2023-02-23 00:00:00+00:00: scheduled__2023-02-23T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:38:21.888088+00:00. externally triggered: False> successful
2025-05-07 15:38:59,822 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-23 00:00:00+00:00, run_id=scheduled__2023-02-23T00:00:00+00:00, run_start_date=2025-05-07 18:38:22.179525+00:00, run_end_date=2025-05-07 18:38:59.822873+00:00, run_duration=37.643348, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-23 00:00:00+00:00, data_interval_end=2023-02-24 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:38:59,825 INFO - Setting next_dagrun for anomaly_detection to 2023-02-24 00:00:00+00:00, run_after=2023-02-25 00:00:00+00:00
2025-05-07 15:39:00,138 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-24T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:00,139 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:39:00,140 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:39:00,140 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-24T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:00,144 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-25T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-24T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:39:00,154 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:39:00,154 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:00,155 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:39:00,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:00,456 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:10,197 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:20,801 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:39:20,802 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:39:20,806 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:39:15.564308+00:00, run_end_date=2025-05-07 18:39:18.490482+00:00, run_duration=2.926174, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=273, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:39:00.142616+00:00, queued_by_job_id=169, pid=42527
2025-05-07 15:39:20,807 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:39:05.906364+00:00, run_end_date=2025-05-07 18:39:07.662259+00:00, run_duration=1.755895, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=272, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:39:00.142616+00:00, queued_by_job_id=169, pid=42506
2025-05-07 15:39:23,380 INFO - Setting next_dagrun for anomaly_detection to 2023-02-25 00:00:00+00:00, run_after=2023-02-26 00:00:00+00:00
2025-05-07 15:39:23,619 INFO - Marking run <DagRun anomaly_detection @ 2023-02-24 00:00:00+00:00: scheduled__2023-02-24T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:38:36.630385+00:00. externally triggered: False> successful
2025-05-07 15:39:23,619 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-24 00:00:00+00:00, run_id=scheduled__2023-02-24T00:00:00+00:00, run_start_date=2025-05-07 18:38:36.895016+00:00, run_end_date=2025-05-07 18:39:23.619693+00:00, run_duration=46.724677, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-24 00:00:00+00:00, data_interval_end=2023-02-25 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:39:23,623 INFO - Setting next_dagrun for anomaly_detection to 2023-02-25 00:00:00+00:00, run_after=2023-02-26 00:00:00+00:00
2025-05-07 15:39:23,967 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:23,968 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:39:23,970 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:23,973 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-25T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:39:23,975 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:39:23,976 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:24,295 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:34,183 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:39:34,368 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:39:29.866256+00:00, run_end_date=2025-05-07 18:39:31.780814+00:00, run_duration=1.914558, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=274, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:39:23.971366+00:00, queued_by_job_id=169, pid=42560
2025-05-07 15:39:37,908 INFO - Setting next_dagrun for anomaly_detection to 2023-02-27 00:00:00+00:00, run_after=2023-02-28 00:00:00+00:00
2025-05-07 15:39:38,523 INFO - Marking run <DagRun anomaly_detection @ 2023-02-25 00:00:00+00:00: scheduled__2023-02-25T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:38:59.207026+00:00. externally triggered: False> successful
2025-05-07 15:39:38,523 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-25 00:00:00+00:00, run_id=scheduled__2023-02-25T00:00:00+00:00, run_start_date=2025-05-07 18:38:59.519039+00:00, run_end_date=2025-05-07 18:39:38.523596+00:00, run_duration=39.004557, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-25 00:00:00+00:00, data_interval_end=2023-02-26 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:39:38,527 INFO - Setting next_dagrun for anomaly_detection to 2023-02-26 00:00:00+00:00, run_after=2023-02-27 00:00:00+00:00
2025-05-07 15:39:38,857 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:38,857 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:39:38,858 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:38,861 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:39:38,861 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:39:38,862 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:39,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:49,910 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:39:49,913 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:39:44.600908+00:00, run_end_date=2025-05-07 18:39:47.173607+00:00, run_duration=2.572699, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=275, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:39:38.859651+00:00, queued_by_job_id=169, pid=42592
2025-05-07 15:39:50,804 INFO - Setting next_dagrun for anomaly_detection to 2023-02-27 00:00:00+00:00, run_after=2023-02-28 00:00:00+00:00
2025-05-07 15:39:51,441 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:51,442 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:39:51,444 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:39:51,447 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-02-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:39:51,448 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:39:51,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:39:51,749 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:02,930 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:40:02,935 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:39:57.183429+00:00, run_end_date=2025-05-07 18:40:00.758002+00:00, run_duration=3.574573, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=276, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:39:51.445833+00:00, queued_by_job_id=169, pid=42615
2025-05-07 15:40:05,201 INFO - Setting next_dagrun for anomaly_detection to 2023-02-28 00:00:00+00:00, run_after=2023-03-01 00:00:00+00:00
2025-05-07 15:40:05,777 INFO - Marking run <DagRun anomaly_detection @ 2023-02-26 00:00:00+00:00: scheduled__2023-02-26T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:39:37.904835+00:00. externally triggered: False> successful
2025-05-07 15:40:05,778 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-26 00:00:00+00:00, run_id=scheduled__2023-02-26T00:00:00+00:00, run_start_date=2025-05-07 18:39:38.128775+00:00, run_end_date=2025-05-07 18:40:05.778492+00:00, run_duration=27.649717, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-26 00:00:00+00:00, data_interval_end=2023-02-27 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:40:05,782 INFO - Setting next_dagrun for anomaly_detection to 2023-02-27 00:00:00+00:00, run_after=2023-02-28 00:00:00+00:00
2025-05-07 15:40:06,178 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:40:06,179 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:40:06,180 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:40:06,182 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-27T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:40:06,183 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:40:06,184 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:06,729 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:16,477 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-27T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:40:16,816 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-27T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:40:12.305326+00:00, run_end_date=2025-05-07 18:40:13.820733+00:00, run_duration=1.515407, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:40:06.181599+00:00, queued_by_job_id=169, pid=42651
2025-05-07 15:40:20,335 INFO - Setting next_dagrun for anomaly_detection to 2023-03-01 00:00:00+00:00, run_after=2023-03-02 00:00:00+00:00
2025-05-07 15:40:21,349 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:40:21,350 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:40:21,351 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:40:21,352 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:40:21,356 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-02-28T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-27T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:40:21,356 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:40:21,357 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:21,358 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:40:21,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:21,647 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:32,667 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:43,338 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-02-28T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:40:43,339 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-27T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:40:43,344 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-27T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:40:38.176064+00:00, run_end_date=2025-05-07 18:40:40.845276+00:00, run_duration=2.669212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=279, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:40:21.354204+00:00, queued_by_job_id=169, pid=42737
2025-05-07 15:40:43,344 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-02-28T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:40:27.436985+00:00, run_end_date=2025-05-07 18:40:30.198224+00:00, run_duration=2.761239, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=278, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:40:21.354204+00:00, queued_by_job_id=169, pid=42715
2025-05-07 15:40:44,240 INFO - Setting next_dagrun for anomaly_detection to 2023-03-02 00:00:00+00:00, run_after=2023-03-03 00:00:00+00:00
2025-05-07 15:40:44,769 INFO - Marking run <DagRun anomaly_detection @ 2023-02-27 00:00:00+00:00: scheduled__2023-02-27T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:40:05.195092+00:00. externally triggered: False> successful
2025-05-07 15:40:44,769 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-27 00:00:00+00:00, run_id=scheduled__2023-02-27T00:00:00+00:00, run_start_date=2025-05-07 18:40:05.422538+00:00, run_end_date=2025-05-07 18:40:44.769739+00:00, run_duration=39.347201, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-27 00:00:00+00:00, data_interval_end=2023-02-28 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:40:44,773 INFO - Setting next_dagrun for anomaly_detection to 2023-02-28 00:00:00+00:00, run_after=2023-03-01 00:00:00+00:00
2025-05-07 15:40:45,159 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-28T00:00:00+00:00 [scheduled]>
2025-05-07 15:40:45,161 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:40:45,162 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:40:45,162 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-02-28T00:00:00+00:00 [scheduled]>
2025-05-07 15:40:45,166 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-01T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-02-28T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:40:45,166 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:40:45,167 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:45,168 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:40:45,168 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:45,456 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:40:56,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:07,384 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:41:07,385 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-02-28T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:41:07,390 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:40:50.896031+00:00, run_end_date=2025-05-07 18:40:53.721018+00:00, run_duration=2.824987, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=280, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:40:45.164374+00:00, queued_by_job_id=169, pid=42766
2025-05-07 15:41:07,390 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-02-28T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:41:01.776651+00:00, run_end_date=2025-05-07 18:41:03.577440+00:00, run_duration=1.800789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=281, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:40:45.164374+00:00, queued_by_job_id=169, pid=42791
2025-05-07 15:41:09,007 INFO - Setting next_dagrun for anomaly_detection to 2023-03-01 00:00:00+00:00, run_after=2023-03-02 00:00:00+00:00
2025-05-07 15:41:09,245 INFO - Marking run <DagRun anomaly_detection @ 2023-02-28 00:00:00+00:00: scheduled__2023-02-28T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:40:20.331612+00:00. externally triggered: False> successful
2025-05-07 15:41:09,245 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-02-28 00:00:00+00:00, run_id=scheduled__2023-02-28T00:00:00+00:00, run_start_date=2025-05-07 18:40:20.688756+00:00, run_end_date=2025-05-07 18:41:09.245766+00:00, run_duration=48.55701, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-02-28 00:00:00+00:00, data_interval_end=2023-03-01 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:41:09,249 INFO - Setting next_dagrun for anomaly_detection to 2023-03-01 00:00:00+00:00, run_after=2023-03-02 00:00:00+00:00
2025-05-07 15:41:09,563 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-01T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:09,564 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:41:09,565 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-01T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:09,568 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-01T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:41:09,569 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-01T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:41:09,570 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:09,997 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:20,786 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-01T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:41:20,790 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-01T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:41:15.533417+00:00, run_end_date=2025-05-07 18:41:18.671948+00:00, run_duration=3.138531, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:41:09.567166+00:00, queued_by_job_id=169, pid=42822
2025-05-07 15:41:24,399 INFO - Setting next_dagrun for anomaly_detection to 2023-03-03 00:00:00+00:00, run_after=2023-03-04 00:00:00+00:00
2025-05-07 15:41:24,966 INFO - Marking run <DagRun anomaly_detection @ 2023-03-01 00:00:00+00:00: scheduled__2023-03-01T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:40:44.236478+00:00. externally triggered: False> successful
2025-05-07 15:41:24,966 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-01 00:00:00+00:00, run_id=scheduled__2023-03-01T00:00:00+00:00, run_start_date=2025-05-07 18:40:44.432825+00:00, run_end_date=2025-05-07 18:41:24.966630+00:00, run_duration=40.533805, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-01 00:00:00+00:00, data_interval_end=2023-03-02 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:41:24,971 INFO - Setting next_dagrun for anomaly_detection to 2023-03-02 00:00:00+00:00, run_after=2023-03-03 00:00:00+00:00
2025-05-07 15:41:25,283 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:25,284 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:41:25,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:25,288 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:41:25,289 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:41:25,289 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:25,582 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:35,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:41:35,277 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:41:31.008005+00:00, run_end_date=2025-05-07 18:41:32.634792+00:00, run_duration=1.626787, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=283, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:41:25.286180+00:00, queued_by_job_id=169, pid=42857
2025-05-07 15:41:36,062 INFO - Setting next_dagrun for anomaly_detection to 2023-03-03 00:00:00+00:00, run_after=2023-03-04 00:00:00+00:00
2025-05-07 15:41:36,668 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:36,669 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:41:36,670 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-02T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:36,673 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-02T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:41:36,675 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-02T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:41:36,676 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:37,010 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:47,077 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-02T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:41:47,083 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-02T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:41:42.718782+00:00, run_end_date=2025-05-07 18:41:44.651388+00:00, run_duration=1.932606, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=284, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:41:36.672217+00:00, queued_by_job_id=169, pid=42880
2025-05-07 15:41:48,551 INFO - Setting next_dagrun for anomaly_detection to 2023-03-04 00:00:00+00:00, run_after=2023-03-05 00:00:00+00:00
2025-05-07 15:41:49,235 INFO - Marking run <DagRun anomaly_detection @ 2023-03-02 00:00:00+00:00: scheduled__2023-03-02T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:41:24.395802+00:00. externally triggered: False> successful
2025-05-07 15:41:49,236 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-02 00:00:00+00:00, run_id=scheduled__2023-03-02T00:00:00+00:00, run_start_date=2025-05-07 18:41:24.605587+00:00, run_end_date=2025-05-07 18:41:49.236008+00:00, run_duration=24.630421, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-02 00:00:00+00:00, data_interval_end=2023-03-03 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:41:49,239 INFO - Setting next_dagrun for anomaly_detection to 2023-03-03 00:00:00+00:00, run_after=2023-03-04 00:00:00+00:00
2025-05-07 15:41:49,537 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:49,538 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:41:49,538 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:41:49,540 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:41:49,541 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:41:49,542 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:49,964 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:41:59,502 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:41:59,560 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:41:55.309466+00:00, run_end_date=2025-05-07 18:41:56.850823+00:00, run_duration=1.541357, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=285, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:41:49.539298+00:00, queued_by_job_id=169, pid=42912
2025-05-07 15:42:02,870 INFO - Setting next_dagrun for anomaly_detection to 2023-03-05 00:00:00+00:00, run_after=2023-03-06 00:00:00+00:00
2025-05-07 15:42:03,866 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:42:03,867 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:42:03,867 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:42:03,868 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-03T00:00:00+00:00 [scheduled]>
2025-05-07 15:42:03,871 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-04T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:42:03,872 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:42:03,872 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:03,873 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:42:03,873 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:04,174 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:15,323 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:25,974 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:42:25,974 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:42:25,978 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-03T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:42:20.736212+00:00, run_end_date=2025-05-07 18:42:23.597519+00:00, run_duration=2.861307, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=287, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:42:03.869896+00:00, queued_by_job_id=169, pid=42966
2025-05-07 15:42:25,979 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:42:09.813432+00:00, run_end_date=2025-05-07 18:42:12.707356+00:00, run_duration=2.893924, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=286, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:42:03.869896+00:00, queued_by_job_id=169, pid=42943
2025-05-07 15:42:26,779 INFO - Setting next_dagrun for anomaly_detection to 2023-03-06 00:00:00+00:00, run_after=2023-03-07 00:00:00+00:00
2025-05-07 15:42:27,724 INFO - Marking run <DagRun anomaly_detection @ 2023-03-03 00:00:00+00:00: scheduled__2023-03-03T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:41:48.546198+00:00. externally triggered: False> successful
2025-05-07 15:42:27,725 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-03 00:00:00+00:00, run_id=scheduled__2023-03-03T00:00:00+00:00, run_start_date=2025-05-07 18:41:48.873808+00:00, run_end_date=2025-05-07 18:42:27.725026+00:00, run_duration=38.851218, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-03 00:00:00+00:00, data_interval_end=2023-03-04 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:42:27,731 INFO - Setting next_dagrun for anomaly_detection to 2023-03-04 00:00:00+00:00, run_after=2023-03-05 00:00:00+00:00
2025-05-07 15:42:28,047 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-04T00:00:00+00:00 [scheduled]>
2025-05-07 15:42:28,049 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:42:28,050 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:42:28,051 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-04T00:00:00+00:00 [scheduled]>
2025-05-07 15:42:28,887 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-05T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:42:28,888 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:42:28,889 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:28,890 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:42:28,891 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:29,180 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:39,296 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:49,880 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:42:49,881 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:42:49,885 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:42:35.369072+00:00, run_end_date=2025-05-07 18:42:36.904077+00:00, run_duration=1.535005, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=288, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:42:28.054435+00:00, queued_by_job_id=169, pid=42991
2025-05-07 15:42:49,885 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-04T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:42:44.850462+00:00, run_end_date=2025-05-07 18:42:47.276912+00:00, run_duration=2.42645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=289, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:42:28.054435+00:00, queued_by_job_id=169, pid=43013
2025-05-07 15:42:50,310 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:42:51,582 INFO - Setting next_dagrun for anomaly_detection to 2023-03-05 00:00:00+00:00, run_after=2023-03-06 00:00:00+00:00
2025-05-07 15:42:51,879 INFO - Marking run <DagRun anomaly_detection @ 2023-03-04 00:00:00+00:00: scheduled__2023-03-04T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:42:02.864549+00:00. externally triggered: False> successful
2025-05-07 15:42:51,880 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-04 00:00:00+00:00, run_id=scheduled__2023-03-04T00:00:00+00:00, run_start_date=2025-05-07 18:42:03.165396+00:00, run_end_date=2025-05-07 18:42:51.880180+00:00, run_duration=48.714784, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-04 00:00:00+00:00, data_interval_end=2023-03-05 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:42:51,884 INFO - Setting next_dagrun for anomaly_detection to 2023-03-05 00:00:00+00:00, run_after=2023-03-06 00:00:00+00:00
2025-05-07 15:42:52,268 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-05T00:00:00+00:00 [scheduled]>
2025-05-07 15:42:52,271 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:42:52,272 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-05T00:00:00+00:00 [scheduled]>
2025-05-07 15:42:52,278 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:42:52,280 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:42:52,281 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:42:52,573 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:03,947 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:43:04,788 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-05T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:42:59.231507+00:00, run_end_date=2025-05-07 18:43:01.771377+00:00, run_duration=2.53987, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=290, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:42:52.275047+00:00, queued_by_job_id=169, pid=43045
2025-05-07 15:43:08,241 INFO - Setting next_dagrun for anomaly_detection to 2023-03-07 00:00:00+00:00, run_after=2023-03-08 00:00:00+00:00
2025-05-07 15:43:08,763 INFO - Marking run <DagRun anomaly_detection @ 2023-03-05 00:00:00+00:00: scheduled__2023-03-05T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:42:26.774232+00:00. externally triggered: False> successful
2025-05-07 15:43:08,764 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-05 00:00:00+00:00, run_id=scheduled__2023-03-05T00:00:00+00:00, run_start_date=2025-05-07 18:42:27.390634+00:00, run_end_date=2025-05-07 18:43:08.764557+00:00, run_duration=41.373923, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-05 00:00:00+00:00, data_interval_end=2023-03-06 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:43:08,769 INFO - Setting next_dagrun for anomaly_detection to 2023-03-06 00:00:00+00:00, run_after=2023-03-07 00:00:00+00:00
2025-05-07 15:43:09,145 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:09,146 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:43:09,147 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:09,150 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:43:09,151 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:43:09,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:09,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:21,290 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:43:21,294 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:43:15.450446+00:00, run_end_date=2025-05-07 18:43:18.571370+00:00, run_duration=3.120924, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=291, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:43:09.148436+00:00, queued_by_job_id=169, pid=43077
2025-05-07 15:43:23,401 INFO - Setting next_dagrun for anomaly_detection to 2023-03-07 00:00:00+00:00, run_after=2023-03-08 00:00:00+00:00
2025-05-07 15:43:24,452 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:24,453 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:43:24,455 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-06T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:24,460 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:43:24,462 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:43:24,464 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:24,818 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:34,694 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:43:34,700 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-06T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:43:30.500458+00:00, run_end_date=2025-05-07 18:43:32.438416+00:00, run_duration=1.937958, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=292, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:43:24.457403+00:00, queued_by_job_id=169, pid=43102
2025-05-07 15:43:36,307 INFO - Setting next_dagrun for anomaly_detection to 2023-03-08 00:00:00+00:00, run_after=2023-03-09 00:00:00+00:00
2025-05-07 15:43:36,898 INFO - Marking run <DagRun anomaly_detection @ 2023-03-06 00:00:00+00:00: scheduled__2023-03-06T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:43:08.237661+00:00. externally triggered: False> successful
2025-05-07 15:43:36,898 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-06 00:00:00+00:00, run_id=scheduled__2023-03-06T00:00:00+00:00, run_start_date=2025-05-07 18:43:08.444343+00:00, run_end_date=2025-05-07 18:43:36.898821+00:00, run_duration=28.454478, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-06 00:00:00+00:00, data_interval_end=2023-03-07 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:43:36,903 INFO - Setting next_dagrun for anomaly_detection to 2023-03-07 00:00:00+00:00, run_after=2023-03-08 00:00:00+00:00
2025-05-07 15:43:37,255 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:37,256 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:43:37,257 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:37,261 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:43:37,262 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:43:37,262 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:37,584 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:47,354 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:43:47,359 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:43:43.129475+00:00, run_end_date=2025-05-07 18:43:44.658266+00:00, run_duration=1.528791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=293, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:43:37.259179+00:00, queued_by_job_id=169, pid=43133
2025-05-07 15:43:50,601 INFO - Setting next_dagrun for anomaly_detection to 2023-03-09 00:00:00+00:00, run_after=2023-03-10 00:00:00+00:00
2025-05-07 15:43:51,570 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:51,571 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:43:51,573 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:43:51,574 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-07T00:00:00+00:00 [scheduled]>
2025-05-07 15:43:51,578 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-08T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:43:51,580 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:43:51,580 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:51,582 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:43:51,583 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:43:51,909 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:02,706 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:13,588 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:44:13,589 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:44:13,593 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-07T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:44:08.022909+00:00, run_end_date=2025-05-07 18:44:10.572858+00:00, run_duration=2.549949, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=295, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:43:51.576556+00:00, queued_by_job_id=169, pid=43187
2025-05-07 15:44:13,593 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:43:57.202162+00:00, run_end_date=2025-05-07 18:44:00.205856+00:00, run_duration=3.003694, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=294, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:43:51.576556+00:00, queued_by_job_id=169, pid=43164
2025-05-07 15:44:14,486 INFO - Setting next_dagrun for anomaly_detection to 2023-03-10 00:00:00+00:00, run_after=2023-03-11 00:00:00+00:00
2025-05-07 15:44:15,311 INFO - Marking run <DagRun anomaly_detection @ 2023-03-07 00:00:00+00:00: scheduled__2023-03-07T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:43:36.303175+00:00. externally triggered: False> successful
2025-05-07 15:44:15,312 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-07 00:00:00+00:00, run_id=scheduled__2023-03-07T00:00:00+00:00, run_start_date=2025-05-07 18:43:36.543730+00:00, run_end_date=2025-05-07 18:44:15.312228+00:00, run_duration=38.768498, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-07 00:00:00+00:00, data_interval_end=2023-03-08 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:44:15,315 INFO - Setting next_dagrun for anomaly_detection to 2023-03-08 00:00:00+00:00, run_after=2023-03-09 00:00:00+00:00
2025-05-07 15:44:15,636 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-08T00:00:00+00:00 [scheduled]>
2025-05-07 15:44:15,637 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:44:15,638 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:44:15,639 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-08T00:00:00+00:00 [scheduled]>
2025-05-07 15:44:15,644 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-09T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:44:15,645 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:44:15,646 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:15,647 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:44:15,647 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:15,940 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:26,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:37,099 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:44:37,099 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-08T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:44:37,104 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-08T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:44:32.079803+00:00, run_end_date=2025-05-07 18:44:34.528423+00:00, run_duration=2.44862, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=297, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:44:15.642081+00:00, queued_by_job_id=169, pid=43235
2025-05-07 15:44:37,105 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:44:21.200207+00:00, run_end_date=2025-05-07 18:44:23.894964+00:00, run_duration=2.694757, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=296, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:44:15.642081+00:00, queued_by_job_id=169, pid=43212
2025-05-07 15:44:38,694 INFO - Setting next_dagrun for anomaly_detection to 2023-03-09 00:00:00+00:00, run_after=2023-03-10 00:00:00+00:00
2025-05-07 15:44:38,914 INFO - Marking run <DagRun anomaly_detection @ 2023-03-08 00:00:00+00:00: scheduled__2023-03-08T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:43:50.598333+00:00. externally triggered: False> successful
2025-05-07 15:44:38,915 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-08 00:00:00+00:00, run_id=scheduled__2023-03-08T00:00:00+00:00, run_start_date=2025-05-07 18:43:50.817409+00:00, run_end_date=2025-05-07 18:44:38.915218+00:00, run_duration=48.097809, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-08 00:00:00+00:00, data_interval_end=2023-03-09 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:44:38,918 INFO - Setting next_dagrun for anomaly_detection to 2023-03-09 00:00:00+00:00, run_after=2023-03-10 00:00:00+00:00
2025-05-07 15:44:39,244 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:44:39,245 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:44:39,246 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-09T00:00:00+00:00 [scheduled]>
2025-05-07 15:44:39,251 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:44:39,252 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:44:39,254 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:39,603 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:50,261 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:44:50,264 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-09T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:44:45.009007+00:00, run_end_date=2025-05-07 18:44:48.071840+00:00, run_duration=3.062833, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=298, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:44:39.248617+00:00, queued_by_job_id=169, pid=43266
2025-05-07 15:44:53,868 INFO - Setting next_dagrun for anomaly_detection to 2023-03-11 00:00:00+00:00, run_after=2023-03-12 00:00:00+00:00
2025-05-07 15:44:54,418 INFO - Marking run <DagRun anomaly_detection @ 2023-03-09 00:00:00+00:00: scheduled__2023-03-09T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:44:14.473452+00:00. externally triggered: False> successful
2025-05-07 15:44:54,419 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-09 00:00:00+00:00, run_id=scheduled__2023-03-09T00:00:00+00:00, run_start_date=2025-05-07 18:44:14.866347+00:00, run_end_date=2025-05-07 18:44:54.419392+00:00, run_duration=39.553045, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-09 00:00:00+00:00, data_interval_end=2023-03-10 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:44:54,423 INFO - Setting next_dagrun for anomaly_detection to 2023-03-10 00:00:00+00:00, run_after=2023-03-11 00:00:00+00:00
2025-05-07 15:44:54,736 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:44:54,737 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:44:54,738 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:44:54,741 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:44:54,742 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:44:54,742 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:44:55,082 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:04,918 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:45:04,923 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:45:00.546000+00:00, run_end_date=2025-05-07 18:45:02.232140+00:00, run_duration=1.68614, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=299, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:44:54.739640+00:00, queued_by_job_id=169, pid=43298
2025-05-07 15:45:05,726 INFO - Setting next_dagrun for anomaly_detection to 2023-03-11 00:00:00+00:00, run_after=2023-03-12 00:00:00+00:00
2025-05-07 15:45:06,395 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:45:06,396 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:45:06,397 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-10T00:00:00+00:00 [scheduled]>
2025-05-07 15:45:06,399 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-10T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:45:06,400 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-10T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:45:06,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:06,694 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:16,751 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-10T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:45:16,755 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-10T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:45:12.313894+00:00, run_end_date=2025-05-07 18:45:14.357952+00:00, run_duration=2.044058, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=300, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:45:06.398517+00:00, queued_by_job_id=169, pid=43324
2025-05-07 15:45:18,458 INFO - Setting next_dagrun for anomaly_detection to 2023-03-12 00:00:00+00:00, run_after=2023-03-13 00:00:00+00:00
2025-05-07 15:45:18,968 INFO - Marking run <DagRun anomaly_detection @ 2023-03-10 00:00:00+00:00: scheduled__2023-03-10T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:44:53.864956+00:00. externally triggered: False> successful
2025-05-07 15:45:18,968 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-10 00:00:00+00:00, run_id=scheduled__2023-03-10T00:00:00+00:00, run_start_date=2025-05-07 18:44:54.099034+00:00, run_end_date=2025-05-07 18:45:18.968545+00:00, run_duration=24.869511, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-10 00:00:00+00:00, data_interval_end=2023-03-11 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:45:18,971 INFO - Setting next_dagrun for anomaly_detection to 2023-03-11 00:00:00+00:00, run_after=2023-03-12 00:00:00+00:00
2025-05-07 15:45:19,337 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:45:19,339 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:45:19,340 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:45:19,345 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:45:19,346 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:45:19,347 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:19,694 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:30,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:45:30,598 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:45:25.199773+00:00, run_end_date=2025-05-07 18:45:27.031440+00:00, run_duration=1.831667, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=301, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:45:19.342587+00:00, queued_by_job_id=169, pid=43385
2025-05-07 15:45:34,759 INFO - Setting next_dagrun for anomaly_detection to 2023-03-13 00:00:00+00:00, run_after=2023-03-14 00:00:00+00:00
2025-05-07 15:45:35,839 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:45:35,840 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:45:35,841 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:45:35,842 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-11T00:00:00+00:00 [scheduled]>
2025-05-07 15:45:35,851 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-12T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-11T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:45:35,852 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:45:35,854 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:35,855 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-11T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:45:35,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:36,296 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:47,213 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:45:57,382 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:45:57,382 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-11T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:45:57,387 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:45:42.116196+00:00, run_end_date=2025-05-07 18:45:44.402925+00:00, run_duration=2.286729, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=302, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:45:35.846575+00:00, queued_by_job_id=169, pid=43417
2025-05-07 15:45:57,388 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-11T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:45:52.965174+00:00, run_end_date=2025-05-07 18:45:55.000884+00:00, run_duration=2.03571, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=303, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:45:35.846575+00:00, queued_by_job_id=169, pid=43445
2025-05-07 15:45:59,186 INFO - Setting next_dagrun for anomaly_detection to 2023-03-14 00:00:00+00:00, run_after=2023-03-15 00:00:00+00:00
2025-05-07 15:45:59,719 INFO - Marking run <DagRun anomaly_detection @ 2023-03-11 00:00:00+00:00: scheduled__2023-03-11T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:45:18.455626+00:00. externally triggered: False> successful
2025-05-07 15:45:59,719 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-11 00:00:00+00:00, run_id=scheduled__2023-03-11T00:00:00+00:00, run_start_date=2025-05-07 18:45:18.668805+00:00, run_end_date=2025-05-07 18:45:59.719863+00:00, run_duration=41.051058, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-11 00:00:00+00:00, data_interval_end=2023-03-12 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:45:59,724 INFO - Setting next_dagrun for anomaly_detection to 2023-03-12 00:00:00+00:00, run_after=2023-03-13 00:00:00+00:00
2025-05-07 15:46:00,026 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-12T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:00,027 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:46:00,028 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:46:00,029 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-12T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:00,032 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-13T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:46:00,033 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:46:00,033 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:00,034 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:46:00,035 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:00,384 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:09,964 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:21,211 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:46:21,212 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-12T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:46:21,217 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-12T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:46:15.484085+00:00, run_end_date=2025-05-07 18:46:18.487538+00:00, run_duration=3.003453, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=305, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:46:00.030693+00:00, queued_by_job_id=169, pid=43491
2025-05-07 15:46:21,218 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:46:05.801378+00:00, run_end_date=2025-05-07 18:46:07.368415+00:00, run_duration=1.567037, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=304, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:46:00.030693+00:00, queued_by_job_id=169, pid=43470
2025-05-07 15:46:23,281 INFO - Setting next_dagrun for anomaly_detection to 2023-03-13 00:00:00+00:00, run_after=2023-03-14 00:00:00+00:00
2025-05-07 15:46:23,533 INFO - Marking run <DagRun anomaly_detection @ 2023-03-12 00:00:00+00:00: scheduled__2023-03-12T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:45:34.755092+00:00. externally triggered: False> successful
2025-05-07 15:46:23,534 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-12 00:00:00+00:00, run_id=scheduled__2023-03-12T00:00:00+00:00, run_start_date=2025-05-07 18:45:34.966919+00:00, run_end_date=2025-05-07 18:46:23.534508+00:00, run_duration=48.567589, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-12 00:00:00+00:00, data_interval_end=2023-03-13 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:46:23,539 INFO - Setting next_dagrun for anomaly_detection to 2023-03-13 00:00:00+00:00, run_after=2023-03-14 00:00:00+00:00
2025-05-07 15:46:23,822 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:23,823 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:46:23,823 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-13T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:23,825 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-13T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:46:23,825 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-13T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:46:23,825 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:24,153 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:33,979 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-13T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:46:34,213 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-13T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:46:29.635700+00:00, run_end_date=2025-05-07 18:46:31.727678+00:00, run_duration=2.091978, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=306, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:46:23.824235+00:00, queued_by_job_id=169, pid=43526
2025-05-07 15:46:37,841 INFO - Setting next_dagrun for anomaly_detection to 2023-03-15 00:00:00+00:00, run_after=2023-03-16 00:00:00+00:00
2025-05-07 15:46:38,578 INFO - Marking run <DagRun anomaly_detection @ 2023-03-13 00:00:00+00:00: scheduled__2023-03-13T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:45:59.173640+00:00. externally triggered: False> successful
2025-05-07 15:46:38,580 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-13 00:00:00+00:00, run_id=scheduled__2023-03-13T00:00:00+00:00, run_start_date=2025-05-07 18:45:59.405298+00:00, run_end_date=2025-05-07 18:46:38.579908+00:00, run_duration=39.17461, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-13 00:00:00+00:00, data_interval_end=2023-03-14 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:46:38,585 INFO - Setting next_dagrun for anomaly_detection to 2023-03-14 00:00:00+00:00, run_after=2023-03-15 00:00:00+00:00
2025-05-07 15:46:38,912 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:38,913 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:46:38,914 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:38,918 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:46:38,919 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:46:38,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:39,278 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:48,918 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:46:49,357 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:46:44.783752+00:00, run_end_date=2025-05-07 18:46:46.386756+00:00, run_duration=1.603004, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=307, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:46:38.916752+00:00, queued_by_job_id=169, pid=43558
2025-05-07 15:46:50,347 INFO - Setting next_dagrun for anomaly_detection to 2023-03-15 00:00:00+00:00, run_after=2023-03-16 00:00:00+00:00
2025-05-07 15:46:50,906 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:50,907 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:46:50,908 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-14T00:00:00+00:00 [scheduled]>
2025-05-07 15:46:50,911 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-14T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:46:50,912 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-14T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:46:50,913 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:46:51,204 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:01,512 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-14T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:47:01,516 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-14T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:46:56.613294+00:00, run_end_date=2025-05-07 18:46:59.230446+00:00, run_duration=2.617152, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=308, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:46:50.909394+00:00, queued_by_job_id=169, pid=43581
2025-05-07 15:47:03,439 INFO - Setting next_dagrun for anomaly_detection to 2023-03-16 00:00:00+00:00, run_after=2023-03-17 00:00:00+00:00
2025-05-07 15:47:04,038 INFO - Marking run <DagRun anomaly_detection @ 2023-03-14 00:00:00+00:00: scheduled__2023-03-14T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:46:37.837605+00:00. externally triggered: False> successful
2025-05-07 15:47:04,041 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-14 00:00:00+00:00, run_id=scheduled__2023-03-14T00:00:00+00:00, run_start_date=2025-05-07 18:46:38.117787+00:00, run_end_date=2025-05-07 18:47:04.040889+00:00, run_duration=25.923102, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-14 00:00:00+00:00, data_interval_end=2023-03-15 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:47:04,060 INFO - Setting next_dagrun for anomaly_detection to 2023-03-15 00:00:00+00:00, run_after=2023-03-16 00:00:00+00:00
2025-05-07 15:47:04,368 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:47:04,370 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:47:04,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:47:04,377 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-15T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:47:04,380 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:47:04,381 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:04,695 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:15,758 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:47:16,599 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:47:10.315322+00:00, run_end_date=2025-05-07 18:47:12.635812+00:00, run_duration=2.32049, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=309, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:47:04.374250+00:00, queued_by_job_id=169, pid=43614
2025-05-07 15:47:19,877 INFO - Setting next_dagrun for anomaly_detection to 2023-03-17 00:00:00+00:00, run_after=2023-03-18 00:00:00+00:00
2025-05-07 15:47:20,749 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:47:20,750 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:47:20,751 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:47:20,752 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-15T00:00:00+00:00 [scheduled]>
2025-05-07 15:47:20,755 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-16T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-15T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:47:20,755 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:47:20,756 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:20,757 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-15T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:47:20,757 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:21,081 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:32,099 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:42,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:47:42,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:47:42,123 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:47:26.681584+00:00, run_end_date=2025-05-07 18:47:29.450634+00:00, run_duration=2.76905, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=310, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:47:20.753456+00:00, queued_by_job_id=169, pid=43646
2025-05-07 15:47:42,124 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-15T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:47:37.509115+00:00, run_end_date=2025-05-07 18:47:39.398972+00:00, run_duration=1.889857, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=311, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:47:20.753456+00:00, queued_by_job_id=169, pid=43668
2025-05-07 15:47:42,891 INFO - Setting next_dagrun for anomaly_detection to 2023-03-18 00:00:00+00:00, run_after=2023-03-19 00:00:00+00:00
2025-05-07 15:47:43,881 INFO - Marking run <DagRun anomaly_detection @ 2023-03-15 00:00:00+00:00: scheduled__2023-03-15T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:47:03.434608+00:00. externally triggered: False> successful
2025-05-07 15:47:43,881 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-15 00:00:00+00:00, run_id=scheduled__2023-03-15T00:00:00+00:00, run_start_date=2025-05-07 18:47:03.691841+00:00, run_end_date=2025-05-07 18:47:43.881909+00:00, run_duration=40.190068, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-15 00:00:00+00:00, data_interval_end=2023-03-16 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:47:43,885 INFO - Setting next_dagrun for anomaly_detection to 2023-03-16 00:00:00+00:00, run_after=2023-03-17 00:00:00+00:00
2025-05-07 15:47:44,260 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-16T00:00:00+00:00 [scheduled]>
2025-05-07 15:47:44,261 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:47:44,261 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:47:44,262 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-16T00:00:00+00:00 [scheduled]>
2025-05-07 15:47:44,265 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-17T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-16T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:47:44,265 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:47:44,266 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:44,266 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:47:44,267 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:44,836 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:47:55,706 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:07,454 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:48:07,454 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:48:07,459 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-16T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:48:01.418606+00:00, run_end_date=2025-05-07 18:48:04.014787+00:00, run_duration=2.596181, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=313, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:47:44.263432+00:00, queued_by_job_id=169, pid=43714
2025-05-07 15:48:07,459 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:47:50.302185+00:00, run_end_date=2025-05-07 18:47:53.185154+00:00, run_duration=2.882969, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=312, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:47:44.263432+00:00, queued_by_job_id=169, pid=43692
2025-05-07 15:48:07,799 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-05-07 15:48:08,984 INFO - Setting next_dagrun for anomaly_detection to 2023-03-17 00:00:00+00:00, run_after=2023-03-18 00:00:00+00:00
2025-05-07 15:48:09,490 INFO - Marking run <DagRun anomaly_detection @ 2023-03-16 00:00:00+00:00: scheduled__2023-03-16T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:47:19.872833+00:00. externally triggered: False> successful
2025-05-07 15:48:09,490 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-16 00:00:00+00:00, run_id=scheduled__2023-03-16T00:00:00+00:00, run_start_date=2025-05-07 18:47:20.087807+00:00, run_end_date=2025-05-07 18:48:09.490824+00:00, run_duration=49.403017, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-16 00:00:00+00:00, data_interval_end=2023-03-17 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:48:09,494 INFO - Setting next_dagrun for anomaly_detection to 2023-03-17 00:00:00+00:00, run_after=2023-03-18 00:00:00+00:00
2025-05-07 15:48:09,867 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:09,868 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:48:09,870 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-17T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:09,874 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-17T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:48:09,875 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-17T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:48:09,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:10,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:22,039 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-17T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:48:22,980 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-17T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:48:15.857263+00:00, run_end_date=2025-05-07 18:48:19.115397+00:00, run_duration=3.258134, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=314, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:48:09.872669+00:00, queued_by_job_id=169, pid=43745
2025-05-07 15:48:26,560 INFO - Setting next_dagrun for anomaly_detection to 2023-03-19 00:00:00+00:00, run_after=2023-03-20 00:00:00+00:00
2025-05-07 15:48:27,369 INFO - Marking run <DagRun anomaly_detection @ 2023-03-17 00:00:00+00:00: scheduled__2023-03-17T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:47:42.887020+00:00. externally triggered: False> successful
2025-05-07 15:48:27,370 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-17 00:00:00+00:00, run_id=scheduled__2023-03-17T00:00:00+00:00, run_start_date=2025-05-07 18:47:43.127216+00:00, run_end_date=2025-05-07 18:48:27.370250+00:00, run_duration=44.243034, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-17 00:00:00+00:00, data_interval_end=2023-03-18 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:48:27,374 INFO - Setting next_dagrun for anomaly_detection to 2023-03-18 00:00:00+00:00, run_after=2023-03-19 00:00:00+00:00
2025-05-07 15:48:27,878 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:27,879 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:48:27,881 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:27,888 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:48:27,890 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:48:27,892 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:28,519 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:39,448 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:48:39,452 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:48:34.094670+00:00, run_end_date=2025-05-07 18:48:36.728517+00:00, run_duration=2.633847, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=315, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:48:27.883942+00:00, queued_by_job_id=169, pid=43779
2025-05-07 15:48:41,526 INFO - Setting next_dagrun for anomaly_detection to 2023-03-19 00:00:00+00:00, run_after=2023-03-20 00:00:00+00:00
2025-05-07 15:48:42,301 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:42,303 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:48:42,304 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-18T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:42,308 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-18T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:48:42,309 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-18T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:48:42,310 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:42,608 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:52,905 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-18T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:48:52,910 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-18T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:48:48.444547+00:00, run_end_date=2025-05-07 18:48:50.517470+00:00, run_duration=2.072923, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=316, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:48:42.306225+00:00, queued_by_job_id=169, pid=43802
2025-05-07 15:48:54,559 INFO - Setting next_dagrun for anomaly_detection to 2023-03-20 00:00:00+00:00, run_after=2023-03-21 00:00:00+00:00
2025-05-07 15:48:55,164 INFO - Marking run <DagRun anomaly_detection @ 2023-03-18 00:00:00+00:00: scheduled__2023-03-18T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:48:26.556840+00:00. externally triggered: False> successful
2025-05-07 15:48:55,165 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-18 00:00:00+00:00, run_id=scheduled__2023-03-18T00:00:00+00:00, run_start_date=2025-05-07 18:48:26.758222+00:00, run_end_date=2025-05-07 18:48:55.165099+00:00, run_duration=28.406877, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-18 00:00:00+00:00, data_interval_end=2023-03-19 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:48:55,167 INFO - Setting next_dagrun for anomaly_detection to 2023-03-19 00:00:00+00:00, run_after=2023-03-20 00:00:00+00:00
2025-05-07 15:48:55,483 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:55,484 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:48:55,485 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:48:55,488 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-19T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:48:55,489 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:48:55,489 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:48:55,781 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:05,515 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:49:05,519 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:49:01.140898+00:00, run_end_date=2025-05-07 18:49:02.710611+00:00, run_duration=1.569713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=317, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:48:55.486369+00:00, queued_by_job_id=169, pid=43834
2025-05-07 15:49:08,889 INFO - Setting next_dagrun for anomaly_detection to 2023-03-21 00:00:00+00:00, run_after=2023-03-22 00:00:00+00:00
2025-05-07 15:49:10,101 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:49:10,103 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:49:10,105 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:49:10,108 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-19T00:00:00+00:00 [scheduled]>
2025-05-07 15:49:10,120 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-20T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-19T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:49:10,125 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:49:10,127 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:10,129 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-19T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:49:10,132 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:10,431 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:22,128 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:32,271 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:49:32,272 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-19T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:49:32,277 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-19T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:49:27.403731+00:00, run_end_date=2025-05-07 18:49:30.212550+00:00, run_duration=2.808819, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=319, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:49:10.113215+00:00, queued_by_job_id=169, pid=43888
2025-05-07 15:49:32,277 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:49:17.563908+00:00, run_end_date=2025-05-07 18:49:19.179185+00:00, run_duration=1.615277, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=318, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:49:10.113215+00:00, queued_by_job_id=169, pid=43865
2025-05-07 15:49:33,033 INFO - Setting next_dagrun for anomaly_detection to 2023-03-22 00:00:00+00:00, run_after=2023-03-23 00:00:00+00:00
2025-05-07 15:49:33,601 INFO - Marking run <DagRun anomaly_detection @ 2023-03-19 00:00:00+00:00: scheduled__2023-03-19T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:48:54.556234+00:00. externally triggered: False> successful
2025-05-07 15:49:33,602 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-19 00:00:00+00:00, run_id=scheduled__2023-03-19T00:00:00+00:00, run_start_date=2025-05-07 18:48:54.776505+00:00, run_end_date=2025-05-07 18:49:33.602841+00:00, run_duration=38.826336, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-19 00:00:00+00:00, data_interval_end=2023-03-20 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:49:33,608 INFO - Setting next_dagrun for anomaly_detection to 2023-03-20 00:00:00+00:00, run_after=2023-03-21 00:00:00+00:00
2025-05-07 15:49:33,927 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-20T00:00:00+00:00 [scheduled]>
2025-05-07 15:49:33,929 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:49:33,931 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:49:33,933 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-20T00:00:00+00:00 [scheduled]>
2025-05-07 15:49:34,270 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-21T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:49:34,272 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:49:34,273 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:34,275 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:49:34,276 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:34,566 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:45,172 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:55,565 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:49:55,566 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-20T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:49:55,570 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:49:39.825574+00:00, run_end_date=2025-05-07 18:49:42.393870+00:00, run_duration=2.568296, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=320, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:49:33.936480+00:00, queued_by_job_id=169, pid=43912
2025-05-07 15:49:55,571 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:49:50.716378+00:00, run_end_date=2025-05-07 18:49:53.405258+00:00, run_duration=2.68888, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=321, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:49:33.936480+00:00, queued_by_job_id=169, pid=43934
2025-05-07 15:49:57,057 INFO - Setting next_dagrun for anomaly_detection to 2023-03-21 00:00:00+00:00, run_after=2023-03-22 00:00:00+00:00
2025-05-07 15:49:57,310 INFO - Marking run <DagRun anomaly_detection @ 2023-03-20 00:00:00+00:00: scheduled__2023-03-20T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:49:08.885827+00:00. externally triggered: False> successful
2025-05-07 15:49:57,311 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-20 00:00:00+00:00, run_id=scheduled__2023-03-20T00:00:00+00:00, run_start_date=2025-05-07 18:49:09.408171+00:00, run_end_date=2025-05-07 18:49:57.311031+00:00, run_duration=47.90286, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-20 00:00:00+00:00, data_interval_end=2023-03-21 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:49:57,315 INFO - Setting next_dagrun for anomaly_detection to 2023-03-21 00:00:00+00:00, run_after=2023-03-22 00:00:00+00:00
2025-05-07 15:49:57,622 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:49:57,623 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:49:57,624 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-21T00:00:00+00:00 [scheduled]>
2025-05-07 15:49:57,628 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:49:57,629 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:49:57,629 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:49:57,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:08,756 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-21T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:50:08,759 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:50:03.362723+00:00, run_end_date=2025-05-07 18:50:06.633965+00:00, run_duration=3.271242, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=322, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:49:57.626597+00:00, queued_by_job_id=169, pid=43965
2025-05-07 15:50:12,526 INFO - Setting next_dagrun for anomaly_detection to 2023-03-23 00:00:00+00:00, run_after=2023-03-24 00:00:00+00:00
2025-05-07 15:50:13,145 INFO - Marking run <DagRun anomaly_detection @ 2023-03-21 00:00:00+00:00: scheduled__2023-03-21T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:49:33.025651+00:00. externally triggered: False> successful
2025-05-07 15:50:13,145 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-21 00:00:00+00:00, run_id=scheduled__2023-03-21T00:00:00+00:00, run_start_date=2025-05-07 18:49:33.272296+00:00, run_end_date=2025-05-07 18:50:13.145701+00:00, run_duration=39.873405, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-21 00:00:00+00:00, data_interval_end=2023-03-22 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:50:13,149 INFO - Setting next_dagrun for anomaly_detection to 2023-03-22 00:00:00+00:00, run_after=2023-03-23 00:00:00+00:00
2025-05-07 15:50:13,463 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:13,465 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:50:13,466 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:13,468 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:50:13,469 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:50:13,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:13,760 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:23,927 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:50:23,931 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:50:19.427090+00:00, run_end_date=2025-05-07 18:50:21.097590+00:00, run_duration=1.6705, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=323, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:50:13.467337+00:00, queued_by_job_id=169, pid=44004
2025-05-07 15:50:24,814 INFO - Setting next_dagrun for anomaly_detection to 2023-03-23 00:00:00+00:00, run_after=2023-03-24 00:00:00+00:00
2025-05-07 15:50:25,357 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:25,358 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:50:25,359 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-22T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:25,362 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-22T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:50:25,363 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-22T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:50:25,364 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:25,644 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:36,139 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-22T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:50:36,142 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-22T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:50:31.202231+00:00, run_end_date=2025-05-07 18:50:33.035791+00:00, run_duration=1.83356, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=324, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:50:25.361326+00:00, queued_by_job_id=169, pid=44058
2025-05-07 15:50:37,687 INFO - Setting next_dagrun for anomaly_detection to 2023-03-24 00:00:00+00:00, run_after=2023-03-25 00:00:00+00:00
2025-05-07 15:50:38,269 INFO - Marking run <DagRun anomaly_detection @ 2023-03-22 00:00:00+00:00: scheduled__2023-03-22T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:50:12.523162+00:00. externally triggered: False> successful
2025-05-07 15:50:38,270 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-22 00:00:00+00:00, run_id=scheduled__2023-03-22T00:00:00+00:00, run_start_date=2025-05-07 18:50:12.762343+00:00, run_end_date=2025-05-07 18:50:38.270411+00:00, run_duration=25.508068, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-22 00:00:00+00:00, data_interval_end=2023-03-23 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:50:38,275 INFO - Setting next_dagrun for anomaly_detection to 2023-03-23 00:00:00+00:00, run_after=2023-03-24 00:00:00+00:00
2025-05-07 15:50:38,615 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:38,616 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:50:38,616 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:38,619 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:50:38,620 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:50:38,620 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:38,934 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:51,079 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:50:51,083 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:50:44.600680+00:00, run_end_date=2025-05-07 18:50:47.811053+00:00, run_duration=3.210373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=325, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:50:38.618063+00:00, queued_by_job_id=169, pid=44089
2025-05-07 15:50:54,754 INFO - Setting next_dagrun for anomaly_detection to 2023-03-25 00:00:00+00:00, run_after=2023-03-26 00:00:00+00:00
2025-05-07 15:50:55,748 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:55,749 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:50:55,751 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:50:55,751 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-23T00:00:00+00:00 [scheduled]>
2025-05-07 15:50:55,755 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-24T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:50:55,755 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:50:55,756 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:55,757 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:50:55,757 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:50:56,056 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:06,750 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:17,155 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:51:17,155 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:51:17,162 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-23T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:51:12.393765+00:00, run_end_date=2025-05-07 18:51:14.740516+00:00, run_duration=2.346751, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=327, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:50:55.753221+00:00, queued_by_job_id=169, pid=44150
2025-05-07 15:51:17,163 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:51:01.660663+00:00, run_end_date=2025-05-07 18:51:03.207110+00:00, run_duration=1.546447, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=326, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:50:55.753221+00:00, queued_by_job_id=169, pid=44128
2025-05-07 15:51:18,303 INFO - Setting next_dagrun for anomaly_detection to 2023-03-26 00:00:00+00:00, run_after=2023-03-27 00:00:00+00:00
2025-05-07 15:51:18,893 INFO - Marking run <DagRun anomaly_detection @ 2023-03-23 00:00:00+00:00: scheduled__2023-03-23T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:50:37.680121+00:00. externally triggered: False> successful
2025-05-07 15:51:18,894 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-23 00:00:00+00:00, run_id=scheduled__2023-03-23T00:00:00+00:00, run_start_date=2025-05-07 18:50:37.895316+00:00, run_end_date=2025-05-07 18:51:18.894566+00:00, run_duration=40.99925, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-23 00:00:00+00:00, data_interval_end=2023-03-24 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:51:18,901 INFO - Setting next_dagrun for anomaly_detection to 2023-03-24 00:00:00+00:00, run_after=2023-03-25 00:00:00+00:00
2025-05-07 15:51:19,326 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-24T00:00:00+00:00 [scheduled]>
2025-05-07 15:51:19,327 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:51:19,329 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:51:19,330 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-24T00:00:00+00:00 [scheduled]>
2025-05-07 15:51:19,333 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-25T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-24T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:51:19,334 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:51:19,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:19,335 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-24T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:51:19,336 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:19,624 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:29,151 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:39,637 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:51:39,637 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-24T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:51:40,182 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:51:25.249449+00:00, run_end_date=2025-05-07 18:51:26.619003+00:00, run_duration=1.369554, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=328, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:51:19.332090+00:00, queued_by_job_id=169, pid=44176
2025-05-07 15:51:40,186 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-24T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:51:34.873523+00:00, run_end_date=2025-05-07 18:51:37.190716+00:00, run_duration=2.317193, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=329, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:51:19.332090+00:00, queued_by_job_id=169, pid=44198
2025-05-07 15:51:41,911 INFO - Setting next_dagrun for anomaly_detection to 2023-03-25 00:00:00+00:00, run_after=2023-03-26 00:00:00+00:00
2025-05-07 15:51:42,167 INFO - Marking run <DagRun anomaly_detection @ 2023-03-24 00:00:00+00:00: scheduled__2023-03-24T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:50:54.748526+00:00. externally triggered: False> successful
2025-05-07 15:51:42,168 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-24 00:00:00+00:00, run_id=scheduled__2023-03-24T00:00:00+00:00, run_start_date=2025-05-07 18:50:54.989871+00:00, run_end_date=2025-05-07 18:51:42.168297+00:00, run_duration=47.178426, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-24 00:00:00+00:00, data_interval_end=2023-03-25 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:51:42,173 INFO - Setting next_dagrun for anomaly_detection to 2023-03-25 00:00:00+00:00, run_after=2023-03-26 00:00:00+00:00
2025-05-07 15:51:42,545 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:51:42,546 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:51:42,547 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-25T00:00:00+00:00 [scheduled]>
2025-05-07 15:51:42,550 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-25T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:51:42,551 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-25T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:51:42,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:42,854 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:52,861 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-25T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:51:52,865 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-25T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:51:48.570333+00:00, run_end_date=2025-05-07 18:51:50.510585+00:00, run_duration=1.940252, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=330, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:51:42.548757+00:00, queued_by_job_id=169, pid=44229
2025-05-07 15:51:56,536 INFO - Setting next_dagrun for anomaly_detection to 2023-03-27 00:00:00+00:00, run_after=2023-03-28 00:00:00+00:00
2025-05-07 15:51:57,040 INFO - Marking run <DagRun anomaly_detection @ 2023-03-25 00:00:00+00:00: scheduled__2023-03-25T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:51:18.299280+00:00. externally triggered: False> successful
2025-05-07 15:51:57,041 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-25 00:00:00+00:00, run_id=scheduled__2023-03-25T00:00:00+00:00, run_start_date=2025-05-07 18:51:18.535407+00:00, run_end_date=2025-05-07 18:51:57.041645+00:00, run_duration=38.506238, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-25 00:00:00+00:00, data_interval_end=2023-03-26 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:51:57,048 INFO - Setting next_dagrun for anomaly_detection to 2023-03-26 00:00:00+00:00, run_after=2023-03-27 00:00:00+00:00
2025-05-07 15:51:57,332 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:51:57,333 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:51:57,333 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:51:57,336 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:51:57,336 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:51:57,336 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:51:57,614 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:08,665 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:52:08,669 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:52:03.100558+00:00, run_end_date=2025-05-07 18:52:05.757240+00:00, run_duration=2.656682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=331, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:51:57.334870+00:00, queued_by_job_id=169, pid=44261
2025-05-07 15:52:09,567 INFO - Setting next_dagrun for anomaly_detection to 2023-03-27 00:00:00+00:00, run_after=2023-03-28 00:00:00+00:00
2025-05-07 15:52:10,210 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:52:10,212 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:52:10,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-26T00:00:00+00:00 [scheduled]>
2025-05-07 15:52:10,446 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.train_model scheduled__2023-03-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:52:10,447 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:52:10,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:10,980 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:23,148 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-26T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:52:23,233 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=train_model, run_id=scheduled__2023-03-26T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:52:17.085959+00:00, run_end_date=2025-05-07 18:52:20.347321+00:00, run_duration=3.261362, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=332, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-05-07 18:52:10.215024+00:00, queued_by_job_id=169, pid=44288
2025-05-07 15:52:24,695 INFO - Setting next_dagrun for anomaly_detection to 2023-03-28 00:00:00+00:00, run_after=2023-03-29 00:00:00+00:00
2025-05-07 15:52:25,281 INFO - Marking run <DagRun anomaly_detection @ 2023-03-26 00:00:00+00:00: scheduled__2023-03-26T00:00:00+00:00, state:running, queued_at: 2025-05-07 18:51:56.531596+00:00. externally triggered: False> successful
2025-05-07 15:52:25,282 INFO - DagRun Finished: dag_id=anomaly_detection, execution_date=2023-03-26 00:00:00+00:00, run_id=scheduled__2023-03-26T00:00:00+00:00, run_start_date=2025-05-07 18:51:56.722794+00:00, run_end_date=2025-05-07 18:52:25.282254+00:00, run_duration=28.55946, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-03-26 00:00:00+00:00, data_interval_end=2023-03-27 00:00:00+00:00, dag_hash=0f7c6f260c3d56bd30cde400c694dcf9
2025-05-07 15:52:25,285 INFO - Setting next_dagrun for anomaly_detection to 2023-03-27 00:00:00+00:00, run_after=2023-03-28 00:00:00+00:00
2025-05-07 15:52:25,652 INFO - 1 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:52:25,653 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:52:25,655 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:52:25,661 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-27T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:52:25,663 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:52:25,665 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:25,969 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:37,031 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-27T00:00:00+00:00', try_number=1, map_index=-1)
2025-05-07 15:52:37,035 INFO - TaskInstance Finished: dag_id=anomaly_detection, task_id=validate_data, run_id=scheduled__2023-03-27T00:00:00+00:00, map_index=-1, run_start_date=2025-05-07 18:52:31.918521+00:00, run_end_date=2025-05-07 18:52:33.245080+00:00, run_duration=1.326559, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=333, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-05-07 18:52:25.658455+00:00, queued_by_job_id=169, pid=44323
2025-05-07 15:52:41,272 INFO - Setting next_dagrun for anomaly_detection to 2023-03-29 00:00:00+00:00, run_after=2023-03-30 00:00:00+00:00
2025-05-07 15:52:42,210 INFO - 2 tasks up for execution:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:52:42,212 INFO - DAG anomaly_detection has 0/16 running and queued tasks
2025-05-07 15:52:42,213 INFO - DAG anomaly_detection has 1/16 running and queued tasks
2025-05-07 15:52:42,214 INFO - Setting the following tasks to queued state:
	<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: anomaly_detection.train_model scheduled__2023-03-27T00:00:00+00:00 [scheduled]>
2025-05-07 15:52:42,222 INFO - Trying to enqueue tasks: [<TaskInstance: anomaly_detection.validate_data scheduled__2023-03-28T00:00:00+00:00 [scheduled]>, <TaskInstance: anomaly_detection.train_model scheduled__2023-03-27T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-05-07 15:52:42,224 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='validate_data', run_id='scheduled__2023-03-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-05-07 15:52:42,225 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:42,227 INFO - Sending TaskInstanceKey(dag_id='anomaly_detection', task_id='train_model', run_id='scheduled__2023-03-27T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-05-07 15:52:42,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:42,599 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:53,752 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:52:54,745 INFO - Exiting gracefully upon receiving signal 15
2025-05-07 15:52:55,156 INFO - Sending 15 to group 39318. PIDs of all processes in the group: []
2025-05-07 15:52:55,157 INFO - Sending the signal 15 to group 39318
2025-05-07 15:52:55,158 INFO - Sending the signal 15 to process 39318 as process group is missing.
2025-05-07 15:52:55,160 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'validate_data', 'scheduled__2023-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:53:02,590 INFO - Executing command: ['airflow', 'tasks', 'run', 'anomaly_detection', 'train_model', 'scheduled__2023-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/anomaly_detection.py']
2025-05-07 15:53:12,252 INFO - Sending 15 to group 39318. PIDs of all processes in the group: []
2025-05-07 15:53:12,252 INFO - Sending the signal 15 to group 39318
2025-05-07 15:53:12,252 INFO - Sending the signal 15 to process 39318 as process group is missing.
2025-05-07 15:53:12,253 INFO - Exited execute loop
